{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "- drug_id を使って解析する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2a931fa\n"
     ]
    }
   ],
   "source": [
    "# gitのhash\n",
    "import subprocess\n",
    "cmd = \"git rev-parse --short HEAD\"\n",
    "hash = subprocess.check_output(cmd.split()).strip().decode('utf-8')\n",
    "print(hash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic\n",
    "DEBUG = False \n",
    "NB = '018'\n",
    "PATH_TRAIN = '../data_ignore/input/train_features.csv'\n",
    "PATH_TRAIN_SCORED = '../data_ignore/input/train_targets_scored.csv'\n",
    "PATH_TRAIN_NONSCORED = '../data_ignore/input/train_targets_nonscored.csv'\n",
    "PATH_SUB = '../data_ignore/input/sample_submission.csv'\n",
    "PATH_TEST = '../data_ignore/input/test_features.csv'\n",
    "PATH_DRUGID = '../data_ignore/input/train_drug.csv'\n",
    "SAVE_DIR = f'../data_ignore/output_nb/nb{NB}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_str = \"\"\"\n",
    "globals:\n",
    "  seed: 2020\n",
    "  device: cuda\n",
    "  num_epochs: 45\n",
    "\n",
    "dataset:\n",
    "  name: \n",
    "  params:\n",
    "    \n",
    "split:\n",
    "  name: MultiStratifiedKFold\n",
    "  params:\n",
    "    n_splits: 5\n",
    "    random_state: 42\n",
    "    shuffle: True\n",
    "\n",
    "loader:\n",
    "  train:\n",
    "    batch_size: 512\n",
    "    shuffle: True\n",
    "    num_workers: 10\n",
    "    pin_memory: True\n",
    "    drop_last: True\n",
    "  val:\n",
    "    batch_size: 512\n",
    "    shuffle: False\n",
    "    num_workers: 10\n",
    "    pin_memory: True\n",
    "    drop_last: False\n",
    "\n",
    "model:\n",
    "  name: \n",
    "  params:\n",
    "\n",
    "loss:\n",
    "  name: SmoothLogitsLoss\n",
    "  params: {}\n",
    "\n",
    "optimizer:\n",
    "  name: Adam\n",
    "  params:\n",
    "    lr: 0.005\n",
    "\n",
    "scheduler:\n",
    "  name: CosineAnnealingLR\n",
    "  params:\n",
    "    T_max: 10\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import everything I need :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py:886: MatplotlibDeprecationWarning: \n",
      "examples.directory is deprecated; in the future, examples will be found relative to the 'datapath' directory.\n",
      "  \"found relative to the 'datapath' directory.\".format(key))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import yaml\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from fastprogress import progress_bar\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import KFold\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df_):\n",
    "    df = df_.copy()\n",
    "    df.loc[:, 'cp_type'] = df.loc[:, 'cp_type'].map({'trt_cp': 0, 'ctl_vehicle': 1})\n",
    "    df.loc[:, 'cp_dose'] = df.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n",
    "#     df.loc[:, 'cp_time'] = df.loc[:, 'cp_time'].map({24: 0, 48: 1, 72: 2})\n",
    "    del df['sig_id']\n",
    "    return df\n",
    "\n",
    "def remove_ctl_cp(features_, target_):\n",
    "    features = features_.copy()\n",
    "    target = target_.copy()\n",
    "#     bools = features['cp_type'] != 'ctl_vehicle'\n",
    "    bools = features['cp_type'] != 1\n",
    "    features = features[bools].reset_index(drop=True)\n",
    "    features = features.drop(['cp_type'], axis=1).values\n",
    "    target = target[bools].reset_index(drop=True).values\n",
    "    return features, target\n",
    "\n",
    "def add_ctl_cp_oof(oof):\n",
    "    oof_new = np.zeros_like(train_targets).astype(float)\n",
    "    bools = train_features['cp_type'] != 'ctl_vehicle'\n",
    "    oof_new[bools, :] = oof\n",
    "    return oof_new\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "class permutation_importance():\n",
    "    def __init__(self, model, metric):\n",
    "        self.is_computed = False\n",
    "        self.n_feat = 0\n",
    "        self.base_score = 0\n",
    "        self.model = model\n",
    "        self.metric = metric\n",
    "        self.df_result = []\n",
    "    \n",
    "    def compute(self, _X_valid, y_valid):\n",
    "        X_valid = pd.DataFrame(_X_valid, columns=FEAT_COLUMNS)\n",
    "        self.n_feat = len(X_valid.columns)\n",
    "        \n",
    "        val_set = MoaDataset(_X_valid, y_valid, mode='train')\n",
    "        dataloaders = {'val': DataLoader(val_set, **settings['loader']['val'])}\n",
    "        y_valid_pred = get_epoch_pred(self.model, device, dataloaders['val'])\n",
    "        \n",
    "        \n",
    "        self.base_score = self.metric(y_valid, y_valid_pred)\n",
    "        self.df_result = pd.DataFrame({'feat': X_valid.columns, \n",
    "                                       'score': np.zeros(self.n_feat),\n",
    "                                       'score_diff': np.zeros(self.n_feat)})\n",
    "        \n",
    "        # predict\n",
    "        for i, col in enumerate(progress_bar(X_valid.columns)):\n",
    "            df_perm = X_valid.copy()\n",
    "            np.random.seed(1)\n",
    "            df_perm[col] = np.random.permutation(df_perm[col])\n",
    "            \n",
    "#             y_valid_pred = self.model.predict(df_perm)\n",
    "            val_set = MoaDataset(df_perm.values, y_valid, mode='train')\n",
    "            dataloaders = {'val': DataLoader(val_set, **settings['loader']['val'])}\n",
    "            y_valid_pred = get_epoch_pred(self.model, device, dataloaders['val'])\n",
    "            \n",
    "            score = self.metric(y_valid, y_valid_pred)\n",
    "            self.df_result['score'][self.df_result['feat']==col] = score\n",
    "            self.df_result['score_diff'][self.df_result['feat']==col] = self.base_score - score\n",
    "        self.is_computed = True\n",
    "    \n",
    "    def get_negative_feature(self):\n",
    "        assert self.is_computed!=False, 'compute メソッドが実行されていません'\n",
    "        idx = self.df_result['score_diff'] < 0\n",
    "        return self.df_result.loc[idx, 'feat'].values.tolist()\n",
    "        \n",
    "    def get_positive_feature(self):\n",
    "        assert self.is_computed!=False, 'compute メソッドが実行されていません'\n",
    "        idx = self.df_result['score_diff'] > 0\n",
    "        return self.df_result.loc[idx, 'feat'].values.tolist()\n",
    "    \n",
    "    def show_permutation_importance(self, score_type='loss'):\n",
    "        '''score_type = 'loss' or 'accuracy'  '''\n",
    "        assert self.is_computed!=False, 'compute メソッドが実行されていません'\n",
    "        if score_type=='loss':\n",
    "            ascending = True\n",
    "        elif score_type=='accuracy':\n",
    "            ascending = False\n",
    "        else:\n",
    "            ascending = ''\n",
    "        \n",
    "        plt.figure(figsize=(15, int(0.25*self.n_feat)))\n",
    "        sns.barplot(x=\"score_diff\", y=\"feat\", data=self.df_result.sort_values(by=\"score_diff\", ascending=ascending))\n",
    "        plt.title('base_score - permutation_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoaModel(nn.Module):\n",
    "    def __init__(self, n_input, n_output):\n",
    "        super(MoaModel, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(n_input)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(n_input, 2048))\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(2048)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.dense2 = nn.utils.weight_norm(nn.Linear(2048, 1048))\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(1048)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "#         self.dense3 = nn.utils.weight_norm(nn.Linear(1048, 206))\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(1048, n_output))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.dense1(x))\n",
    "        \n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.dense2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x_raw = self.dense3(x)\n",
    "        x_sigmoid = F.sigmoid(x_raw)\n",
    "        \n",
    "        return x_sigmoid, x_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoaDataset(Dataset):\n",
    "    def __init__(self, df, targets, mode):\n",
    "        self.mode = mode\n",
    "        self.df = df\n",
    "#         self.targets = targets\n",
    "        if mode=='train':\n",
    "            self.targets = targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == 'train':\n",
    "            return torch.FloatTensor(self.df[idx]), torch.FloatTensor(self.targets[idx])\n",
    "        elif self.mode == 'val':\n",
    "            return torch.FloatTensor(self.df[idx]), 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_log_loss(y_true, y_pred):\n",
    "    metrics = []\n",
    "#     for i in range(y_true.shape[1]):\n",
    "#         metrics.append(log_loss(y_true[:, i], y_pred[:, i].astype(float), labels=[0,1]))\n",
    "#     return np.mean(metrics)\n",
    "    y_true =  y_true.astype(np.float64).ravel()\n",
    "    y_pred =  y_pred.astype(np.float64).ravel()\n",
    "    return log_loss(y_true, y_pred, labels=[0, 1])\n",
    "\n",
    "class SmoothBCEwLogits(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.001):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n",
    "        assert 0 <= smoothing < 1\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1),\n",
    "            self.smoothing)\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets,self.weight)\n",
    "\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"\n",
    "    Early stops the training if validation loss doesn't improve after a given patience.\n",
    "    https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\n",
    "    \"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "#         self.best_state_dict = {}\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "#         if not DEBUG:\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "#         self.best_state_dict = model.state_dict()\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, device, train_loader, optimizer, scheduler, criterion):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(True):\n",
    "            pred_sigmoid, pred_raw = model(x)\n",
    "            loss = criterion(pred_raw, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        running_loss += loss.item() / len(train_loader)\n",
    "    scheduler.step()\n",
    "    return running_loss\n",
    "\n",
    "def get_epoch_loss_score(model, device, valid_loader, criterion, optimizer):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    targets = []\n",
    "    preds = []\n",
    "    for i, (x, y) in enumerate(valid_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(False):\n",
    "            pred_sigmoid, pred_raw = model(x)\n",
    "            loss = criterion(pred_raw, y)\n",
    "        running_loss += loss.item() / len(valid_loader)\n",
    "        targets.append(y)\n",
    "        preds.append(pred_sigmoid)\n",
    "    targets = torch.cat(targets, dim=0).cpu().numpy()\n",
    "    preds = torch.cat(preds, dim=0).cpu().numpy()\n",
    "    _mean_log_loss = mean_log_loss(targets, preds)\n",
    "    return running_loss, _mean_log_loss, preds\n",
    "\n",
    "def get_epoch_pred(model, device, valid_loader):\n",
    "    model.eval()\n",
    "    targets = []\n",
    "    preds = []\n",
    "    for i, (x, y) in enumerate(valid_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        with torch.set_grad_enabled(False):\n",
    "            pred_sigmoid, pred_raw = model(x)\n",
    "        targets.append(y)\n",
    "        preds.append(pred_sigmoid)\n",
    "    targets = torch.cat(targets, dim=0).cpu().numpy()\n",
    "    preds = torch.cat(preds, dim=0).cpu().numpy()\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fold(dataloaders, shape, checkpoint_path, ModelClass, show_log=True):\n",
    "    device = torch.device(\"cuda\")\n",
    "    model = ModelClass(shape[0], shape[1]).to(device)\n",
    "#     model = ModelClass(train.shape[1], ).to(device)\n",
    "    early_stopping = EarlyStopping(patience=15, verbose=show_log, path=checkpoint_path)\n",
    "    optimizer = optim.__getattribute__(settings['optimizer']['name'])(\n",
    "        model.parameters(), **settings['optimizer']['params'])\n",
    "    scheduler = optim.lr_scheduler.__getattribute__(settings['scheduler']['name'])(\n",
    "        optimizer, **settings['scheduler']['params'])\n",
    "    \n",
    "    best_valid_loss = np.inf\n",
    "    best_mean_log_loss = np.inf\n",
    "    best_preds = 0\n",
    "    val_losses = []\n",
    "    trn_losses = []\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss =  train_model(model, device, dataloaders['train'], optimizer, scheduler, criterion)\n",
    "        valid_loss, _mean_log_loss, preds = get_epoch_loss_score(model, device, dataloaders['val'], criterion, optimizer)\n",
    "\n",
    "        trn_losses.append(train_loss)\n",
    "        val_losses.append(valid_loss)\n",
    "        if show_log:\n",
    "            print(f\"Epoch {str(epoch+1).zfill(2)}/{n_epochs }   loss: {train_loss:5.5f}   val_loss: {valid_loss:5.5f}   mean_log_loss: {_mean_log_loss:5.5f}\")\n",
    "        early_stopping(valid_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "        if valid_loss < best_valid_loss: \n",
    "            best_valid_loss = valid_loss\n",
    "            best_mean_log_loss = _mean_log_loss\n",
    "            best_preds = preds\n",
    "    return best_mean_log_loss, best_preds, trn_losses, val_losses\n",
    "\n",
    "def run(splitter, train, targets, ModelClass, show_log=True, pi=False):\n",
    "    mean_log_loss_list = []\n",
    "    oof = np.zeros_like(targets).astype(float)\n",
    "    df_pi = pd.DataFrame(columns=['feat', 'score_diff'])\n",
    "    for n, (idx_trn, idx_val) in enumerate(splitter.split(train, targets)):\n",
    "        print('-'*100)\n",
    "        print(f':: start fold {n+1}/{n_splits} at {time.ctime()} ::')\n",
    "        print('-'*100)\n",
    "        X_trn, X_val = train[idx_trn], train[idx_val]\n",
    "        y_trn, y_val = targets[idx_trn], targets[idx_val]\n",
    "\n",
    "        train_set = MoaDataset(X_trn, y_trn, mode='train')\n",
    "        val_set = MoaDataset(X_val, y_val, mode='train')\n",
    "\n",
    "        dataloaders = {\n",
    "            'train': DataLoader(train_set, **settings['loader']['train']),\n",
    "            'val': DataLoader(val_set, **settings['loader']['val']),\n",
    "        }\n",
    "\n",
    "        checkpoint_path = f'{SAVE_DIR}Fold{n+1}of{n_splits}.pt'\n",
    "        shape = (X_trn.shape[1], y_trn.shape[1])\n",
    "        best_mean_log_loss, best_preds, trn_losses, val_losses =  run_fold(dataloaders, shape, checkpoint_path, ModelClass, show_log=show_log)\n",
    "\n",
    "        # result\n",
    "        print(f':: best mean_log_loss: {best_mean_log_loss:5.5f} ::')\n",
    "        mean_log_loss_list.append(best_mean_log_loss)\n",
    "        oof[idx_val, :] = best_preds\n",
    "        \n",
    "        # permutation importance\n",
    "        if pi:\n",
    "            device = torch.device(\"cuda\")\n",
    "            model = ModelClass(shape[0], shape[1]).to(device)\n",
    "            state_dict = torch.load(checkpoint_path)\n",
    "            model.load_state_dict(state_dict)\n",
    "            model.to(device)\n",
    "            model.eval()\n",
    "            pi = permutation_importance(model, mean_log_loss) # model と metric を渡す\n",
    "            pi.compute(X_val, y_val)\n",
    "            pi_result = pi.df_result\n",
    "            df_pi = pd.concat([df_pi, pi_result[['feat', 'score_diff']]])\n",
    "    #         pi.show_permutation_importance(score_type='loss')\n",
    "        \n",
    "        # plot\n",
    "        if show_log:\n",
    "            x = np.arange(1, len(trn_losses)+1)\n",
    "            plt.figure(figsize=(12, 7))\n",
    "            plt.plot(x[1:], trn_losses[1:], '--.', label='train')\n",
    "            plt.plot(x[1:], val_losses[1:], '--.', label='valid')\n",
    "            plt.title(f\"fold{n+1}/{n_splits} {settings['loss']['name']}\")\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        print('\\n')\n",
    "    \n",
    "    if pi:\n",
    "        # permutation score\n",
    "        plt.figure(figsize=(15, int(0.25*len(FEAT_COLUMNS))))\n",
    "        order = df_pi.groupby([\"feat\"]).mean()['score_diff'].reset_index().sort_values('score_diff', ascending=True)\n",
    "        sns.barplot(x=\"score_diff\", y=\"feat\", data=df_pi, order=order['feat'])\n",
    "        plt.title('base_score - permutation_score')\n",
    "        plt.show()\n",
    "    return mean_log_loss_list, oof, df_pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = yaml.safe_load(settings_str)\n",
    "seed_everything(settings['globals']['seed'])\n",
    "sns.set()\n",
    "sns.set_context('talk')\n",
    "# sns.set_context('notebook')\n",
    "\n",
    "if not os.path.exists(SAVE_DIR):\n",
    "    os.makedirs(SAVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    settings['split']['params']['n_splits'] = 2\n",
    "    settings['globals']['num_epochs'] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv(PATH_TRAIN)\n",
    "train_targets = pd.read_csv(PATH_TRAIN_SCORED)\n",
    "train_drug = pd.read_csv(PATH_DRUGID)\n",
    "# test_features = pd.read_csv(PATH_TEST)\n",
    "\n",
    "# ss = pd.read_csv(PATH_SUB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step_row = 100\n",
    "end_col = 10\n",
    "step_row = 10\n",
    "# step_row = 4\n",
    "# step_row = 2\n",
    "if DEBUG:\n",
    "    print(':: debug mode ::')\n",
    "    train_features = train_features.iloc[::step_row, :end_col]\n",
    "    train_targets = train_targets.iloc[::step_row, :]\n",
    "#     test_features = test_features.iloc[::100, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_trt = (train_features['cp_type'] == 'trt_cp').values\n",
    "train = preprocess(train_features)\n",
    "FEAT_COLUMNS = train_features.columns[2:]\n",
    "# test = preprocess(test_features).values\n",
    "\n",
    "del train_targets['sig_id']\n",
    "\n",
    "target_cols = [col for col in train_targets.columns]\n",
    "train, targets = remove_ctl_cp(train, train_targets)\n",
    "# train_targets = train_targets.loc[train['cp_type']==0].reset_index(drop=True).values\n",
    "# train = train.loc[train['cp_type']==0].reset_index(drop=True).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:         (21948, 874)\n",
      "train_targets shape: (21948, 206)\n"
     ]
    }
   ],
   "source": [
    "print(f'train shape:         {train.shape}')\n",
    "# print(f'test shape:          {test.shape}')\n",
    "print(f'train_targets shape: {targets.shape}')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n_splits = settings['split']['params']['n_splits']\n",
    "n_epochs = settings['globals']['num_epochs']\n",
    "splitter = MultilabelStratifiedKFold(**settings['split']['params'])\n",
    "device = settings['globals']['device']\n",
    "# criterion = criterion_ = nn.__getattribute__(\n",
    "#     settings['loss']['name'])(**settings['loss']['params'])\n",
    "criterion = SmoothBCEwLogits(**settings['loss']['params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "load oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>adrenergic_receptor_agonist</th>\n",
       "      <th>...</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003428</td>\n",
       "      <td>0.001405</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.005459</td>\n",
       "      <td>0.068069</td>\n",
       "      <td>0.007565</td>\n",
       "      <td>0.006974</td>\n",
       "      <td>0.002605</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.023679</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.002231</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.002598</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000824</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.001830</td>\n",
       "      <td>0.017313</td>\n",
       "      <td>0.013250</td>\n",
       "      <td>0.004077</td>\n",
       "      <td>0.002426</td>\n",
       "      <td>0.002496</td>\n",
       "      <td>0.001395</td>\n",
       "      <td>0.013766</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002163</td>\n",
       "      <td>0.003794</td>\n",
       "      <td>0.002362</td>\n",
       "      <td>0.002224</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.001549</td>\n",
       "      <td>0.002565</td>\n",
       "      <td>0.008342</td>\n",
       "      <td>0.006311</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004459</td>\n",
       "      <td>0.005623</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.005052</td>\n",
       "      <td>0.016952</td>\n",
       "      <td>0.006443</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.010359</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.003232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002149</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>0.005329</td>\n",
       "      <td>0.003227</td>\n",
       "      <td>0.001696</td>\n",
       "      <td>0.014682</td>\n",
       "      <td>0.002368</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.002813</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.001317</td>\n",
       "      <td>0.004430</td>\n",
       "      <td>0.002437</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>0.001194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017621</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>0.135419</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.001207</td>\n",
       "      <td>0.001212</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000646</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.007079</td>\n",
       "      <td>0.012863</td>\n",
       "      <td>0.012686</td>\n",
       "      <td>0.002953</td>\n",
       "      <td>0.010215</td>\n",
       "      <td>0.003091</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.008687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003503</td>\n",
       "      <td>0.002866</td>\n",
       "      <td>0.001668</td>\n",
       "      <td>0.002689</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>0.001471</td>\n",
       "      <td>0.005410</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.001826</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  acat_inhibitor  \\\n",
       "0                     0.003428                0.001405        0.000703   \n",
       "1                     0.000824                0.000599        0.001830   \n",
       "2                     0.004459                0.005623        0.001095   \n",
       "3                     0.000276                0.000743        0.001317   \n",
       "4                     0.000646                0.001003        0.007079   \n",
       "\n",
       "   acetylcholine_receptor_agonist  acetylcholine_receptor_antagonist  \\\n",
       "0                        0.005459                           0.068069   \n",
       "1                        0.017313                           0.013250   \n",
       "2                        0.005052                           0.016952   \n",
       "3                        0.004430                           0.002437   \n",
       "4                        0.012863                           0.012686   \n",
       "\n",
       "   acetylcholinesterase_inhibitor  adenosine_receptor_agonist  \\\n",
       "0                        0.007565                    0.006974   \n",
       "1                        0.004077                    0.002426   \n",
       "2                        0.006443                    0.001563   \n",
       "3                        0.000435                    0.001486   \n",
       "4                        0.002953                    0.010215   \n",
       "\n",
       "   adenosine_receptor_antagonist  adenylyl_cyclase_activator  \\\n",
       "0                       0.002605                    0.000736   \n",
       "1                       0.002496                    0.001395   \n",
       "2                       0.010359                    0.000897   \n",
       "3                       0.000419                    0.000445   \n",
       "4                       0.003091                    0.001398   \n",
       "\n",
       "   adrenergic_receptor_agonist  ...  trpv_agonist  trpv_antagonist  \\\n",
       "0                     0.023679  ...      0.000611         0.002231   \n",
       "1                     0.013766  ...      0.002163         0.003794   \n",
       "2                     0.003232  ...      0.002149         0.001665   \n",
       "3                     0.001194  ...      0.017621         0.001743   \n",
       "4                     0.008687  ...      0.003503         0.002866   \n",
       "\n",
       "   tubulin_inhibitor  tyrosine_kinase_inhibitor  \\\n",
       "0           0.000627                   0.002979   \n",
       "1           0.002362                   0.002224   \n",
       "2           0.005329                   0.003227   \n",
       "3           0.135419                   0.003500   \n",
       "4           0.001668                   0.002689   \n",
       "\n",
       "   ubiquitin_specific_protease_inhibitor  vegfr_inhibitor  vitamin_b  \\\n",
       "0                               0.000706         0.000589   0.001297   \n",
       "1                               0.000809         0.001549   0.002565   \n",
       "2                               0.001696         0.014682   0.002368   \n",
       "3                               0.001019         0.001207   0.001212   \n",
       "4                               0.000652         0.001471   0.005410   \n",
       "\n",
       "   vitamin_d_receptor_agonist  wnt_inhibitor  fold  \n",
       "0                    0.000444       0.002598     3  \n",
       "1                    0.008342       0.006311     5  \n",
       "2                    0.000777       0.002813     2  \n",
       "3                    0.000353       0.000621     1  \n",
       "4                    0.000728       0.001826     4  \n",
       "\n",
       "[5 rows x 207 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../data_ignore/output_nb/nb013/oof.csv'\n",
    "df_oof = pd.read_csv(path)\n",
    "oof = df_oof.values[:, :-1]\n",
    "df_oof.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>drug_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>b68db1d53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>df89a8e5a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>18bb41b2c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>8c7f86626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>7cbed3131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id    drug_id\n",
       "0  id_000644bb2  b68db1d53\n",
       "1  id_000779bfc  df89a8e5a\n",
       "2  id_000a6266a  18bb41b2c\n",
       "3  id_0015fd391  8c7f86626\n",
       "4  id_001626bd3  7cbed3131"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_drug.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "top20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cacb2b860    1866\n",
       "87d714366     718\n",
       "9f80f3f77     246\n",
       "8b87a7a83     203\n",
       "5628cb3ee     202\n",
       "d08af5d4b     196\n",
       "292ab2c28     194\n",
       "d50f18348     186\n",
       "d1b47f29d     178\n",
       "67c879e79      19\n",
       "52d1e6f43      18\n",
       "d488d031d      18\n",
       "83a9ea167      18\n",
       "1a52478dc      14\n",
       "11f66c124      14\n",
       "5d9bb0ebe      14\n",
       "a7c2673c1      14\n",
       "30aa2f709      14\n",
       "6b8b675cc      14\n",
       "bb3b7c7d5      13\n",
       "Name: drug_id, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_drug['drug_id'].value_counts()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263b9a195    1\n",
       "4d7280c91    1\n",
       "58d311643    1\n",
       "861a693e3    1\n",
       "3264f3b74    1\n",
       "4a8eda087    1\n",
       "ed64cad3a    1\n",
       "44bba684f    1\n",
       "153840764    1\n",
       "6ec93d617    1\n",
       "ed81f4046    1\n",
       "a90e40334    1\n",
       "c1292b6d8    1\n",
       "828099693    1\n",
       "5def38f5f    1\n",
       "a8ec8311e    1\n",
       "29d24570f    1\n",
       "277f1d6f9    1\n",
       "dac782c74    1\n",
       "b6b4f212d    1\n",
       "Name: drug_id, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_drug['drug_id'].value_counts()[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
