{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "- nb021の改良\n",
    "- SmoothLogitsLoss の最適化を行なう\n",
    "- nb020のfoldを使う\n",
    "- top8を除く"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f78cefd\n"
     ]
    }
   ],
   "source": [
    "# gitのhash\n",
    "import subprocess\n",
    "cmd = \"git rev-parse --short HEAD\"\n",
    "hash = subprocess.check_output(cmd.split()).strip().decode('utf-8')\n",
    "print(hash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic\n",
    "NB = '022'\n",
    "DEBUG = False \n",
    "isPI = False\n",
    "isShowLog = False\n",
    "\n",
    "PATH_TRAIN = '../data_ignore/input/train_features.csv'\n",
    "PATH_TRAIN_SCORED = '../data_ignore/input/train_targets_scored.csv'\n",
    "PATH_TRAIN_NONSCORED = '../data_ignore/input/train_targets_nonscored.csv'\n",
    "PATH_SUB = '../data_ignore/input/sample_submission.csv'\n",
    "PATH_TEST = '../data_ignore/input/test_features.csv'\n",
    "SAVE_DIR = f'../data_ignore/output_nb/nb{NB}/'\n",
    "PATH_DRUGID = '../data_ignore/input/train_drug.csv'\n",
    "PATH_GROUP696 = './../data_ignore/output_nb/nb004/group.csv'\n",
    "PATH_ESTIMATED_LOGLOSS = './../data_ignore/output_nb/nb017/estimated_logloss.csv'\n",
    "TOP8_DRUG = ['87d714366', '9f80f3f77', '8b87a7a83', '5628cb3ee', 'd08af5d4b', '292ab2c28', 'd50f18348', 'd1b47f29d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_str = \"\"\"\n",
    "globals:\n",
    "  seed: 2020\n",
    "  device: cuda\n",
    "  num_epochs: 45\n",
    "\n",
    "dataset:\n",
    "  name: \n",
    "  params:\n",
    "    \n",
    "split:\n",
    "  name: MultiStratifiedKFold\n",
    "  params:\n",
    "    n_splits: 5\n",
    "    random_state: 42\n",
    "    shuffle: True\n",
    "\n",
    "loader:\n",
    "  train:\n",
    "    batch_size: 512\n",
    "    shuffle: True\n",
    "    num_workers: 10\n",
    "    pin_memory: True\n",
    "    drop_last: True\n",
    "  val:\n",
    "    batch_size: 512\n",
    "    shuffle: False\n",
    "    num_workers: 10\n",
    "    pin_memory: True\n",
    "    drop_last: False\n",
    "\n",
    "model:\n",
    "  name: \n",
    "  params:\n",
    "\n",
    "loss:\n",
    "  name: SmoothLogitsLoss\n",
    "  params: {}\n",
    "\n",
    "optimizer:\n",
    "  name: Adam\n",
    "  params:\n",
    "    lr: 0.005\n",
    "\n",
    "scheduler:\n",
    "  name: CosineAnnealingLR\n",
    "  params:\n",
    "    T_max: 10\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import everything I need :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py:886: MatplotlibDeprecationWarning: \n",
      "examples.directory is deprecated; in the future, examples will be found relative to the 'datapath' directory.\n",
      "  \"found relative to the 'datapath' directory.\".format(key))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import yaml\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from pdb import set_trace as st\n",
    "from fastprogress import progress_bar\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import KFold\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df_):\n",
    "    df = df_.copy()\n",
    "    df.loc[:, 'cp_type'] = df.loc[:, 'cp_type'].map({'trt_cp': 0, 'ctl_vehicle': 1})\n",
    "    df.loc[:, 'cp_dose'] = df.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n",
    "#     df.loc[:, 'cp_time'] = df.loc[:, 'cp_time'].map({24: 0, 48: 1, 72: 2})\n",
    "    del df['sig_id']\n",
    "    return df\n",
    "\n",
    "def remove_ctl_cp(features_, target_):\n",
    "    features = features_.copy()\n",
    "    target = target_.copy()\n",
    "#     bools = features['cp_type'] != 'ctl_vehicle'\n",
    "    bools = features['cp_type'] != 1\n",
    "    features = features[bools].reset_index(drop=True)\n",
    "    features = features.drop(['cp_type'], axis=1).values\n",
    "    target = target[bools].reset_index(drop=True).values\n",
    "    return features, target\n",
    "\n",
    "def add_ctl_cp_oof(oof):\n",
    "    oof_new = np.zeros_like(train_targets).astype(float)\n",
    "    bools = train_features['cp_type'] != 'ctl_vehicle'\n",
    "    oof_new[bools, :] = oof\n",
    "    return oof_new\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "class permutation_importance():\n",
    "    def __init__(self, model, metric):\n",
    "        self.is_computed = False\n",
    "        self.n_feat = 0\n",
    "        self.base_score = 0\n",
    "        self.model = model\n",
    "        self.metric = metric\n",
    "        self.df_result = []\n",
    "    \n",
    "    def compute(self, _X_valid, y_valid):\n",
    "        X_valid = pd.DataFrame(_X_valid, columns=FEAT_COLUMNS)\n",
    "        self.n_feat = len(X_valid.columns)\n",
    "        \n",
    "        val_set = MoaDataset(_X_valid, y_valid, mode='train')\n",
    "        dataloaders = {'val': DataLoader(val_set, **settings['loader']['val'])}\n",
    "        y_valid_pred = get_epoch_pred(self.model, device, dataloaders['val'])\n",
    "        \n",
    "        \n",
    "        self.base_score = self.metric(y_valid, y_valid_pred)\n",
    "        self.df_result = pd.DataFrame({'feat': X_valid.columns, \n",
    "                                       'score': np.zeros(self.n_feat),\n",
    "                                       'score_diff': np.zeros(self.n_feat)})\n",
    "        \n",
    "        # predict\n",
    "        for i, col in enumerate(progress_bar(X_valid.columns)):\n",
    "            df_perm = X_valid.copy()\n",
    "            np.random.seed(1)\n",
    "            df_perm[col] = np.random.permutation(df_perm[col])\n",
    "            \n",
    "#             y_valid_pred = self.model.predict(df_perm)\n",
    "            val_set = MoaDataset(df_perm.values, y_valid, mode='train')\n",
    "            dataloaders = {'val': DataLoader(val_set, **settings['loader']['val'])}\n",
    "            y_valid_pred = get_epoch_pred(self.model, device, dataloaders['val'])\n",
    "            \n",
    "            score = self.metric(y_valid, y_valid_pred)\n",
    "            self.df_result['score'][self.df_result['feat']==col] = score\n",
    "            self.df_result['score_diff'][self.df_result['feat']==col] = self.base_score - score\n",
    "        self.is_computed = True\n",
    "    \n",
    "    def get_negative_feature(self):\n",
    "        assert self.is_computed!=False, 'compute メソッドが実行されていません'\n",
    "        idx = self.df_result['score_diff'] < 0\n",
    "        return self.df_result.loc[idx, 'feat'].values.tolist()\n",
    "        \n",
    "    def get_positive_feature(self):\n",
    "        assert self.is_computed!=False, 'compute メソッドが実行されていません'\n",
    "        idx = self.df_result['score_diff'] > 0\n",
    "        return self.df_result.loc[idx, 'feat'].values.tolist()\n",
    "    \n",
    "    def show_permutation_importance(self, score_type='loss'):\n",
    "        '''score_type = 'loss' or 'accuracy'  '''\n",
    "        assert self.is_computed!=False, 'compute メソッドが実行されていません'\n",
    "        if score_type=='loss':\n",
    "            ascending = True\n",
    "        elif score_type=='accuracy':\n",
    "            ascending = False\n",
    "        else:\n",
    "            ascending = ''\n",
    "        \n",
    "        plt.figure(figsize=(15, int(0.25*self.n_feat)))\n",
    "        sns.barplot(x=\"score_diff\", y=\"feat\", data=self.df_result.sort_values(by=\"score_diff\", ascending=ascending))\n",
    "        plt.title('base_score - permutation_score')\n",
    "\n",
    "def get_not_drug_leak_folds(n_splits, train_features, train_drug, gruoup696):\n",
    "    '''\n",
    "    n_splits だけfoldを作成する。\n",
    "    ただし、cp_type = ctl_vehicle と、top8にはfold=-1を割り振っている。\n",
    "    \n",
    "    696group のcsv: https://www.kaggle.com/fkubota/moa-nb004-696group\n",
    "    \n",
    "    ::example::\n",
    "    train_features = pd.read_csv(\"train_features.csv\")\n",
    "    train_drug = pd.read_csv(\"train_drug.csv\")\n",
    "    group696 = pd.read_csv(\"MoA_nb004_696group/group.csv\")\n",
    "    df_fold = get_not_drug_leak_folds(5, train_features, train_drug, group696)\n",
    "    '''\n",
    "    TOP8_DRUG = ['87d714366', '9f80f3f77', '8b87a7a83', '5628cb3ee', 'd08af5d4b', '292ab2c28', 'd50f18348', 'd1b47f29d']\n",
    "    mask_trt = (train_features['cp_type'] == 'trt_cp').values\n",
    "\n",
    "    # mask_top8 を作成\n",
    "    mask_top8 = []\n",
    "    for drug_id in train_drug.drug_id.values:\n",
    "        if drug_id in TOP8_DRUG:\n",
    "            mask_top8.append(True)\n",
    "        else:\n",
    "            mask_top8.append(False)\n",
    "    mask_top8 = np.array(mask_top8)\n",
    "    \n",
    "    # trt かつ top8 以外を抜き出す\n",
    "    # group = 0 は要素数が多いので一番最後にやるようにする\n",
    "    drug_groups = group696[mask_trt & ~mask_top8].group.values\n",
    "    groups = np.sort(group696[mask_trt & ~mask_top8].group.unique())\n",
    "    groups = groups[1:]\n",
    "    groups = np.append(groups, 0)\n",
    "    \n",
    "    # 各グループにfoldを割り振る\n",
    "    tile = []\n",
    "    train_drug_trt = train_drug[mask_trt & ~mask_top8]\n",
    "    train_drug_trt['fold'] = -1\n",
    "    for i_grp, grp in enumerate(groups):\n",
    "        if i_grp == 0:\n",
    "            tile = np.arange(1, n_splits+1).astype(int)\n",
    "\n",
    "        mask_grp = drug_groups == grp\n",
    "        drug_rank = train_drug[mask_trt & ~mask_top8][mask_grp].drug_id.value_counts()\n",
    "\n",
    "        n_repeat = np.ceil(len(drug_rank)/n_splits).astype(int)\n",
    "        folds = np.tile(tile, n_repeat)[:len(drug_rank)]\n",
    "\n",
    "        for i, drug_id in enumerate(drug_rank.index.sort_values()):\n",
    "            mask = train_drug_trt.drug_id.values == drug_id\n",
    "            train_drug_trt.fold[mask] = folds[i]\n",
    "        tile = train_drug_trt.fold.value_counts()[::-1][:n_splits].index\n",
    "        \n",
    "    train_drug_fold = train_drug.copy()\n",
    "    train_drug_fold['fold'] = -1\n",
    "    train_drug_fold['fold'][mask_trt & ~mask_top8] = train_drug_trt.fold.values\n",
    "    return train_drug_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoaModel(nn.Module):\n",
    "    def __init__(self, n_input, n_output):\n",
    "        super(MoaModel, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(n_input)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(n_input, 2048))\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(2048)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.dense2 = nn.utils.weight_norm(nn.Linear(2048, 1048))\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(1048)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "#         self.dense3 = nn.utils.weight_norm(nn.Linear(1048, 206))\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(1048, n_output))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.dense1(x))\n",
    "        \n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.dense2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x_raw = self.dense3(x)\n",
    "        x_sigmoid = F.sigmoid(x_raw)\n",
    "        \n",
    "        return x_sigmoid, x_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoaDataset(Dataset):\n",
    "    def __init__(self, df, targets, mode):\n",
    "        self.mode = mode\n",
    "        self.df = df\n",
    "#         self.targets = targets\n",
    "        if mode=='train':\n",
    "            self.targets = targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == 'train':\n",
    "            return torch.FloatTensor(self.df[idx]), torch.FloatTensor(self.targets[idx])\n",
    "        elif self.mode == 'val':\n",
    "            return torch.FloatTensor(self.df[idx]), 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_log_loss(y_true, y_pred):\n",
    "    metrics = []\n",
    "#     for i in range(y_true.shape[1]):\n",
    "#         metrics.append(log_loss(y_true[:, i], y_pred[:, i].astype(float), labels=[0,1]))\n",
    "#     return np.mean(metrics)\n",
    "    y_true =  y_true.astype(np.float64).ravel()\n",
    "    y_pred =  y_pred.astype(np.float64).ravel()\n",
    "    return log_loss(y_true, y_pred, labels=[0, 1])\n",
    "\n",
    "class SmoothBCEwLogits(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.001):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n",
    "        assert 0 <= smoothing < 1\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1),\n",
    "            self.smoothing)\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets,self.weight)\n",
    "\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"\n",
    "    Early stops the training if validation loss doesn't improve after a given patience.\n",
    "    https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\n",
    "    \"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "#         self.best_state_dict = {}\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "#         if not DEBUG:\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "#         self.best_state_dict = model.state_dict()\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, device, train_loader, optimizer, scheduler, criterion):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(True):\n",
    "            pred_sigmoid, pred_raw = model(x)\n",
    "            loss = criterion(pred_raw, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        running_loss += loss.item() / len(train_loader)\n",
    "    scheduler.step()\n",
    "    return running_loss\n",
    "\n",
    "def get_epoch_loss_score(model, device, valid_loader, criterion, optimizer):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    targets = []\n",
    "    preds = []\n",
    "    for i, (x, y) in enumerate(valid_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(False):\n",
    "            pred_sigmoid, pred_raw = model(x)\n",
    "            loss = criterion(pred_raw, y)\n",
    "        running_loss += loss.item() / len(valid_loader)\n",
    "        targets.append(y)\n",
    "        preds.append(pred_sigmoid)\n",
    "    targets = torch.cat(targets, dim=0).cpu().numpy()\n",
    "    preds = torch.cat(preds, dim=0).cpu().numpy()\n",
    "    _mean_log_loss = mean_log_loss(targets, preds)\n",
    "    return running_loss, _mean_log_loss, preds\n",
    "\n",
    "def get_epoch_pred(model, device, valid_loader):\n",
    "    model.eval()\n",
    "    targets = []\n",
    "    preds = []\n",
    "    for i, (x, y) in enumerate(valid_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        with torch.set_grad_enabled(False):\n",
    "            pred_sigmoid, pred_raw = model(x)\n",
    "        targets.append(y)\n",
    "        preds.append(pred_sigmoid)\n",
    "    targets = torch.cat(targets, dim=0).cpu().numpy()\n",
    "    preds = torch.cat(preds, dim=0).cpu().numpy()\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fold(dataloaders, shape, checkpoint_path, ModelClass, show_log=True):\n",
    "    device = torch.device(\"cuda\")\n",
    "    model = ModelClass(shape[0], shape[1]).to(device)\n",
    "#     model = ModelClass(train.shape[1], ).to(device)\n",
    "    early_stopping = EarlyStopping(patience=15, verbose=show_log, path=checkpoint_path)\n",
    "    optimizer = optim.__getattribute__(settings['optimizer']['name'])(\n",
    "        model.parameters(), **settings['optimizer']['params'])\n",
    "    scheduler = optim.lr_scheduler.__getattribute__(settings['scheduler']['name'])(\n",
    "        optimizer, **settings['scheduler']['params'])\n",
    "    \n",
    "    best_valid_loss = np.inf\n",
    "    best_mean_log_loss = np.inf\n",
    "    best_preds = 0\n",
    "    val_losses = []\n",
    "    trn_losses = []\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss =  train_model(model, device, dataloaders['train'], optimizer, scheduler, criterion)\n",
    "        valid_loss, _mean_log_loss, preds = get_epoch_loss_score(model, device, dataloaders['val'], criterion, optimizer)\n",
    "\n",
    "        trn_losses.append(train_loss)\n",
    "        val_losses.append(valid_loss)\n",
    "        if show_log:\n",
    "            print(f\"Epoch {str(epoch+1).zfill(2)}/{n_epochs }   loss: {train_loss:5.5f}   val_loss: {valid_loss:5.5f}   mean_log_loss: {_mean_log_loss:5.5f}\")\n",
    "        early_stopping(valid_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "        if valid_loss < best_valid_loss: \n",
    "            best_valid_loss = valid_loss\n",
    "            best_mean_log_loss = _mean_log_loss\n",
    "            best_preds = preds\n",
    "    return best_mean_log_loss, best_preds, trn_losses, val_losses\n",
    "\n",
    "def run(splitter, train, targets, ModelClass, show_log=True, pi=False):\n",
    "    mean_log_loss_list = []\n",
    "    oof = np.zeros_like(targets).astype(float)\n",
    "    df_pi = pd.DataFrame(columns=['feat', 'score_diff'])\n",
    "    for n, (idx_trn, idx_val) in enumerate(splitter.split(train, targets)):\n",
    "        print('-'*100)\n",
    "        print(f':: start fold {n+1}/{n_splits} at {time.ctime()} ::')\n",
    "        print('-'*100)\n",
    "        X_trn, X_val = train[idx_trn], train[idx_val]\n",
    "        y_trn, y_val = targets[idx_trn], targets[idx_val]\n",
    "\n",
    "        train_set = MoaDataset(X_trn, y_trn, mode='train')\n",
    "        val_set = MoaDataset(X_val, y_val, mode='train')\n",
    "\n",
    "        dataloaders = {\n",
    "            'train': DataLoader(train_set, **settings['loader']['train']),\n",
    "            'val': DataLoader(val_set, **settings['loader']['val']),\n",
    "        }\n",
    "\n",
    "        checkpoint_path = f'{SAVE_DIR}Fold{n+1}of{n_splits}.pt'\n",
    "        shape = (X_trn.shape[1], y_trn.shape[1])\n",
    "        best_mean_log_loss, best_preds, trn_losses, val_losses =  run_fold(dataloaders, shape, checkpoint_path, ModelClass, show_log=show_log)\n",
    "\n",
    "        # result\n",
    "        print(f':: best mean_log_loss: {best_mean_log_loss:5.5f} ::')\n",
    "        mean_log_loss_list.append(best_mean_log_loss)\n",
    "        oof[idx_val, :] = best_preds\n",
    "        \n",
    "        # permutation importance\n",
    "        if pi:\n",
    "            device = torch.device(\"cuda\")\n",
    "            model = ModelClass(shape[0], shape[1]).to(device)\n",
    "            state_dict = torch.load(checkpoint_path)\n",
    "            model.load_state_dict(state_dict)\n",
    "            model.to(device)\n",
    "            model.eval()\n",
    "            pi = permutation_importance(model, mean_log_loss) # model と metric を渡す\n",
    "            pi.compute(X_val, y_val)\n",
    "            pi_result = pi.df_result\n",
    "            df_pi = pd.concat([df_pi, pi_result[['feat', 'score_diff']]])\n",
    "    #         pi.show_permutation_importance(score_type='loss')\n",
    "        \n",
    "        # plot\n",
    "        if show_log:\n",
    "            x = np.arange(1, len(trn_losses)+1)\n",
    "            plt.figure(figsize=(12, 7))\n",
    "            plt.plot(x[1:], trn_losses[1:], '--.', label='train')\n",
    "            plt.plot(x[1:], val_losses[1:], '--.', label='valid')\n",
    "            plt.title(f\"fold{n+1}/{n_splits} {settings['loss']['name']}\")\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        print('\\n')\n",
    "    \n",
    "    if pi:\n",
    "        # permutation score\n",
    "        plt.figure(figsize=(15, int(0.25*len(FEAT_COLUMNS))))\n",
    "        order = df_pi.groupby([\"feat\"]).mean()['score_diff'].reset_index().sort_values('score_diff', ascending=True)\n",
    "        sns.barplot(x=\"score_diff\", y=\"feat\", data=df_pi, order=order['feat'])\n",
    "        plt.title('base_score - permutation_score')\n",
    "        plt.show()\n",
    "    return mean_log_loss_list, oof, df_pi\n",
    "\n",
    "def run_not_drug_leak(df_fold, train, targets, ModelClass, show_log=True, pi=False):\n",
    "    mean_log_loss_list = []\n",
    "    oof = np.zeros_like(targets).astype(float)\n",
    "    df_pi = pd.DataFrame(columns=['feat', 'score_diff'])\n",
    "#     for n, (idx_trn, idx_val) in enumerate(splitter.split(train, targets)):\n",
    "    for n, fold_i in enumerate(df_fold['fold'].unique()):\n",
    "        print('-'*100)\n",
    "        print(f':: start fold {n+1}/{n_splits} at {time.ctime()} ::')\n",
    "        print('-'*100)\n",
    "        mask_fold = df_fold.fold == fold_i\n",
    "        X_trn, X_val = train[~mask_fold], train[mask_fold]\n",
    "        y_trn, y_val = targets[~mask_fold], targets[mask_fold]\n",
    "\n",
    "        train_set = MoaDataset(X_trn, y_trn, mode='train')\n",
    "        val_set = MoaDataset(X_val, y_val, mode='train')\n",
    "\n",
    "        dataloaders = {\n",
    "            'train': DataLoader(train_set, **settings['loader']['train']),\n",
    "            'val': DataLoader(val_set, **settings['loader']['val']),\n",
    "        }\n",
    "\n",
    "        checkpoint_path = f'{SAVE_DIR}Fold{n+1}of{n_splits}.pt'\n",
    "        shape = (X_trn.shape[1], y_trn.shape[1])\n",
    "        best_mean_log_loss, best_preds, trn_losses, val_losses =  run_fold(dataloaders, shape, checkpoint_path, ModelClass, show_log=show_log)\n",
    "\n",
    "        # result\n",
    "        print(f':: best mean_log_loss: {best_mean_log_loss:5.5f} ::')\n",
    "        mean_log_loss_list.append(best_mean_log_loss)\n",
    "#         oof[idx_val, :] = best_preds\n",
    "        oof[mask_fold, :] = best_preds\n",
    "        \n",
    "        # permutation importance\n",
    "        if pi:\n",
    "            device = torch.device(\"cuda\")\n",
    "            model = ModelClass(shape[0], shape[1]).to(device)\n",
    "            state_dict = torch.load(checkpoint_path)\n",
    "            model.load_state_dict(state_dict)\n",
    "            model.to(device)\n",
    "            model.eval()\n",
    "            pi = permutation_importance(model, mean_log_loss) # model と metric を渡す\n",
    "            pi.compute(X_val, y_val)\n",
    "            pi_result = pi.df_result\n",
    "            df_pi = pd.concat([df_pi, pi_result[['feat', 'score_diff']]])\n",
    "    #         pi.show_permutation_importance(score_type='loss')\n",
    "        \n",
    "        # plot\n",
    "        if show_log:\n",
    "            x = np.arange(1, len(trn_losses)+1)\n",
    "            plt.figure(figsize=(12, 7))\n",
    "            plt.plot(x[1:], trn_losses[1:], '--.', label='train')\n",
    "            plt.plot(x[1:], val_losses[1:], '--.', label='valid')\n",
    "            plt.title(f\"fold{n+1}/{n_splits} {settings['loss']['name']}\")\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        print('\\n')\n",
    "    \n",
    "    if pi:\n",
    "        # permutation score\n",
    "        plt.figure(figsize=(15, int(0.25*len(FEAT_COLUMNS))))\n",
    "        order = df_pi.groupby([\"feat\"]).mean()['score_diff'].reset_index().sort_values('score_diff', ascending=True)\n",
    "        sns.barplot(x=\"score_diff\", y=\"feat\", data=df_pi, order=order['feat'])\n",
    "        plt.title('base_score - permutation_score')\n",
    "        plt.show()\n",
    "    return mean_log_loss_list, oof, df_pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = yaml.safe_load(settings_str)\n",
    "seed_everything(settings['globals']['seed'])\n",
    "sns.set()\n",
    "sns.set_context('talk')\n",
    "\n",
    "if not os.path.exists(SAVE_DIR):\n",
    "    os.makedirs(SAVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    settings['split']['params']['n_splits'] = 2\n",
    "    settings['globals']['num_epochs'] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv(PATH_TRAIN)\n",
    "train_targets = pd.read_csv(PATH_TRAIN_SCORED)\n",
    "# test_features = pd.read_csv(PATH_TEST)\n",
    "train_drug = pd.read_csv(PATH_DRUGID)\n",
    "group696 = pd.read_csv(PATH_GROUP696)\n",
    "\n",
    "# ss = pd.read_csv(PATH_SUB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_top8 を作成\n",
    "mask_top8 = []\n",
    "for drug_id in train_drug.drug_id.values:\n",
    "    if drug_id in TOP8_DRUG:\n",
    "        mask_top8.append(True)\n",
    "    else:\n",
    "        mask_top8.append(False)\n",
    "mask_top8 = np.array(mask_top8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_col = 10\n",
    "step_row = 11\n",
    "\n",
    "if DEBUG:\n",
    "    print(':: debug mode ::')\n",
    "    train_features = train_features.iloc[::step_row, :end_col].reset_index(drop=True)\n",
    "    train_targets = train_targets.iloc[::step_row, :].reset_index(drop=True)\n",
    "    mask_top8 = mask_top8[::step_row]\n",
    "    train_drug = train_drug.iloc[::step_row, :].reset_index(drop=True)\n",
    "    group696 = group696.iloc[::step_row, :].reset_index(drop=True)\n",
    "#     test_features = test_features.iloc[::100, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_trt = (train_features['cp_type'] == 'trt_cp').values\n",
    "train = preprocess(train_features)\n",
    "FEAT_COLUMNS = train_features.columns[2:]\n",
    "# test = preprocess(test_features).values\n",
    "\n",
    "del train_targets['sig_id']\n",
    "\n",
    "target_cols = [col for col in train_targets.columns]\n",
    "train, targets = remove_ctl_cp(train, train_targets)\n",
    "# train_targets = train_targets.loc[train['cp_type']==0].reset_index(drop=True).values\n",
    "# train = train.loc[train['cp_type']==0].reset_index(drop=True).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:         (21948, 874)\n",
      "train_targets shape: (21948, 206)\n"
     ]
    }
   ],
   "source": [
    "print(f'train shape:         {train.shape}')\n",
    "# print(f'test shape:          {test.shape}')\n",
    "print(f'train_targets shape: {targets.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "fold分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.49 s, sys: 318 µs, total: 6.49 s\n",
      "Wall time: 6.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_fold = get_not_drug_leak_folds(settings['split']['params']['n_splits'], train_features, train_drug, group696)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5  3  1  2  4 -1]\n",
      "[5 3 1 2 4]\n"
     ]
    }
   ],
   "source": [
    "splitter = KFold(n_splits=settings['split']['params']['n_splits'], random_state=1, shuffle=True)\n",
    "for top8_i in range(len(TOP8_DRUG)):\n",
    "    mask_drug = df_fold['drug_id'] == TOP8_DRUG[top8_i]\n",
    "\n",
    "    for fold_i, (train_idx, valid_idx) in enumerate(splitter.split(df_fold[mask_drug])):\n",
    "#         df_fold[['fold']][mask_drug].iloc[valid_idx, :] = fold_i + 1\n",
    "#         df_fold[['fold']][mask_drug] = fold_i + 1\n",
    "        _df_fold = df_fold[mask_drug]\n",
    "        _df_fold.fold.values[valid_idx] = fold_i + 1\n",
    "        df_fold.fold[mask_drug] = _df_fold.fold.values\n",
    "print(df_fold.fold.unique())\n",
    "print(df_fold[mask_trt].fold.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "top8の除去"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[~mask_top8[mask_trt]]\n",
    "targets = targets[~mask_top8[mask_trt]]\n",
    "df_fold = df_fold[mask_trt & ~mask_top8].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = settings['split']['params']['n_splits']\n",
    "n_epochs = settings['globals']['num_epochs']\n",
    "splitter = MultilabelStratifiedKFold(**settings['split']['params'])\n",
    "device = settings['globals']['device']\n",
    "# criterion = criterion_ = nn.__getattribute__(\n",
    "#     settings['loss']['name'])(**settings['loss']['params'])\n",
    "criterion = SmoothBCEwLogits(**settings['loss']['params'], smoothing=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 1.00000000e-05, 1.32035178e-05, 1.74332882e-05,\n",
       "       2.30180731e-05, 3.03919538e-05, 4.01280703e-05, 5.29831691e-05,\n",
       "       6.99564216e-05, 9.23670857e-05, 1.21957046e-04, 1.61026203e-04,\n",
       "       2.12611233e-04, 2.80721620e-04, 3.70651291e-04, 4.89390092e-04,\n",
       "       6.46167079e-04, 8.53167852e-04, 1.12648169e-03, 1.48735211e-03,\n",
       "       1.96382800e-03, 2.59294380e-03, 3.42359796e-03, 4.52035366e-03,\n",
       "       5.96845700e-03, 7.88046282e-03, 1.04049831e-02, 1.37382380e-02,\n",
       "       1.81393069e-02, 2.39502662e-02, 3.16227766e-02])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_logspace = 30\n",
    "logspace = np.logspace(-5, -1.5, n_logspace)\n",
    "logspace = np.hstack((np.array([0]), logspace))\n",
    "logspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='31' class='' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [31/31 2:33:51<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smoothing: 0.0\n",
      "save: ../data_ignore/output_nb/nb022/oof_smoothing_0.000000.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Sun Nov 22 01:05:35 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01897 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Sun Nov 22 01:06:35 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02028 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Sun Nov 22 01:07:35 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01884 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Sun Nov 22 01:08:35 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02127 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Sun Nov 22 01:09:30 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01914 ::\n",
      "\n",
      "\n",
      "smoothing: 1e-05\n",
      "save: ../data_ignore/output_nb/nb022/oof_smoothing_0.000010.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Sun Nov 22 01:10:35 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01895 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Sun Nov 22 01:11:35 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02027 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Sun Nov 22 01:12:35 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01882 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Sun Nov 22 01:13:35 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02141 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Sun Nov 22 01:14:23 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01919 ::\n",
      "\n",
      "\n",
      "smoothing: 1.3203517797162949e-05\n",
      "save: ../data_ignore/output_nb/nb022/oof_smoothing_0.000013.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Sun Nov 22 01:15:31 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01890 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Sun Nov 22 01:16:30 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02027 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Sun Nov 22 01:17:29 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01886 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Sun Nov 22 01:18:29 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02125 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Sun Nov 22 01:19:28 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01922 ::\n",
      "\n",
      "\n",
      "smoothing: 1.7433288221999873e-05\n",
      "save: ../data_ignore/output_nb/nb022/oof_smoothing_0.000017.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Sun Nov 22 01:20:35 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01891 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Sun Nov 22 01:21:35 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02024 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Sun Nov 22 01:22:35 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01878 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Sun Nov 22 01:23:35 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02127 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Sun Nov 22 01:24:34 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01916 ::\n",
      "\n",
      "\n",
      "smoothing: 2.3018073130224653e-05\n",
      "save: ../data_ignore/output_nb/nb022/oof_smoothing_0.000023.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Sun Nov 22 01:25:41 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01896 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Sun Nov 22 01:26:37 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02029 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Sun Nov 22 01:27:37 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01890 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Sun Nov 22 01:28:37 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02123 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Sun Nov 22 01:29:36 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01918 ::\n",
      "\n",
      "\n",
      "smoothing: 3.039195382313195e-05\n",
      "save: ../data_ignore/output_nb/nb022/oof_smoothing_0.000030.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Sun Nov 22 01:30:42 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01891 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Sun Nov 22 01:31:39 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02024 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Sun Nov 22 01:32:35 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01886 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Sun Nov 22 01:33:36 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02121 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Sun Nov 22 01:34:37 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01908 ::\n",
      "\n",
      "\n",
      "smoothing: 4.0128070319427804e-05\n",
      "save: ../data_ignore/output_nb/nb022/oof_smoothing_0.000040.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Sun Nov 22 01:35:41 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01902 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Sun Nov 22 01:36:41 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02020 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Sun Nov 22 01:37:38 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01884 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Sun Nov 22 01:38:38 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02129 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Sun Nov 22 01:39:37 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01915 ::\n",
      "\n",
      "\n",
      "smoothing: 5.2983169062837125e-05\n",
      "save: ../data_ignore/output_nb/nb022/oof_smoothing_0.000053.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Sun Nov 22 01:40:44 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01894 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Sun Nov 22 01:41:44 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02023 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Sun Nov 22 01:42:43 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01881 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Sun Nov 22 01:43:44 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02125 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Sun Nov 22 01:44:43 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01914 ::\n",
      "\n",
      "\n",
      "smoothing: 6.995642156712633e-05\n",
      "save: ../data_ignore/output_nb/nb022/oof_smoothing_0.000070.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Sun Nov 22 01:45:50 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01894 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Sun Nov 22 01:46:49 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02022 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Sun Nov 22 01:47:44 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01879 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Sun Nov 22 01:48:44 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02115 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Sun Nov 22 01:49:36 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01917 ::\n",
      "\n",
      "\n",
      "smoothing: 9.236708571873866e-05\n",
      "save: ../data_ignore/output_nb/nb022/oof_smoothing_0.000092.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Sun Nov 22 01:50:42 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01892 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Sun Nov 22 01:51:40 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02026 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Sun Nov 22 01:52:39 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01883 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Sun Nov 22 01:53:39 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02127 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Sun Nov 22 01:54:38 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01915 ::\n",
      "\n",
      "\n",
      "smoothing: 0.00012195704601594415\n",
      "save: ../data_ignore/output_nb/nb022/oof_smoothing_0.000122.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Sun Nov 22 01:55:45 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01888 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Sun Nov 22 01:56:45 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02024 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Sun Nov 22 01:57:42 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01880 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Sun Nov 22 01:58:41 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02139 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Sun Nov 22 01:59:35 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01914 ::\n",
      "\n",
      "\n",
      "smoothing: 0.00016102620275609394\n",
      "save: ../data_ignore/output_nb/nb022/oof_smoothing_0.000161.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Sun Nov 22 02:00:42 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01893 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Sun Nov 22 02:01:39 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02024 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Sun Nov 22 02:02:38 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01889 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Sun Nov 22 02:03:38 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02111 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Sun Nov 22 02:04:37 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01918 ::\n",
      "\n",
      "\n",
      "smoothing: 0.00021261123338996556\n",
      "save: ../data_ignore/output_nb/nb022/oof_smoothing_0.000213.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Sun Nov 22 02:05:42 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01889 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Sun Nov 22 02:06:41 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02027 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Sun Nov 22 02:07:43 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01884 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Sun Nov 22 02:08:43 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02110 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Sun Nov 22 02:09:43 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01919 ::\n",
      "\n",
      "\n",
      "smoothing: 0.0002807216203941176\n",
      "save: ../data_ignore/output_nb/nb022/oof_smoothing_0.000281.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Sun Nov 22 02:10:50 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01890 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Sun Nov 22 02:11:50 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02021 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Sun Nov 22 02:12:49 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01886 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Sun Nov 22 02:13:48 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02124 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Sun Nov 22 02:14:47 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01906 ::\n",
      "\n",
      "\n",
      "smoothing: 0.00037065129109221565\n",
      "save: ../data_ignore/output_nb/nb022/oof_smoothing_0.000371.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Sun Nov 22 02:15:52 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01888 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Sun Nov 22 02:16:51 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02030 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Sun Nov 22 02:17:50 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01881 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Sun Nov 22 02:18:50 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02121 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Sun Nov 22 02:19:48 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01918 ::\n",
      "\n",
      "\n",
      "smoothing: 0.0004893900918477494\n",
      "save: ../data_ignore/output_nb/nb022/oof_smoothing_0.000489.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Sun Nov 22 02:20:55 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01892 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Sun Nov 22 02:21:54 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02022 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Sun Nov 22 02:22:54 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01883 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Sun Nov 22 02:23:53 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02124 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Sun Nov 22 02:24:42 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01910 ::\n",
      "\n",
      "\n",
      "smoothing: 0.0006461670787466976\n",
      "save: ../data_ignore/output_nb/nb022/oof_smoothing_0.000646.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Sun Nov 22 02:25:49 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01889 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Sun Nov 22 02:26:48 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02019 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Sun Nov 22 02:27:47 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01884 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Sun Nov 22 02:28:44 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02113 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Sun Nov 22 02:29:43 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01906 ::\n",
      "\n",
      "\n",
      "smoothing: 0.0008531678524172815\n",
      "save: ../data_ignore/output_nb/nb022/oof_smoothing_0.000853.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Sun Nov 22 02:30:49 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01898 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Sun Nov 22 02:31:44 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02017 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Sun Nov 22 02:32:44 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01883 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Sun Nov 22 02:33:43 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02108 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Sun Nov 22 02:34:37 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01904 ::\n",
      "\n",
      "\n",
      "smoothing: 0.0011264816923358867\n",
      "save: ../data_ignore/output_nb/nb022/oof_smoothing_0.001126.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Sun Nov 22 02:35:42 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01898 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Sun Nov 22 02:36:41 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02013 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Sun Nov 22 02:37:41 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01887 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Sun Nov 22 02:38:41 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02117 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Sun Nov 22 02:39:40 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01913 ::\n",
      "\n",
      "\n",
      "smoothing: 0.0014873521072935117\n",
      "save: ../data_ignore/output_nb/nb022/oof_smoothing_0.001487.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Sun Nov 22 02:40:47 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01900 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Sun Nov 22 02:41:46 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02014 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Sun Nov 22 02:42:45 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01887 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Sun Nov 22 02:43:44 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02115 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Sun Nov 22 02:44:43 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01914 ::\n",
      "\n",
      "\n",
      "smoothing: 0.00196382800192977\n",
      "save: ../data_ignore/output_nb/nb022/oof_smoothing_0.001964.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Sun Nov 22 02:45:50 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01897 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Sun Nov 22 02:46:49 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02025 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Sun Nov 22 02:47:46 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01893 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Sun Nov 22 02:48:45 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02099 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Sun Nov 22 02:49:44 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01919 ::\n",
      "\n",
      "\n",
      "smoothing: 0.002592943797404667\n",
      "save: ../data_ignore/output_nb/nb022/oof_smoothing_0.002593.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Sun Nov 22 02:50:51 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01917 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Sun Nov 22 02:51:50 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02036 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Sun Nov 22 02:52:50 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01908 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Sun Nov 22 02:53:49 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02117 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Sun Nov 22 02:54:48 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01924 ::\n",
      "\n",
      "\n",
      "smoothing: 0.0034235979576075835\n",
      "save: ../data_ignore/output_nb/nb022/oof_smoothing_0.003424.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Sun Nov 22 02:55:54 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01928 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Sun Nov 22 02:56:50 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02066 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Sun Nov 22 02:57:50 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01917 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Sun Nov 22 02:58:49 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02117 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Sun Nov 22 02:59:47 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01935 ::\n",
      "\n",
      "\n",
      "smoothing: 0.004520353656360245\n",
      "save: ../data_ignore/output_nb/nb022/oof_smoothing_0.004520.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Sun Nov 22 03:00:53 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01962 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Sun Nov 22 03:01:52 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02080 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Sun Nov 22 03:02:52 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01948 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Sun Nov 22 03:03:51 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02126 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Sun Nov 22 03:04:49 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.01976 ::\n",
      "\n",
      "\n",
      "smoothing: 0.0059684569951223105\n",
      "save: ../data_ignore/output_nb/nb022/oof_smoothing_0.005968.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Sun Nov 22 03:05:55 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02000 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Sun Nov 22 03:06:49 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02093 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Sun Nov 22 03:07:48 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01997 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Sun Nov 22 03:08:45 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02139 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Sun Nov 22 03:09:43 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02009 ::\n",
      "\n",
      "\n",
      "smoothing: 0.007880462815669913\n",
      "save: ../data_ignore/output_nb/nb022/oof_smoothing_0.007880.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Sun Nov 22 03:10:50 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02057 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Sun Nov 22 03:11:51 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02167 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Sun Nov 22 03:12:48 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02027 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Sun Nov 22 03:13:47 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02193 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Sun Nov 22 03:14:45 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02073 ::\n",
      "\n",
      "\n",
      "smoothing: 0.010404983103657853\n",
      "save: ../data_ignore/output_nb/nb022/oof_smoothing_0.010405.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Sun Nov 22 03:15:51 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02213 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Sun Nov 22 03:16:21 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02223 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Sun Nov 22 03:17:20 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02121 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Sun Nov 22 03:18:19 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02261 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Sun Nov 22 03:19:18 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02157 ::\n",
      "\n",
      "\n",
      "smoothing: 0.013738237958832637\n",
      "save: ../data_ignore/output_nb/nb022/oof_smoothing_0.013738.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Sun Nov 22 03:20:25 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02208 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Sun Nov 22 03:21:24 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02334 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Sun Nov 22 03:22:23 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02329 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Sun Nov 22 03:22:51 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02378 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Sun Nov 22 03:23:51 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02221 ::\n",
      "\n",
      "\n",
      "smoothing: 0.01813930693911063\n",
      "save: ../data_ignore/output_nb/nb022/oof_smoothing_0.018139.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Sun Nov 22 03:24:56 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02455 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Sun Nov 22 03:25:55 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02571 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Sun Nov 22 03:26:54 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02466 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Sun Nov 22 03:27:53 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02568 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Sun Nov 22 03:28:19 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02424 ::\n",
      "\n",
      "\n",
      "smoothing: 0.02395026619987486\n",
      "save: ../data_ignore/output_nb/nb022/oof_smoothing_0.023950.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Sun Nov 22 03:29:25 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02654 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Sun Nov 22 03:30:23 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02763 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Sun Nov 22 03:31:22 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02641 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Sun Nov 22 03:32:21 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02817 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Sun Nov 22 03:33:19 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02679 ::\n",
      "\n",
      "\n",
      "smoothing: 0.03162277660168379\n",
      "save: ../data_ignore/output_nb/nb022/oof_smoothing_0.031623.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Sun Nov 22 03:34:25 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.03028 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Sun Nov 22 03:35:24 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.03080 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Sun Nov 22 03:36:23 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02987 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Sun Nov 22 03:37:22 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.03099 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Sun Nov 22 03:38:21 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: best mean_log_loss: 0.02977 ::\n",
      "\n",
      "\n",
      "CPU times: user 40min 13s, sys: 1h 38min 44s, total: 2h 18min 57s\n",
      "Wall time: 2h 33min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# mean_log_loss_list, _oof, df_pi = run(splitter, train, targets, MoaModel, show_log=isShowLog, pi=isPI)\n",
    "list_oof_score = []\n",
    "for smooth in progress_bar(logspace):\n",
    "    print(f'smoothing: {smooth}')\n",
    "    save_path = f'{SAVE_DIR}oof_smoothing_{smooth:.6f}.csv'\n",
    "    print(f'save: {save_path}')\n",
    "    \n",
    "    criterion = SmoothBCEwLogits(**settings['loss']['params'], smoothing=smooth)\n",
    "    mean_log_loss_list, _oof, df_pi = run_not_drug_leak(df_fold, train, targets, MoaModel,\n",
    "                                                        show_log=isShowLog, pi=isPI)\n",
    "    oof_score = mean_log_loss(targets, _oof)\n",
    "    list_oof_score.append(oof_score)\n",
    "    \n",
    "    # save oof\n",
    "    df_oof = pd.DataFrame(_oof, columns=target_cols)\n",
    "    df_oof.to_csv(save_path, index=False)\n",
    "\n",
    "df_smooth = pd.DataFrame()\n",
    "df_smooth['smooth'] = logspace\n",
    "df_smooth['oof_score'] = list_oof_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smooth</th>\n",
       "      <th>oof_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.019729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.019702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.019672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.019712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.019662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.019701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.019673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.019653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.019686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.019690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.019669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.019659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.019655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.019676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.019661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000646</td>\n",
       "      <td>0.019624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000853</td>\n",
       "      <td>0.019619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.001126</td>\n",
       "      <td>0.019655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.001487</td>\n",
       "      <td>0.019660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.001964</td>\n",
       "      <td>0.019664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.002593</td>\n",
       "      <td>0.019804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.003424</td>\n",
       "      <td>0.019925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.004520</td>\n",
       "      <td>0.020185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.005968</td>\n",
       "      <td>0.020477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.007880</td>\n",
       "      <td>0.021032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.010405</td>\n",
       "      <td>0.021950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.013738</td>\n",
       "      <td>0.022940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.018139</td>\n",
       "      <td>0.024967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.023950</td>\n",
       "      <td>0.027109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.031623</td>\n",
       "      <td>0.030345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      smooth  oof_score\n",
       "0   0.000000   0.019697\n",
       "1   0.000010   0.019729\n",
       "2   0.000013   0.019702\n",
       "3   0.000017   0.019672\n",
       "4   0.000023   0.019712\n",
       "5   0.000030   0.019662\n",
       "6   0.000040   0.019701\n",
       "7   0.000053   0.019673\n",
       "8   0.000070   0.019653\n",
       "9   0.000092   0.019686\n",
       "10  0.000122   0.019690\n",
       "11  0.000161   0.019669\n",
       "12  0.000213   0.019659\n",
       "13  0.000281   0.019655\n",
       "14  0.000371   0.019676\n",
       "15  0.000489   0.019661\n",
       "16  0.000646   0.019624\n",
       "17  0.000853   0.019619\n",
       "18  0.001126   0.019655\n",
       "19  0.001487   0.019660\n",
       "20  0.001964   0.019664\n",
       "21  0.002593   0.019804\n",
       "22  0.003424   0.019925\n",
       "23  0.004520   0.020185\n",
       "24  0.005968   0.020477\n",
       "25  0.007880   0.021032\n",
       "26  0.010405   0.021950\n",
       "27  0.013738   0.022940\n",
       "28  0.018139   0.024967\n",
       "29  0.023950   0.027109\n",
       "30  0.031623   0.030345"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smooth</th>\n",
       "      <th>oof_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.019729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.019702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.019672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.019712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.019662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.019701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.019673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.019653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.019686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.019690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.019669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.019659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.019655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.019676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.019661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000646</td>\n",
       "      <td>0.019624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000853</td>\n",
       "      <td>0.019619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.001126</td>\n",
       "      <td>0.019655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.001487</td>\n",
       "      <td>0.019660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.001964</td>\n",
       "      <td>0.019664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.002593</td>\n",
       "      <td>0.019804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.003424</td>\n",
       "      <td>0.019925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.004520</td>\n",
       "      <td>0.020185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.005968</td>\n",
       "      <td>0.020477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.007880</td>\n",
       "      <td>0.021032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.010405</td>\n",
       "      <td>0.021950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.013738</td>\n",
       "      <td>0.022940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.018139</td>\n",
       "      <td>0.024967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.023950</td>\n",
       "      <td>0.027109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.031623</td>\n",
       "      <td>0.030345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      smooth  oof_score\n",
       "0   0.000000   0.019697\n",
       "1   0.000010   0.019729\n",
       "2   0.000013   0.019702\n",
       "3   0.000017   0.019672\n",
       "4   0.000023   0.019712\n",
       "5   0.000030   0.019662\n",
       "6   0.000040   0.019701\n",
       "7   0.000053   0.019673\n",
       "8   0.000070   0.019653\n",
       "9   0.000092   0.019686\n",
       "10  0.000122   0.019690\n",
       "11  0.000161   0.019669\n",
       "12  0.000213   0.019659\n",
       "13  0.000281   0.019655\n",
       "14  0.000371   0.019676\n",
       "15  0.000489   0.019661\n",
       "16  0.000646   0.019624\n",
       "17  0.000853   0.019619\n",
       "18  0.001126   0.019655\n",
       "19  0.001487   0.019660\n",
       "20  0.001964   0.019664\n",
       "21  0.002593   0.019804\n",
       "22  0.003424   0.019925\n",
       "23  0.004520   0.020185\n",
       "24  0.005968   0.020477\n",
       "25  0.007880   0.021032\n",
       "26  0.010405   0.021950\n",
       "27  0.013738   0.022940\n",
       "28  0.018139   0.024967\n",
       "29  0.023950   0.027109\n",
       "30  0.031623   0.030345"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe09aeb5f60>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.axhline(df_smooth.oof_score[1], color='r', label='smooth=0')\n",
    "plt.plot(df_smooth.smooth[1:], df_smooth.oof_score[1:], '.', label=None)\n",
    "plt.xscale('log')\n",
    "plt.xlabel('smoothing')\n",
    "plt.ylabel('oof_score')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe0833a58d0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.axhline(df_smooth.oof_score[1], color='r', label='smooth=0')\n",
    "plt.plot(df_smooth.smooth[1:22], df_smooth.oof_score[1:22], '.', label=None)\n",
    "plt.xscale('log')\n",
    "plt.xlabel('smoothing')\n",
    "plt.ylabel('oof_score')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0008531678524172815"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = df_smooth.oof_score.argmin()\n",
    "df_smooth.smooth[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                        ￥0.0\n",
       "1                      ￥1e-05\n",
       "3     ￥1.7433288221999873e-05\n",
       "4     ￥2.3018073130224653e-05\n",
       "5      ￥3.039195382313195e-05\n",
       "6     ￥4.0128070319427804e-05\n",
       "7     ￥5.2983169062837125e-05\n",
       "8      ￥6.995642156712633e-05\n",
       "9      ￥9.236708571873866e-05\n",
       "10    ￥0.00012195704601594415\n",
       "11    ￥0.00016102620275609394\n",
       "12    ￥0.00021261123338996556\n",
       "13     ￥0.0002807216203941176\n",
       "14    ￥0.00037065129109221565\n",
       "15     ￥0.0004893900918477494\n",
       "16     ￥0.0006461670787466976\n",
       "17     ￥0.0008531678524172815\n",
       "18     ￥0.0011264816923358867\n",
       "19     ￥0.0014873521072935117\n",
       "20       ￥0.00196382800192977\n",
       "21      ￥0.002592943797404667\n",
       "22     ￥0.0034235979576075835\n",
       "23      ￥0.004520353656360245\n",
       "24     ￥0.0059684569951223105\n",
       "25      ￥0.007880462815669913\n",
       "26      ￥0.010404983103657853\n",
       "27      ￥0.013738237958832637\n",
       "28       ￥0.01813930693911063\n",
       "29       ￥0.02395026619987486\n",
       "30       ￥0.03162277660168379\n",
       "Name: smooth, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = df_smooth.index != 2\n",
    "df_smooth[mask].smooth.apply('￥{:,}'.format)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
