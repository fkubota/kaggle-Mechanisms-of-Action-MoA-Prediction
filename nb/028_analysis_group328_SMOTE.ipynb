{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "- 696Group単位でSMOTEを行なう\n",
    "- top8を除く\n",
    "- ctrlを除く"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "020e1cf\n"
     ]
    }
   ],
   "source": [
    "# gitのhash\n",
    "import subprocess\n",
    "cmd = \"git rev-parse --short HEAD\"\n",
    "hash = subprocess.check_output(cmd.split()).strip().decode('utf-8')\n",
    "print(hash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic\n",
    "NB = '027'\n",
    "DEBUG = False \n",
    "isPI = False\n",
    "isShowLog = False\n",
    "MIXUP = True\n",
    "\n",
    "PATH_TRAIN = '../data_ignore/input/train_features.csv'\n",
    "PATH_TRAIN_SCORED = '../data_ignore/input/train_targets_scored.csv'\n",
    "PATH_TRAIN_NONSCORED = '../data_ignore/input/train_targets_nonscored.csv'\n",
    "PATH_SUB = '../data_ignore/input/sample_submission.csv'\n",
    "PATH_TEST = '../data_ignore/input/test_features.csv'\n",
    "SAVE_DIR = f'../data_ignore/output_nb/nb{NB}/'\n",
    "PATH_DRUGID = '../data_ignore/input/train_drug.csv'\n",
    "PATH_GROUP696 = './../data_ignore/output_nb/nb004/group.csv'\n",
    "PATH_ESTIMATED_LOGLOSS = './../data_ignore/output_nb/nb017/estimated_logloss.csv'\n",
    "TOP8_DRUG = ['87d714366', '9f80f3f77', '8b87a7a83', '5628cb3ee', 'd08af5d4b', '292ab2c28', 'd50f18348', 'd1b47f29d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_str = \"\"\"\n",
    "globals:\n",
    "  seed: 2020\n",
    "  device: cuda\n",
    "  num_epochs: 80\n",
    "\n",
    "dataset:\n",
    "  name: \n",
    "  params:\n",
    "    \n",
    "split:\n",
    "  name: MultiStratifiedKFold\n",
    "  params:\n",
    "    n_splits: 5\n",
    "    random_state: 42\n",
    "    shuffle: True\n",
    "\n",
    "loader:\n",
    "  train:\n",
    "    batch_size: 512\n",
    "    shuffle: True\n",
    "    num_workers: 10\n",
    "    pin_memory: True\n",
    "    drop_last: True\n",
    "  val:\n",
    "    batch_size: 512\n",
    "    shuffle: False\n",
    "    num_workers: 10\n",
    "    pin_memory: True\n",
    "    drop_last: False\n",
    "\n",
    "model:\n",
    "  name: \n",
    "  params:\n",
    "\n",
    "loss:\n",
    "  name: SmoothLogitsLoss\n",
    "  params: {}\n",
    "\n",
    "optimizer:\n",
    "  name: Adam\n",
    "  params:\n",
    "    lr: 0.005\n",
    "\n",
    "scheduler:\n",
    "  name: CosineAnnealingLR\n",
    "  params:\n",
    "    T_max: 10\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import everything I need :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py:886: MatplotlibDeprecationWarning: \n",
      "examples.directory is deprecated; in the future, examples will be found relative to the 'datapath' directory.\n",
      "  \"found relative to the 'datapath' directory.\".format(key))\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import yaml\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from pdb import set_trace as st\n",
    "from fastprogress import progress_bar\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import KFold\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df_):\n",
    "    df = df_.copy()\n",
    "    df.loc[:, 'cp_type'] = df.loc[:, 'cp_type'].map({'trt_cp': 0, 'ctl_vehicle': 1})\n",
    "    df.loc[:, 'cp_dose'] = df.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n",
    "#     df.loc[:, 'cp_time'] = df.loc[:, 'cp_time'].map({24: 0, 48: 1, 72: 2})\n",
    "    del df['sig_id']\n",
    "    return df\n",
    "\n",
    "def remove_ctl_cp(features_, target_):\n",
    "    features = features_.copy()\n",
    "    target = target_.copy()\n",
    "#     bools = features['cp_type'] != 'ctl_vehicle'\n",
    "    bools = features['cp_type'] != 1\n",
    "    features = features[bools].reset_index(drop=True)\n",
    "    features = features.drop(['cp_type'], axis=1).values\n",
    "    target = target[bools].reset_index(drop=True).values\n",
    "    return features, target\n",
    "\n",
    "def add_ctl_cp_oof(oof):\n",
    "    oof_new = np.zeros_like(train_targets).astype(float)\n",
    "    bools = train_features['cp_type'] != 'ctl_vehicle'\n",
    "    oof_new[bools, :] = oof\n",
    "    return oof_new\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "class permutation_importance():\n",
    "    def __init__(self, model, metric):\n",
    "        self.is_computed = False\n",
    "        self.n_feat = 0\n",
    "        self.base_score = 0\n",
    "        self.model = model\n",
    "        self.metric = metric\n",
    "        self.df_result = []\n",
    "    \n",
    "    def compute(self, _X_valid, y_valid):\n",
    "        X_valid = pd.DataFrame(_X_valid, columns=FEAT_COLUMNS)\n",
    "        self.n_feat = len(X_valid.columns)\n",
    "        \n",
    "        val_set = MoaDataset(_X_valid, y_valid, mode='train')\n",
    "        dataloaders = {'val': DataLoader(val_set, **settings['loader']['val'])}\n",
    "        y_valid_pred = get_epoch_pred(self.model, device, dataloaders['val'])\n",
    "        \n",
    "        \n",
    "        self.base_score = self.metric(y_valid, y_valid_pred)\n",
    "        self.df_result = pd.DataFrame({'feat': X_valid.columns, \n",
    "                                       'score': np.zeros(self.n_feat),\n",
    "                                       'score_diff': np.zeros(self.n_feat)})\n",
    "        \n",
    "        # predict\n",
    "        for i, col in enumerate(progress_bar(X_valid.columns)):\n",
    "            df_perm = X_valid.copy()\n",
    "            np.random.seed(1)\n",
    "            df_perm[col] = np.random.permutation(df_perm[col])\n",
    "            \n",
    "#             y_valid_pred = self.model.predict(df_perm)\n",
    "            val_set = MoaDataset(df_perm.values, y_valid, mode='train')\n",
    "            dataloaders = {'val': DataLoader(val_set, **settings['loader']['val'])}\n",
    "            y_valid_pred = get_epoch_pred(self.model, device, dataloaders['val'])\n",
    "            \n",
    "            score = self.metric(y_valid, y_valid_pred)\n",
    "            self.df_result['score'][self.df_result['feat']==col] = score\n",
    "            self.df_result['score_diff'][self.df_result['feat']==col] = self.base_score - score\n",
    "        self.is_computed = True\n",
    "    \n",
    "    def get_negative_feature(self):\n",
    "        assert self.is_computed!=False, 'compute メソッドが実行されていません'\n",
    "        idx = self.df_result['score_diff'] < 0\n",
    "        return self.df_result.loc[idx, 'feat'].values.tolist()\n",
    "        \n",
    "    def get_positive_feature(self):\n",
    "        assert self.is_computed!=False, 'compute メソッドが実行されていません'\n",
    "        idx = self.df_result['score_diff'] > 0\n",
    "        return self.df_result.loc[idx, 'feat'].values.tolist()\n",
    "    \n",
    "    def show_permutation_importance(self, score_type='loss'):\n",
    "        '''score_type = 'loss' or 'accuracy'  '''\n",
    "        assert self.is_computed!=False, 'compute メソッドが実行されていません'\n",
    "        if score_type=='loss':\n",
    "            ascending = True\n",
    "        elif score_type=='accuracy':\n",
    "            ascending = False\n",
    "        else:\n",
    "            ascending = ''\n",
    "        \n",
    "        plt.figure(figsize=(15, int(0.25*self.n_feat)))\n",
    "        sns.barplot(x=\"score_diff\", y=\"feat\", data=self.df_result.sort_values(by=\"score_diff\", ascending=ascending))\n",
    "        plt.title('base_score - permutation_score')\n",
    "\n",
    "def get_not_drug_leak_folds(n_splits, train_features, train_drug, gruoup696):\n",
    "    '''\n",
    "    n_splits だけfoldを作成する。\n",
    "    ただし、cp_type = ctl_vehicle と、top8にはfold=-1を割り振っている。\n",
    "    \n",
    "    696group のcsv: https://www.kaggle.com/fkubota/moa-nb004-696group\n",
    "    \n",
    "    ::example::\n",
    "    train_features = pd.read_csv(\"train_features.csv\")\n",
    "    train_drug = pd.read_csv(\"train_drug.csv\")\n",
    "    group696 = pd.read_csv(\"MoA_nb004_696group/group.csv\")\n",
    "    df_fold = get_not_drug_leak_folds(5, train_features, train_drug, group696)\n",
    "    '''\n",
    "    TOP8_DRUG = ['87d714366', '9f80f3f77', '8b87a7a83', '5628cb3ee', 'd08af5d4b', '292ab2c28', 'd50f18348', 'd1b47f29d']\n",
    "    mask_trt = (train_features['cp_type'] == 'trt_cp').values\n",
    "\n",
    "    # mask_top8 を作成\n",
    "    mask_top8 = []\n",
    "    for drug_id in train_drug.drug_id.values:\n",
    "        if drug_id in TOP8_DRUG:\n",
    "            mask_top8.append(True)\n",
    "        else:\n",
    "            mask_top8.append(False)\n",
    "    mask_top8 = np.array(mask_top8)\n",
    "    \n",
    "    # trt かつ top8 以外を抜き出す\n",
    "    # group = 0 は要素数が多いので一番最後にやるようにする\n",
    "    drug_groups = group696[mask_trt & ~mask_top8].group.values\n",
    "    groups = np.sort(group696[mask_trt & ~mask_top8].group.unique())\n",
    "    groups = groups[1:]\n",
    "    groups = np.append(groups, 0)\n",
    "    \n",
    "    # 各グループにfoldを割り振る\n",
    "    tile = []\n",
    "    train_drug_trt = train_drug[mask_trt & ~mask_top8]\n",
    "    train_drug_trt['fold'] = -1\n",
    "    for i_grp, grp in enumerate(groups):\n",
    "        if i_grp == 0:\n",
    "            tile = np.arange(1, n_splits+1).astype(int)\n",
    "\n",
    "        mask_grp = drug_groups == grp\n",
    "        drug_rank = train_drug[mask_trt & ~mask_top8][mask_grp].drug_id.value_counts()\n",
    "\n",
    "        n_repeat = np.ceil(len(drug_rank)/n_splits).astype(int)\n",
    "        folds = np.tile(tile, n_repeat)[:len(drug_rank)]\n",
    "\n",
    "        for i, drug_id in enumerate(drug_rank.index.sort_values()):\n",
    "            mask = train_drug_trt.drug_id.values == drug_id\n",
    "            train_drug_trt.fold[mask] = folds[i]\n",
    "        tile = train_drug_trt.fold.value_counts()[::-1][:n_splits].index\n",
    "        \n",
    "    train_drug_fold = train_drug.copy()\n",
    "    train_drug_fold['fold'] = -1\n",
    "    train_drug_fold['fold'][mask_trt & ~mask_top8] = train_drug_trt.fold.values\n",
    "    return train_drug_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoaModel(nn.Module):\n",
    "    def __init__(self, n_input, n_output):\n",
    "        super(MoaModel, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(n_input)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(n_input, 2048))\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(2048)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.dense2 = nn.utils.weight_norm(nn.Linear(2048, 1048))\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(1048)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "#         self.dense3 = nn.utils.weight_norm(nn.Linear(1048, 206))\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(1048, n_output))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.dense1(x))\n",
    "        \n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.dense2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x_raw = self.dense3(x)\n",
    "        x_sigmoid = F.sigmoid(x_raw)\n",
    "        \n",
    "        return x_sigmoid, x_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoaDataset(Dataset):\n",
    "    def __init__(self, df, targets, mode):\n",
    "        self.mode = mode\n",
    "        self.df = df\n",
    "#         self.targets = targets\n",
    "        if mode=='train':\n",
    "            self.targets = targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == 'train':\n",
    "            return torch.FloatTensor(self.df[idx]), torch.FloatTensor(self.targets[idx])\n",
    "        elif self.mode == 'val':\n",
    "            return torch.FloatTensor(self.df[idx]), 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_log_loss(y_true, y_pred):\n",
    "    metrics = []\n",
    "#     for i in range(y_true.shape[1]):\n",
    "#         metrics.append(log_loss(y_true[:, i], y_pred[:, i].astype(float), labels=[0,1]))\n",
    "#     return np.mean(metrics)\n",
    "    y_true =  y_true.astype(np.float64).ravel()\n",
    "    y_pred =  y_pred.astype(np.float64).ravel()\n",
    "    return log_loss(y_true, y_pred, labels=[0, 1])\n",
    "\n",
    "class SmoothBCEwLogits(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.001):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n",
    "        assert 0 <= smoothing < 1\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1),\n",
    "            self.smoothing)\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets,self.weight)\n",
    "\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss\n",
    "\n",
    "class FocalLoss2d(nn.modules.loss._WeightedLoss):\n",
    "    '''\n",
    "    https://github.com/andrijdavid/FocalLoss/blob/master/focalloss.py\n",
    "    '''\n",
    "    def __init__(self, gamma=2, weight=None, size_average=None, ignore_index=-100,\n",
    "                 reduce=None, reduction='mean', balance_param=0.25):\n",
    "        super(FocalLoss2d, self).__init__(weight, size_average, reduce, reduction)\n",
    "        self.gamma = gamma\n",
    "        self.weight = weight\n",
    "        self.size_average = size_average\n",
    "        self.ignore_index = ignore_index\n",
    "        self.balance_param = balance_param\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        \n",
    "        # inputs and targets are assumed to be BatchxClasses\n",
    "        assert len(input.shape) == len(target.shape)\n",
    "        assert input.size(0) == target.size(0)\n",
    "        assert input.size(1) == target.size(1)\n",
    "        \n",
    "        weight = Variable(self.weight)\n",
    "           \n",
    "        # compute the negative likelyhood\n",
    "        logpt = - F.binary_cross_entropy_with_logits(input, target, pos_weight=self.weight, reduction=self.reduction)\n",
    "#         logpt = - F.binary_cross_entropy_with_logits(input, target, reduction=self.reduction)\n",
    "        pt = torch.exp(logpt)\n",
    "\n",
    "        # compute the loss\n",
    "        focal_loss = -( (1-pt)**self.gamma ) * logpt\n",
    "        balanced_focal_loss = self.balance_param * focal_loss\n",
    "        return balanced_focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"\n",
    "    Early stops the training if validation loss doesn't improve after a given patience.\n",
    "    https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\n",
    "    \"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "#         self.best_state_dict = {}\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "#         if not DEBUG:\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "#         self.best_state_dict = model.state_dict()\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "def mixup_data(x, y, alpha=1.0, use_cuda=True):\n",
    "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    if use_cuda:\n",
    "        index = torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index = torch.randperm(batch_size)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, device, train_loader, optimizer, scheduler, criterion, mixup=False, mixup_alpha=1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        if mixup:\n",
    "            x, y_a, y_b, lam = mixup_data(x, y, mixup_alpha)\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(True):\n",
    "            pred_sigmoid, pred_raw = model(x)\n",
    "            if mixup:\n",
    "                loss = mixup_criterion(criterion, pred_raw, y_a, y_b, lam)\n",
    "            else:\n",
    "                loss = criterion(pred_raw, y)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        running_loss += loss.item() / len(train_loader)\n",
    "    scheduler.step()\n",
    "    return running_loss\n",
    "\n",
    "def get_epoch_loss_score(model, device, valid_loader, criterion, optimizer):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    targets = []\n",
    "    preds = []\n",
    "    for i, (x, y) in enumerate(valid_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(False):\n",
    "            pred_sigmoid, pred_raw = model(x)\n",
    "            loss = criterion(pred_raw, y)\n",
    "        running_loss += loss.item() / len(valid_loader)\n",
    "        targets.append(y)\n",
    "        preds.append(pred_sigmoid)\n",
    "    targets = torch.cat(targets, dim=0).cpu().numpy()\n",
    "    preds = torch.cat(preds, dim=0).cpu().numpy()\n",
    "    _mean_log_loss = mean_log_loss(targets, preds)\n",
    "    return running_loss, _mean_log_loss, preds\n",
    "\n",
    "def get_epoch_pred(model, device, valid_loader):\n",
    "    model.eval()\n",
    "    targets = []\n",
    "    preds = []\n",
    "    for i, (x, y) in enumerate(valid_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        with torch.set_grad_enabled(False):\n",
    "            pred_sigmoid, pred_raw = model(x)\n",
    "        targets.append(y)\n",
    "        preds.append(pred_sigmoid)\n",
    "    targets = torch.cat(targets, dim=0).cpu().numpy()\n",
    "    preds = torch.cat(preds, dim=0).cpu().numpy()\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fold(dataloaders, shape, checkpoint_path, ModelClass, show_log=True, mixup=False, mixup_alpha=1):\n",
    "    device = torch.device(\"cuda\")\n",
    "    model = ModelClass(shape[0], shape[1]).to(device)\n",
    "#     model = ModelClass(train.shape[1], ).to(device)\n",
    "    early_stopping = EarlyStopping(patience=15, verbose=show_log, path=checkpoint_path)\n",
    "    optimizer = optim.__getattribute__(settings['optimizer']['name'])(\n",
    "        model.parameters(), **settings['optimizer']['params'])\n",
    "    scheduler = optim.lr_scheduler.__getattribute__(settings['scheduler']['name'])(\n",
    "        optimizer, **settings['scheduler']['params'])\n",
    "    \n",
    "    best_valid_loss = np.inf\n",
    "    best_mean_log_loss = np.inf\n",
    "    best_preds = 0\n",
    "    val_losses = []\n",
    "    trn_losses = []\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss =  train_model(model, device, dataloaders['train'], optimizer, scheduler, criterion, mixup=mixup, mixup_alpha=mixup_alpha)\n",
    "        valid_loss, _mean_log_loss, preds = get_epoch_loss_score(model, device, dataloaders['val'], criterion, optimizer)\n",
    "\n",
    "        trn_losses.append(train_loss)\n",
    "        val_losses.append(valid_loss)\n",
    "        if show_log:\n",
    "            print(f\"Epoch {str(epoch+1).zfill(2)}/{n_epochs }   loss: {train_loss:5.5f}   val_loss: {valid_loss:5.5f}   mean_log_loss: {_mean_log_loss:5.5f}\")\n",
    "        early_stopping(valid_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "        if valid_loss < best_valid_loss: \n",
    "            best_valid_loss = valid_loss\n",
    "            best_mean_log_loss = _mean_log_loss\n",
    "            best_preds = preds\n",
    "    return best_mean_log_loss, best_preds, trn_losses, val_losses\n",
    "\n",
    "def run(splitter, train, targets, ModelClass, show_log=True, pi=False, mixup=False):\n",
    "    mean_log_loss_list = []\n",
    "    oof = np.zeros_like(targets).astype(float)\n",
    "    df_pi = pd.DataFrame(columns=['feat', 'score_diff'])\n",
    "    for n, (idx_trn, idx_val) in enumerate(splitter.split(train, targets)):\n",
    "        print('-'*100)\n",
    "        print(f':: start fold {n+1}/{n_splits} at {time.ctime()} ::')\n",
    "        print('-'*100)\n",
    "        X_trn, X_val = train[idx_trn], train[idx_val]\n",
    "        y_trn, y_val = targets[idx_trn], targets[idx_val]\n",
    "\n",
    "        train_set = MoaDataset(X_trn, y_trn, mode='train')\n",
    "        val_set = MoaDataset(X_val, y_val, mode='train')\n",
    "\n",
    "        dataloaders = {\n",
    "            'train': DataLoader(train_set, **settings['loader']['train']),\n",
    "            'val': DataLoader(val_set, **settings['loader']['val']),\n",
    "        }\n",
    "\n",
    "        checkpoint_path = f'{SAVE_DIR}Fold{n+1}of{n_splits}.pt'\n",
    "        shape = (X_trn.shape[1], y_trn.shape[1])\n",
    "        best_mean_log_loss, best_preds, trn_losses, val_losses =  run_fold(dataloaders, shape, checkpoint_path, ModelClass, show_log=show_log, mixup=mixup)\n",
    "\n",
    "        # result\n",
    "        print(f':: best mean_log_loss: {best_mean_log_loss:5.5f} ::')\n",
    "        mean_log_loss_list.append(best_mean_log_loss)\n",
    "        oof[idx_val, :] = best_preds\n",
    "        \n",
    "        # permutation importance\n",
    "        if pi:\n",
    "            device = torch.device(\"cuda\")\n",
    "            model = ModelClass(shape[0], shape[1]).to(device)\n",
    "            state_dict = torch.load(checkpoint_path)\n",
    "            model.load_state_dict(state_dict)\n",
    "            model.to(device)\n",
    "            model.eval()\n",
    "            pi = permutation_importance(model, mean_log_loss) # model と metric を渡す\n",
    "            pi.compute(X_val, y_val)\n",
    "            pi_result = pi.df_result\n",
    "            df_pi = pd.concat([df_pi, pi_result[['feat', 'score_diff']]])\n",
    "    #         pi.show_permutation_importance(score_type='loss')\n",
    "        \n",
    "        # plot\n",
    "        if show_log:\n",
    "            x = np.arange(1, len(trn_losses)+1)\n",
    "            plt.figure(figsize=(12, 7))\n",
    "            plt.plot(x[1:], trn_losses[1:], '--.', label='train')\n",
    "            plt.plot(x[1:], val_losses[1:], '--.', label='valid')\n",
    "            plt.title(f\"fold{n+1}/{n_splits} {settings['loss']['name']}\")\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        print('\\n')\n",
    "    \n",
    "    if pi:\n",
    "        # permutation score\n",
    "        plt.figure(figsize=(15, int(0.25*len(FEAT_COLUMNS))))\n",
    "        order = df_pi.groupby([\"feat\"]).mean()['score_diff'].reset_index().sort_values('score_diff', ascending=True)\n",
    "        sns.barplot(x=\"score_diff\", y=\"feat\", data=df_pi, order=order['feat'])\n",
    "        plt.title('base_score - permutation_score')\n",
    "        plt.show()\n",
    "    return mean_log_loss_list, oof, df_pi\n",
    "\n",
    "def run_not_drug_leak(df_fold, train, targets, ModelClass, show_log=True, pi=False, mixup=False, mixup_alpha=1):\n",
    "    mean_log_loss_list = []\n",
    "    oof = np.zeros_like(targets).astype(float)\n",
    "    df_pi = pd.DataFrame(columns=['feat', 'score_diff'])\n",
    "#     for n, (idx_trn, idx_val) in enumerate(splitter.split(train, targets)):\n",
    "    for n, fold_i in enumerate(df_fold['fold'].unique()):\n",
    "        print('-'*100)\n",
    "        print(f':: start fold {n+1}/{n_splits} at {time.ctime()} ::')\n",
    "        print('-'*100)\n",
    "        mask_fold = df_fold.fold == fold_i\n",
    "        X_trn, X_val = train[~mask_fold], train[mask_fold]\n",
    "        y_trn, y_val = targets[~mask_fold], targets[mask_fold]\n",
    "\n",
    "        train_set = MoaDataset(X_trn, y_trn, mode='train')\n",
    "        val_set = MoaDataset(X_val, y_val, mode='train')\n",
    "\n",
    "        dataloaders = {\n",
    "            'train': DataLoader(train_set, **settings['loader']['train']),\n",
    "            'val': DataLoader(val_set, **settings['loader']['val']),\n",
    "        }\n",
    "\n",
    "        checkpoint_path = f'{SAVE_DIR}Fold{n+1}of{n_splits}.pt'\n",
    "        shape = (X_trn.shape[1], y_trn.shape[1])\n",
    "        best_mean_log_loss, best_preds, trn_losses, val_losses = run_fold(dataloaders, shape, checkpoint_path, \n",
    "                                                                          ModelClass, show_log=show_log, \n",
    "                                                                          mixup=mixup, mixup_alpha=mixup_alpha)\n",
    "\n",
    "        # result\n",
    "        print(f':: best mean_log_loss: {best_mean_log_loss:5.5f} ::')\n",
    "        mean_log_loss_list.append(best_mean_log_loss)\n",
    "#         oof[idx_val, :] = best_preds\n",
    "        oof[mask_fold, :] = best_preds\n",
    "        \n",
    "        # permutation importance\n",
    "        if pi:\n",
    "            device = torch.device(\"cuda\")\n",
    "            model = ModelClass(shape[0], shape[1]).to(device)\n",
    "            state_dict = torch.load(checkpoint_path)\n",
    "            model.load_state_dict(state_dict)\n",
    "            model.to(device)\n",
    "            model.eval()\n",
    "            pi = permutation_importance(model, mean_log_loss) # model と metric を渡す\n",
    "            pi.compute(X_val, y_val)\n",
    "            pi_result = pi.df_result\n",
    "            df_pi = pd.concat([df_pi, pi_result[['feat', 'score_diff']]])\n",
    "    #         pi.show_permutation_importance(score_type='loss')\n",
    "        \n",
    "        # plot\n",
    "        if show_log:\n",
    "            x = np.arange(1, len(trn_losses)+1)\n",
    "            plt.figure(figsize=(12, 7))\n",
    "            plt.plot(x[1:], trn_losses[1:], '--.', label='train')\n",
    "            plt.plot(x[1:], val_losses[1:], '--.', label='valid')\n",
    "            plt.title(f\"fold{n+1}/{n_splits} {settings['loss']['name']}\")\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        print('\\n')\n",
    "    \n",
    "    if pi:\n",
    "        # permutation score\n",
    "        plt.figure(figsize=(15, int(0.25*len(FEAT_COLUMNS))))\n",
    "        order = df_pi.groupby([\"feat\"]).mean()['score_diff'].reset_index().sort_values('score_diff', ascending=True)\n",
    "        sns.barplot(x=\"score_diff\", y=\"feat\", data=df_pi, order=order['feat'])\n",
    "        plt.title('base_score - permutation_score')\n",
    "        plt.show()\n",
    "    return mean_log_loss_list, oof, df_pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = yaml.safe_load(settings_str)\n",
    "seed_everything(settings['globals']['seed'])\n",
    "sns.set()\n",
    "sns.set_context('talk')\n",
    "\n",
    "if not os.path.exists(SAVE_DIR):\n",
    "    os.makedirs(SAVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    settings['split']['params']['n_splits'] = 2\n",
    "    settings['globals']['num_epochs'] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv(PATH_TRAIN)\n",
    "train_targets = pd.read_csv(PATH_TRAIN_SCORED)\n",
    "# test_features = pd.read_csv(PATH_TEST)\n",
    "train_drug = pd.read_csv(PATH_DRUGID)\n",
    "group696 = pd.read_csv(PATH_GROUP696)\n",
    "\n",
    "# ss = pd.read_csv(PATH_SUB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_top8 を作成\n",
    "mask_top8 = []\n",
    "for drug_id in train_drug.drug_id.values:\n",
    "    if drug_id in TOP8_DRUG:\n",
    "        mask_top8.append(True)\n",
    "    else:\n",
    "        mask_top8.append(False)\n",
    "mask_top8 = np.array(mask_top8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_col = 10\n",
    "step_row = 11\n",
    "\n",
    "if DEBUG:\n",
    "    print(':: debug mode ::')\n",
    "    train_features = train_features.iloc[::step_row, :end_col].reset_index(drop=True)\n",
    "    train_targets = train_targets.iloc[::step_row, :].reset_index(drop=True)\n",
    "    mask_top8 = mask_top8[::step_row]\n",
    "    train_drug = train_drug.iloc[::step_row, :].reset_index(drop=True)\n",
    "    group696 = group696.iloc[::step_row, :].reset_index(drop=True)\n",
    "#     test_features = test_features.iloc[::100, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_trt = (train_features['cp_type'] == 'trt_cp').values\n",
    "train = preprocess(train_features)\n",
    "FEAT_COLUMNS = train_features.columns[2:]\n",
    "# test = preprocess(test_features).values\n",
    "\n",
    "del train_targets['sig_id']\n",
    "\n",
    "target_cols = [col for col in train_targets.columns]\n",
    "train, targets = remove_ctl_cp(train, train_targets)\n",
    "# train_targets = train_targets.loc[train['cp_type']==0].reset_index(drop=True).values\n",
    "# train = train.loc[train['cp_type']==0].reset_index(drop=True).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:         (21948, 874)\n",
      "train_targets shape: (21948, 206)\n"
     ]
    }
   ],
   "source": [
    "print(f'train shape:         {train.shape}')\n",
    "# print(f'test shape:          {test.shape}')\n",
    "print(f'train_targets shape: {targets.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "fold分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.5 s, sys: 0 ns, total: 6.5 s\n",
      "Wall time: 6.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_fold = get_not_drug_leak_folds(settings['split']['params']['n_splits'], train_features, train_drug, group696)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5  3  1  2  4 -1]\n",
      "[5 3 1 2 4]\n"
     ]
    }
   ],
   "source": [
    "splitter = KFold(n_splits=settings['split']['params']['n_splits'], random_state=1, shuffle=True)\n",
    "for top8_i in range(len(TOP8_DRUG)):\n",
    "    mask_drug = df_fold['drug_id'] == TOP8_DRUG[top8_i]\n",
    "\n",
    "    for fold_i, (train_idx, valid_idx) in enumerate(splitter.split(df_fold[mask_drug])):\n",
    "        _df_fold = df_fold[mask_drug]\n",
    "        _df_fold.fold.values[valid_idx] = fold_i + 1\n",
    "        df_fold.fold[mask_drug] = _df_fold.fold.values\n",
    "print(df_fold.fold.unique())\n",
    "print(df_fold[mask_trt].fold.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "top8の除去"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[~mask_top8[mask_trt]]\n",
    "targets = targets[~mask_top8[mask_trt]]\n",
    "df_fold = df_fold[mask_trt & ~mask_top8].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "- group696 に1意的なgroup単位でresampleする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23814, 19825)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(group696), len(df_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fold['group'] = group696.group.values[mask_trt & ~mask_top8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>drug_id</th>\n",
       "      <th>fold</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>b68db1d53</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>df89a8e5a</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>18bb41b2c</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>8c7f86626</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>7cbed3131</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19820</th>\n",
       "      <td>id_fff7e6992</td>\n",
       "      <td>a28556d51</td>\n",
       "      <td>4</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19821</th>\n",
       "      <td>id_fff8c2444</td>\n",
       "      <td>6c3a459be</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19822</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>df1d0a5a1</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19823</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>ecf3b6b74</td>\n",
       "      <td>4</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19824</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>972f41291</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19825 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id    drug_id  fold  group\n",
       "0      id_000644bb2  b68db1d53     5      1\n",
       "1      id_000779bfc  df89a8e5a     3      0\n",
       "2      id_000a6266a  18bb41b2c     3      2\n",
       "3      id_0015fd391  8c7f86626     3      0\n",
       "4      id_001626bd3  7cbed3131     1      3\n",
       "...             ...        ...   ...    ...\n",
       "19820  id_fff7e6992  a28556d51     4     69\n",
       "19821  id_fff8c2444  6c3a459be     4     18\n",
       "19822  id_fffb1ceed  df1d0a5a1     5     26\n",
       "19823  id_fffb70c0c  ecf3b6b74     4    237\n",
       "19824  id_ffffdd77b  972f41291     4      0\n",
       "\n",
       "[19825 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>drug_id</th>\n",
       "      <th>fold</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_001762a82</td>\n",
       "      <td>e06749542</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_00224bf20</td>\n",
       "      <td>952b76dfc</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_0023f063e</td>\n",
       "      <td>de7583071</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_002e08ff8</td>\n",
       "      <td>6fe04582f</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_003603254</td>\n",
       "      <td>3cda750b5</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3958</th>\n",
       "      <td>id_ffab8a71d</td>\n",
       "      <td>d49f848d5</td>\n",
       "      <td>2</td>\n",
       "      <td>589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3959</th>\n",
       "      <td>id_ffcfbf583</td>\n",
       "      <td>c27545fd6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3960</th>\n",
       "      <td>id_ffdd24c81</td>\n",
       "      <td>e234cbb34</td>\n",
       "      <td>2</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3961</th>\n",
       "      <td>id_fff11dbf5</td>\n",
       "      <td>95fa83810</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3962</th>\n",
       "      <td>id_fff790a17</td>\n",
       "      <td>47dd8f190</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3963 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sig_id    drug_id  fold  group\n",
       "0     id_001762a82  e06749542     2      1\n",
       "1     id_00224bf20  952b76dfc     2      0\n",
       "2     id_0023f063e  de7583071     2      6\n",
       "3     id_002e08ff8  6fe04582f     2     12\n",
       "4     id_003603254  3cda750b5     2     15\n",
       "...            ...        ...   ...    ...\n",
       "3958  id_ffab8a71d  d49f848d5     2    589\n",
       "3959  id_ffcfbf583  c27545fd6     2      0\n",
       "3960  id_ffdd24c81  e234cbb34     2    222\n",
       "3961  id_fff11dbf5  95fa83810     2    168\n",
       "3962  id_fff790a17  47dd8f190     2    200\n",
       "\n",
       "[3963 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_i = 2\n",
    "mask_fold = df_fold.fold == fold_i\n",
    "df_fold_i = df_fold[mask_fold].reset_index(drop=True)\n",
    "df_fold_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "562    1\n",
       "41     1\n",
       "552    1\n",
       "619    1\n",
       "156    1\n",
       "560    5\n",
       "210    5\n",
       "662    5\n",
       "584    6\n",
       "594    6\n",
       "598    6\n",
       "602    6\n",
       "606    6\n",
       "626    6\n",
       "630    6\n",
       "640    6\n",
       "684    6\n",
       "677    6\n",
       "347    6\n",
       "345    6\n",
       "Name: group, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fold_i.group.value_counts()[::-1][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df_fold_i.group.value_counts()\n",
    "mask_count = (5 <= counts) & (counts <= 100)\n",
    "select_groups = df_fold_i.group.value_counts().index[mask_count].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_n = np.array([group in select_groups for group in df_fold_i.group.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 275 ms, sys: 39.9 ms, total: 315 ms\n",
      "Wall time: 314 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sm = SMOTE(sampling_strategy='auto', random_state=42, k_neighbors=4)\n",
    "train_res, group_res = sm.fit_resample(train[mask_fold][mask_n], df_fold_i.group.values[mask_n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22849, 19825)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_res), len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "495    73\n",
       "277    73\n",
       "101    73\n",
       "133    73\n",
       "165    73\n",
       "       ..\n",
       "282    73\n",
       "314    73\n",
       "346    73\n",
       "442    73\n",
       "16     73\n",
       "Name: g, Length: 313, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(group_res, columns=['g']).g.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> 5 以上、100以下をすべて over samplingする。  \n",
    "--> その中で73が最も大きかったのでそれに合わせてsampleが増えている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "- 5以上 100以下とそれ以外に分ける\n",
    "- 5以上 100以下をリサンプル\n",
    "- 結合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>drug_id</th>\n",
       "      <th>fold</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>b68db1d53</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>df89a8e5a</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>18bb41b2c</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>8c7f86626</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>7cbed3131</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19820</th>\n",
       "      <td>id_fff7e6992</td>\n",
       "      <td>a28556d51</td>\n",
       "      <td>4</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19821</th>\n",
       "      <td>id_fff8c2444</td>\n",
       "      <td>6c3a459be</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19822</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>df1d0a5a1</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19823</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>ecf3b6b74</td>\n",
       "      <td>4</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19824</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>972f41291</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19825 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id    drug_id  fold  group\n",
       "0      id_000644bb2  b68db1d53     5      1\n",
       "1      id_000779bfc  df89a8e5a     3      0\n",
       "2      id_000a6266a  18bb41b2c     3      2\n",
       "3      id_0015fd391  8c7f86626     3      0\n",
       "4      id_001626bd3  7cbed3131     1      3\n",
       "...             ...        ...   ...    ...\n",
       "19820  id_fff7e6992  a28556d51     4     69\n",
       "19821  id_fff8c2444  6c3a459be     4     18\n",
       "19822  id_fffb1ceed  df1d0a5a1     5     26\n",
       "19823  id_fffb70c0c  ecf3b6b74     4    237\n",
       "19824  id_ffffdd77b  972f41291     4      0\n",
       "\n",
       "[19825 rows x 4 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fold と group が入ったDataFrameを準備\n",
    "df_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_i = 1\n",
    "mask_fold_i = df_fold.fold == fold_i\n",
    "df_fold_i = df_fold[mask_fold_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df_fold_i.group.value_counts()\n",
    "mask_count = (5 <= counts) & (counts <= 100)\n",
    "select_groups = df_fold_i.group.value_counts().index[mask_count].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 275 ms, sys: 39.9 ms, total: 315 ms\n",
      "Wall time: 314 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sm = SMOTE(sampling_strategy='auto', random_state=42, k_neighbors=4)\n",
    "train_res, group_res = sm.fit_resample(train[mask_fold][mask_resample], df_fold_i.group.values[mask_resample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19825, 206)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19825, 4)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fold.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets_group = train_targets[mask_trt & ~mask_top8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets_group['group'] = df_fold.group.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_target = train_targets_group.groupby('group').sum().values.astype(int)\n",
    "unique_group = train_targets_group.groupby('group').sum().index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0, 66,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_target[unique_group == 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>adrenergic_receptor_agonist</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>694 rows × 206 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  acat_inhibitor  \\\n",
       "group                                                                        \n",
       "0                                0                       0               0   \n",
       "1                                0                       0               0   \n",
       "2                                0                       0               0   \n",
       "3                                0                       0               0   \n",
       "4                                0                       0               0   \n",
       "...                            ...                     ...             ...   \n",
       "691                              0                       0               0   \n",
       "692                              0                       0               0   \n",
       "693                              0                       0               0   \n",
       "694                              0                       0               0   \n",
       "695                              0                       0               0   \n",
       "\n",
       "       acetylcholine_receptor_agonist  acetylcholine_receptor_antagonist  \\\n",
       "group                                                                      \n",
       "0                                   0                                  0   \n",
       "1                                   0                                  0   \n",
       "2                                   0                                  0   \n",
       "3                                   0                                  0   \n",
       "4                                   0                                  0   \n",
       "...                               ...                                ...   \n",
       "691                                 0                                  0   \n",
       "692                                 0                                  0   \n",
       "693                                 0                                  0   \n",
       "694                                 0                                  0   \n",
       "695                                 0                                  0   \n",
       "\n",
       "       acetylcholinesterase_inhibitor  adenosine_receptor_agonist  \\\n",
       "group                                                               \n",
       "0                                   0                           0   \n",
       "1                                   0                           0   \n",
       "2                                   0                           0   \n",
       "3                                   0                           0   \n",
       "4                                   0                           0   \n",
       "...                               ...                         ...   \n",
       "691                                 0                           0   \n",
       "692                                 0                           0   \n",
       "693                                 0                           0   \n",
       "694                                 0                           0   \n",
       "695                                 0                           0   \n",
       "\n",
       "       adenosine_receptor_antagonist  adenylyl_cyclase_activator  \\\n",
       "group                                                              \n",
       "0                                  0                           0   \n",
       "1                                  0                           0   \n",
       "2                                  0                           0   \n",
       "3                                  0                           0   \n",
       "4                                  0                           0   \n",
       "...                              ...                         ...   \n",
       "691                                0                           0   \n",
       "692                                0                           0   \n",
       "693                                0                           0   \n",
       "694                                0                           0   \n",
       "695                                0                           0   \n",
       "\n",
       "       adrenergic_receptor_agonist  ...  \\\n",
       "group                               ...   \n",
       "0                                0  ...   \n",
       "1                                0  ...   \n",
       "2                                0  ...   \n",
       "3                                0  ...   \n",
       "4                                0  ...   \n",
       "...                            ...  ...   \n",
       "691                              0  ...   \n",
       "692                              0  ...   \n",
       "693                              0  ...   \n",
       "694                              0  ...   \n",
       "695                              0  ...   \n",
       "\n",
       "       tropomyosin_receptor_kinase_inhibitor  trpv_agonist  trpv_antagonist  \\\n",
       "group                                                                         \n",
       "0                                          0             0                0   \n",
       "1                                          0             0                0   \n",
       "2                                          0             0                0   \n",
       "3                                          0             0                0   \n",
       "4                                          0             0                0   \n",
       "...                                      ...           ...              ...   \n",
       "691                                        0             0                0   \n",
       "692                                        0             0                0   \n",
       "693                                        0             0                0   \n",
       "694                                        0             0                0   \n",
       "695                                        0             0                0   \n",
       "\n",
       "       tubulin_inhibitor  tyrosine_kinase_inhibitor  \\\n",
       "group                                                 \n",
       "0                      0                          0   \n",
       "1                      0                          0   \n",
       "2                      0                          0   \n",
       "3                      0                          0   \n",
       "4                      0                          0   \n",
       "...                  ...                        ...   \n",
       "691                    0                          0   \n",
       "692                    0                          0   \n",
       "693                    0                          0   \n",
       "694                    0                          0   \n",
       "695                    0                          0   \n",
       "\n",
       "       ubiquitin_specific_protease_inhibitor  vegfr_inhibitor  vitamin_b  \\\n",
       "group                                                                      \n",
       "0                                          0                0          0   \n",
       "1                                          0                0          0   \n",
       "2                                          0                0          0   \n",
       "3                                          0                0          0   \n",
       "4                                          0                0          0   \n",
       "...                                      ...              ...        ...   \n",
       "691                                        0                0          0   \n",
       "692                                        0                0          0   \n",
       "693                                        0                0          0   \n",
       "694                                        0                0          0   \n",
       "695                                        0                0          0   \n",
       "\n",
       "       vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "group                                             \n",
       "0                               0              0  \n",
       "1                               0              0  \n",
       "2                               0              0  \n",
       "3                               0              0  \n",
       "4                               0              0  \n",
       "...                           ...            ...  \n",
       "691                             0              0  \n",
       "692                             0              0  \n",
       "693                             0              0  \n",
       "694                             0              0  \n",
       "695                             0              0  \n",
       "\n",
       "[694 rows x 206 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets_group.groupby('group').max().values.astype(int)\n",
    "train_targets_group.groupby('group').max()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
