{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "- nb025を改良\n",
    "- mixupを使う\n",
    "- group328を使用\n",
    "- nb020のfoldを使う\n",
    "- ctrl除く\n",
    "- top8を除く"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275f719\n"
     ]
    }
   ],
   "source": [
    "# gitのhash\n",
    "import subprocess\n",
    "cmd = \"git rev-parse --short HEAD\"\n",
    "hash = subprocess.check_output(cmd.split()).strip().decode('utf-8')\n",
    "print(hash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic\n",
    "NB = '031'\n",
    "DEBUG = False \n",
    "isPI = False\n",
    "isShowLog = True\n",
    "MIXUP = True\n",
    "isSMOTE = False\n",
    "\n",
    "PATH_TRAIN = '../data_ignore/input/train_features.csv'\n",
    "PATH_TRAIN_SCORED = '../data_ignore/input/train_targets_scored.csv'\n",
    "PATH_TRAIN_NONSCORED = '../data_ignore/input/train_targets_nonscored.csv'\n",
    "PATH_SUB = '../data_ignore/input/sample_submission.csv'\n",
    "PATH_TEST = '../data_ignore/input/test_features.csv'\n",
    "SAVE_DIR = f'../data_ignore/output_nb/nb{NB}/'\n",
    "PATH_DRUGID = '../data_ignore/input/train_drug.csv'\n",
    "PATH_GROUP696 = './../data_ignore/output_nb/nb004/group.csv'\n",
    "PATH_GROUP328 = './../data_ignore/output_nb/nb027/group.csv'\n",
    "PATH_ESTIMATED_LOGLOSS = './../data_ignore/output_nb/nb017/estimated_logloss.csv'\n",
    "TOP8_DRUG = ['87d714366', '9f80f3f77', '8b87a7a83', '5628cb3ee', 'd08af5d4b', '292ab2c28', 'd50f18348', 'd1b47f29d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_str = \"\"\"\n",
    "globals:\n",
    "  seed: 2020\n",
    "  device: cuda\n",
    "  num_epochs: 45\n",
    "\n",
    "dataset:\n",
    "  name: \n",
    "  params:\n",
    "    \n",
    "split:\n",
    "  name: MultiStratifiedKFold\n",
    "  params:\n",
    "    n_splits: 5\n",
    "    random_state: 42\n",
    "    shuffle: True\n",
    "\n",
    "loader:\n",
    "  train:\n",
    "    batch_size: 512\n",
    "    shuffle: True\n",
    "    num_workers: 10\n",
    "    pin_memory: True\n",
    "    drop_last: True\n",
    "  val:\n",
    "    batch_size: 512\n",
    "    shuffle: False\n",
    "    num_workers: 10\n",
    "    pin_memory: True\n",
    "    drop_last: False\n",
    "\n",
    "model:\n",
    "  name: \n",
    "  params:\n",
    "\n",
    "loss:\n",
    "  name: SmoothLogitsLoss\n",
    "  params: {}\n",
    "\n",
    "optimizer:\n",
    "  name: Adam\n",
    "  params:\n",
    "    lr: 0.005\n",
    "\n",
    "scheduler:\n",
    "  name: CosineAnnealingLR\n",
    "  params:\n",
    "    T_max: 10\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import everything I need :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import yaml\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from pdb import set_trace as st\n",
    "from fastprogress import progress_bar\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import KFold\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df_):\n",
    "    df = df_.copy()\n",
    "    df.loc[:, 'cp_type'] = df.loc[:, 'cp_type'].map({'trt_cp': 0, 'ctl_vehicle': 1})\n",
    "    df.loc[:, 'cp_dose'] = df.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n",
    "#     df.loc[:, 'cp_time'] = df.loc[:, 'cp_time'].map({24: 0, 48: 1, 72: 2})\n",
    "    del df['sig_id']\n",
    "    return df\n",
    "\n",
    "def remove_ctl_cp(features_, target_):\n",
    "    features = features_.copy()\n",
    "    target = target_.copy()\n",
    "#     bools = features['cp_type'] != 'ctl_vehicle'\n",
    "    bools = features['cp_type'] != 1\n",
    "    features = features[bools].reset_index(drop=True)\n",
    "    features = features.drop(['cp_type'], axis=1).values\n",
    "    target = target[bools].reset_index(drop=True).values\n",
    "    return features, target\n",
    "\n",
    "def add_ctl_cp_oof(oof):\n",
    "    oof_new = np.zeros_like(train_targets).astype(float)\n",
    "    bools = train_features['cp_type'] != 'ctl_vehicle'\n",
    "    oof_new[bools, :] = oof\n",
    "    return oof_new\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "class permutation_importance():\n",
    "    def __init__(self, model, metric):\n",
    "        self.is_computed = False\n",
    "        self.n_feat = 0\n",
    "        self.base_score = 0\n",
    "        self.model = model\n",
    "        self.metric = metric\n",
    "        self.df_result = []\n",
    "    \n",
    "    def compute(self, _X_valid, y_valid):\n",
    "        X_valid = pd.DataFrame(_X_valid, columns=FEAT_COLUMNS)\n",
    "        self.n_feat = len(X_valid.columns)\n",
    "        \n",
    "        val_set = MoaDataset(_X_valid, y_valid, mode='train')\n",
    "        dataloaders = {'val': DataLoader(val_set, **settings['loader']['val'])}\n",
    "        y_valid_pred = get_epoch_pred(self.model, device, dataloaders['val'])\n",
    "        \n",
    "        \n",
    "        self.base_score = self.metric(y_valid, y_valid_pred)\n",
    "        self.df_result = pd.DataFrame({'feat': X_valid.columns, \n",
    "                                       'score': np.zeros(self.n_feat),\n",
    "                                       'score_diff': np.zeros(self.n_feat)})\n",
    "        \n",
    "        # predict\n",
    "        for i, col in enumerate(progress_bar(X_valid.columns)):\n",
    "            df_perm = X_valid.copy()\n",
    "            np.random.seed(1)\n",
    "            df_perm[col] = np.random.permutation(df_perm[col])\n",
    "            \n",
    "#             y_valid_pred = self.model.predict(df_perm)\n",
    "            val_set = MoaDataset(df_perm.values, y_valid, mode='train')\n",
    "            dataloaders = {'val': DataLoader(val_set, **settings['loader']['val'])}\n",
    "            y_valid_pred = get_epoch_pred(self.model, device, dataloaders['val'])\n",
    "            \n",
    "            score = self.metric(y_valid, y_valid_pred)\n",
    "            self.df_result['score'][self.df_result['feat']==col] = score\n",
    "            self.df_result['score_diff'][self.df_result['feat']==col] = self.base_score - score\n",
    "        self.is_computed = True\n",
    "    \n",
    "    def get_negative_feature(self):\n",
    "        assert self.is_computed!=False, 'compute メソッドが実行されていません'\n",
    "        idx = self.df_result['score_diff'] < 0\n",
    "        return self.df_result.loc[idx, 'feat'].values.tolist()\n",
    "        \n",
    "    def get_positive_feature(self):\n",
    "        assert self.is_computed!=False, 'compute メソッドが実行されていません'\n",
    "        idx = self.df_result['score_diff'] > 0\n",
    "        return self.df_result.loc[idx, 'feat'].values.tolist()\n",
    "    \n",
    "    def show_permutation_importance(self, score_type='loss'):\n",
    "        '''score_type = 'loss' or 'accuracy'  '''\n",
    "        assert self.is_computed!=False, 'compute メソッドが実行されていません'\n",
    "        if score_type=='loss':\n",
    "            ascending = True\n",
    "        elif score_type=='accuracy':\n",
    "            ascending = False\n",
    "        else:\n",
    "            ascending = ''\n",
    "        \n",
    "        plt.figure(figsize=(15, int(0.25*self.n_feat)))\n",
    "        sns.barplot(x=\"score_diff\", y=\"feat\", data=self.df_result.sort_values(by=\"score_diff\", ascending=ascending))\n",
    "        plt.title('base_score - permutation_score')\n",
    "        \n",
    "    \n",
    "\n",
    "def get_not_drug_leak_folds(n_splits, train_features, train_drug, group):\n",
    "    '''\n",
    "    n_splits だけfoldを作成する。\n",
    "    ただし、cp_type = ctl_vehicle と、top8にはfold=-1を割り振っている。\n",
    "    \n",
    "    696group のcsv: https://www.kaggle.com/fkubota/moa-nb004-696group\n",
    "    \n",
    "    ::example::\n",
    "    train_features = pd.read_csv(\"train_features.csv\")\n",
    "    train_drug = pd.read_csv(\"train_drug.csv\")\n",
    "    group696 = pd.read_csv(\"MoA_nb004_696group/group.csv\")\n",
    "    df_fold = get_not_drug_leak_folds(5, train_features, train_drug, group696)\n",
    "    '''\n",
    "    TOP8_DRUG = ['87d714366', '9f80f3f77', '8b87a7a83', '5628cb3ee', 'd08af5d4b', '292ab2c28', 'd50f18348', 'd1b47f29d']\n",
    "    mask_trt = (train_features['cp_type'] == 'trt_cp').values\n",
    "\n",
    "    # mask_top8 を作成\n",
    "    mask_top8 = []\n",
    "    for drug_id in train_drug.drug_id.values:\n",
    "        if drug_id in TOP8_DRUG:\n",
    "            mask_top8.append(True)\n",
    "        else:\n",
    "            mask_top8.append(False)\n",
    "    mask_top8 = np.array(mask_top8)\n",
    "    \n",
    "    # trt かつ top8 以外を抜き出す\n",
    "    # group = 0 は要素数が多いので一番最後にやるようにする\n",
    "    drug_groups = group[mask_trt & ~mask_top8].group.values\n",
    "    groups = np.sort(group[mask_trt & ~mask_top8].group.unique())\n",
    "    groups = groups[1:]\n",
    "    groups = np.append(groups, 0)\n",
    "    \n",
    "    # 各グループにfoldを割り振る\n",
    "    tile = []\n",
    "    train_drug_trt = train_drug[mask_trt & ~mask_top8]\n",
    "    train_drug_trt['fold'] = -1\n",
    "    for i_grp, grp in enumerate(groups):\n",
    "        if i_grp == 0:\n",
    "            tile = np.arange(1, n_splits+1).astype(int)\n",
    "\n",
    "        mask_grp = drug_groups == grp\n",
    "        drug_rank = train_drug[mask_trt & ~mask_top8][mask_grp].drug_id.value_counts()\n",
    "\n",
    "        n_repeat = np.ceil(len(drug_rank)/n_splits).astype(int)\n",
    "        folds = np.tile(tile, n_repeat)[:len(drug_rank)]\n",
    "\n",
    "        for i, drug_id in enumerate(drug_rank.index.sort_values()):\n",
    "            mask = train_drug_trt.drug_id.values == drug_id\n",
    "            train_drug_trt.fold[mask] = folds[i]\n",
    "        tile = train_drug_trt.fold.value_counts()[::-1][:n_splits].index\n",
    "        \n",
    "    train_drug_fold = train_drug.copy()\n",
    "    train_drug_fold['fold'] = -1\n",
    "    train_drug_fold['fold'][mask_trt & ~mask_top8] = train_drug_trt.fold.values\n",
    "    return train_drug_fold\n",
    "\n",
    "def group_smote(groups_fold, train_fold, targets_fold, n_min=5, n_max=100):\n",
    "    df_g = pd.DataFrame(groups_fold, columns=['group'])\n",
    "    counts = df_g.group.value_counts()\n",
    "    mask_count = (n_min <= counts) & (counts <= n_max)\n",
    "    select_groups = counts.index[mask_count].values\n",
    "    mask_resample = np.array([g in select_groups for g in groups_fold])\n",
    "    \n",
    "    # smote\n",
    "    sm = SMOTE(sampling_strategy='auto', random_state=42, k_neighbors=4)\n",
    "    train_sm, group_sm = sm.fit_resample(\n",
    "        train_fold[mask_resample], \n",
    "        groups_fold[mask_resample])\n",
    "    \n",
    "    # create resample target\n",
    "#     df_targets = pd.DataFrame(targets_fold, columns=[str(i) for i in range(targets_fold.shape[1])])\n",
    "    df_targets = pd.DataFrame(targets_fold)\n",
    "    df_targets['group'] = groups_fold\n",
    "    unique_target = df_targets.groupby('group').max().values.astype(int)\n",
    "    unique_group = df_targets.groupby('group').max().index.values\n",
    "    target_sm = np.array([unique_target[unique_group == g] for g in group_sm])[:, 0]\n",
    "    \n",
    "    # merge\n",
    "    train_not_sm = train_fold[~mask_resample]\n",
    "    target_not_sm = targets_fold[~mask_resample]\n",
    "    group_not_sm = groups_fold[~mask_resample]\n",
    "    \n",
    "    train_res = np.vstack([train_not_sm, train_sm])\n",
    "    target_res = np.vstack([target_not_sm, target_sm])\n",
    "    group_res = np.hstack([group_not_sm, group_sm])\n",
    "    \n",
    "    return group_res, train_res, target_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoaModel(nn.Module):\n",
    "    def __init__(self, n_input, n_output):\n",
    "        super(MoaModel, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(n_input)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(n_input, 2048))\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(2048)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.dense2 = nn.utils.weight_norm(nn.Linear(2048, 1048))\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(1048)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "#         self.dense3 = nn.utils.weight_norm(nn.Linear(1048, 206))\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(1048, n_output))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.dense1(x))\n",
    "        \n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.dense2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x_raw = self.dense3(x)\n",
    "        x_sigmoid = F.sigmoid(x_raw)\n",
    "        \n",
    "        return x_sigmoid, x_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoaDataset(Dataset):\n",
    "    def __init__(self, df, targets, mode):\n",
    "        self.mode = mode\n",
    "        self.df = df\n",
    "#         self.targets = targets\n",
    "        if mode=='train':\n",
    "            self.targets = targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == 'train':\n",
    "            return torch.FloatTensor(self.df[idx]), torch.FloatTensor(self.targets[idx])\n",
    "        elif self.mode == 'val':\n",
    "            return torch.FloatTensor(self.df[idx]), 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_log_loss(y_true, y_pred):\n",
    "    metrics = []\n",
    "#     for i in range(y_true.shape[1]):\n",
    "#         metrics.append(log_loss(y_true[:, i], y_pred[:, i].astype(float), labels=[0,1]))\n",
    "#     return np.mean(metrics)\n",
    "    y_true =  y_true.astype(np.float64).ravel()\n",
    "    y_pred =  y_pred.astype(np.float64).ravel()\n",
    "    return log_loss(y_true, y_pred, labels=[0, 1])\n",
    "\n",
    "class SmoothBCEwLogits(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.001):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n",
    "        assert 0 <= smoothing < 1\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1),\n",
    "            self.smoothing)\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets,self.weight)\n",
    "\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"\n",
    "    Early stops the training if validation loss doesn't improve after a given patience.\n",
    "    https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\n",
    "    \"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "#         self.best_state_dict = {}\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "#         if not DEBUG:\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "#         self.best_state_dict = model.state_dict()\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "def mixup_data(x, y, alpha=1.0, use_cuda=True):\n",
    "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    if use_cuda:\n",
    "        index = torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index = torch.randperm(batch_size)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, device, train_loader, optimizer, scheduler, criterion, mixup=False):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        if mixup:\n",
    "            x, y_a, y_b, lam = mixup_data(x, y, 1.0)\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(True):\n",
    "            pred_sigmoid, pred_raw = model(x)\n",
    "            if mixup:\n",
    "                loss = mixup_criterion(criterion, pred_raw, y_a, y_b, lam)\n",
    "            else:\n",
    "                loss = criterion(pred_raw, y)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        running_loss += loss.item() / len(train_loader)\n",
    "    scheduler.step()\n",
    "    return running_loss\n",
    "\n",
    "def get_epoch_loss_score(model, device, valid_loader, criterion, optimizer):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    targets = []\n",
    "    preds = []\n",
    "    for i, (x, y) in enumerate(valid_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(False):\n",
    "            pred_sigmoid, pred_raw = model(x)\n",
    "            loss = criterion(pred_raw, y)\n",
    "        running_loss += loss.item() / len(valid_loader)\n",
    "        targets.append(y)\n",
    "        preds.append(pred_sigmoid)\n",
    "    targets = torch.cat(targets, dim=0).cpu().numpy()\n",
    "    preds = torch.cat(preds, dim=0).cpu().numpy()\n",
    "    _mean_log_loss = mean_log_loss(targets, preds)\n",
    "    return running_loss, _mean_log_loss, preds\n",
    "\n",
    "def get_epoch_pred(model, device, valid_loader):\n",
    "    model.eval()\n",
    "    targets = []\n",
    "    preds = []\n",
    "    for i, (x, y) in enumerate(valid_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        with torch.set_grad_enabled(False):\n",
    "            pred_sigmoid, pred_raw = model(x)\n",
    "        targets.append(y)\n",
    "        preds.append(pred_sigmoid)\n",
    "    targets = torch.cat(targets, dim=0).cpu().numpy()\n",
    "    preds = torch.cat(preds, dim=0).cpu().numpy()\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fold(dataloaders, shape, checkpoint_path, ModelClass, show_log=True, mixup=False):\n",
    "    device = torch.device(\"cuda\")\n",
    "    model = ModelClass(shape[0], shape[1]).to(device)\n",
    "#     model = ModelClass(train.shape[1], ).to(device)\n",
    "    early_stopping = EarlyStopping(patience=15, verbose=show_log, path=checkpoint_path)\n",
    "    optimizer = optim.__getattribute__(settings['optimizer']['name'])(\n",
    "        model.parameters(), **settings['optimizer']['params'])\n",
    "    scheduler = optim.lr_scheduler.__getattribute__(settings['scheduler']['name'])(\n",
    "        optimizer, **settings['scheduler']['params'])\n",
    "    \n",
    "    best_valid_loss = np.inf\n",
    "    best_mean_log_loss = np.inf\n",
    "    best_preds = 0\n",
    "    val_losses = []\n",
    "    trn_losses = []\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss =  train_model(model, device, dataloaders['train'], optimizer, scheduler, criterion, mixup=mixup)\n",
    "        valid_loss, _mean_log_loss, preds = get_epoch_loss_score(model, device, dataloaders['val'], criterion, optimizer)\n",
    "\n",
    "        trn_losses.append(train_loss)\n",
    "        val_losses.append(valid_loss)\n",
    "        if show_log:\n",
    "            print(f\"Epoch {str(epoch+1).zfill(2)}/{n_epochs }   loss: {train_loss:5.5f}   val_loss: {valid_loss:5.5f}   mean_log_loss: {_mean_log_loss:5.5f}\")\n",
    "        early_stopping(valid_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "        if valid_loss < best_valid_loss: \n",
    "            best_valid_loss = valid_loss\n",
    "            best_mean_log_loss = _mean_log_loss\n",
    "            best_preds = preds\n",
    "    return best_mean_log_loss, best_preds, trn_losses, val_losses\n",
    "\n",
    "def run(splitter, train, targets, ModelClass, show_log=True, pi=False, mixup=False):\n",
    "    mean_log_loss_list = []\n",
    "    oof = np.zeros_like(targets).astype(float)\n",
    "    df_pi = pd.DataFrame(columns=['feat', 'score_diff'])\n",
    "    for n, (idx_trn, idx_val) in enumerate(splitter.split(train, targets)):\n",
    "        print('-'*100)\n",
    "        print(f':: start fold {n+1}/{n_splits} at {time.ctime()} ::')\n",
    "        print('-'*100)\n",
    "        X_trn, X_val = train[idx_trn], train[idx_val]\n",
    "        y_trn, y_val = targets[idx_trn], targets[idx_val]\n",
    "\n",
    "        train_set = MoaDataset(X_trn, y_trn, mode='train')\n",
    "        val_set = MoaDataset(X_val, y_val, mode='train')\n",
    "\n",
    "        dataloaders = {\n",
    "            'train': DataLoader(train_set, **settings['loader']['train']),\n",
    "            'val': DataLoader(val_set, **settings['loader']['val']),\n",
    "        }\n",
    "\n",
    "        checkpoint_path = f'{SAVE_DIR}Fold{n+1}of{n_splits}.pt'\n",
    "        shape = (X_trn.shape[1], y_trn.shape[1])\n",
    "        best_mean_log_loss, best_preds, trn_losses, val_losses =  run_fold(dataloaders, shape, checkpoint_path, ModelClass, show_log=show_log, mixup=mixup)\n",
    "\n",
    "        # result\n",
    "        print(f':: best mean_log_loss: {best_mean_log_loss:5.5f} ::')\n",
    "        mean_log_loss_list.append(best_mean_log_loss)\n",
    "        oof[idx_val, :] = best_preds\n",
    "        \n",
    "        # permutation importance\n",
    "        if pi:\n",
    "            device = torch.device(\"cuda\")\n",
    "            model = ModelClass(shape[0], shape[1]).to(device)\n",
    "            state_dict = torch.load(checkpoint_path)\n",
    "            model.load_state_dict(state_dict)\n",
    "            model.to(device)\n",
    "            model.eval()\n",
    "            pi = permutation_importance(model, mean_log_loss) # model と metric を渡す\n",
    "            pi.compute(X_val, y_val)\n",
    "            pi_result = pi.df_result\n",
    "            df_pi = pd.concat([df_pi, pi_result[['feat', 'score_diff']]])\n",
    "    #         pi.show_permutation_importance(score_type='loss')\n",
    "        \n",
    "        # plot\n",
    "        if show_log:\n",
    "            x = np.arange(1, len(trn_losses)+1)\n",
    "            plt.figure(figsize=(12, 7))\n",
    "            plt.plot(x[1:], trn_losses[1:], '--.', label='train')\n",
    "            plt.plot(x[1:], val_losses[1:], '--.', label='valid')\n",
    "            plt.title(f\"fold{n+1}/{n_splits} {settings['loss']['name']}\")\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        print('\\n')\n",
    "    \n",
    "    if pi:\n",
    "        # permutation score\n",
    "        plt.figure(figsize=(15, int(0.25*len(FEAT_COLUMNS))))\n",
    "        order = df_pi.groupby([\"feat\"]).mean()['score_diff'].reset_index().sort_values('score_diff', ascending=True)\n",
    "        sns.barplot(x=\"score_diff\", y=\"feat\", data=df_pi, order=order['feat'])\n",
    "        plt.title('base_score - permutation_score')\n",
    "        plt.show()\n",
    "    return mean_log_loss_list, oof, df_pi\n",
    "\n",
    "def run_not_drug_leak(df_fold, train, targets, \n",
    "                      ModelClass, show_log=True,\n",
    "                      pi=False, mixup=False, smote=False):\n",
    "    mean_log_loss_list = []\n",
    "    oof = np.zeros_like(targets).astype(float)\n",
    "    df_pi = pd.DataFrame(columns=['feat', 'score_diff'])\n",
    "#     for n, (idx_trn, idx_val) in enumerate(splitter.split(train, targets)):\n",
    "    for n, fold_i in enumerate(df_fold['fold'].unique()):\n",
    "        print('-'*100)\n",
    "        print(f':: start fold {n+1}/{n_splits} at {time.ctime()} ::')\n",
    "        print('-'*100)\n",
    "        mask_fold = df_fold.fold == fold_i\n",
    "        X_trn, X_val = train[~mask_fold], train[mask_fold]\n",
    "        y_trn, y_val = targets[~mask_fold], targets[mask_fold]\n",
    "        groups_fold = df_fold.group.values[~mask_fold]\n",
    "                      \n",
    "        if smote:\n",
    "            print('do smote')\n",
    "            groups_fold, X_trn, y_trn = group_smote(groups_fold, X_trn, y_trn, n_min=60, n_max=100)\n",
    "            groups_fold, X_trn, y_trn = group_smote(groups_fold, X_trn, y_trn, n_min=30, n_max=59)\n",
    "            groups_fold, X_trn, y_trn = group_smote(groups_fold, X_trn, y_trn, n_min=5, n_max=29)\n",
    "\n",
    "        train_set = MoaDataset(X_trn, y_trn, mode='train')\n",
    "        val_set = MoaDataset(X_val, y_val, mode='train')\n",
    "\n",
    "        dataloaders = {\n",
    "            'train': DataLoader(train_set, **settings['loader']['train']),\n",
    "            'val': DataLoader(val_set, **settings['loader']['val']),\n",
    "        }\n",
    "\n",
    "        checkpoint_path = f'{SAVE_DIR}Fold{n+1}of{n_splits}.pt'\n",
    "        shape = (X_trn.shape[1], y_trn.shape[1])\n",
    "        best_mean_log_loss, best_preds, trn_losses, val_losses = run_fold(dataloaders, shape, checkpoint_path, \n",
    "                                                                          ModelClass, show_log=show_log, mixup=mixup)\n",
    "\n",
    "        # result\n",
    "        print(f':: best mean_log_loss: {best_mean_log_loss:5.5f} ::')\n",
    "        mean_log_loss_list.append(best_mean_log_loss)\n",
    "#         oof[idx_val, :] = best_preds\n",
    "        oof[mask_fold, :] = best_preds\n",
    "        \n",
    "        # permutation importance\n",
    "        if pi:\n",
    "            device = torch.device(\"cuda\")\n",
    "            model = ModelClass(shape[0], shape[1]).to(device)\n",
    "            state_dict = torch.load(checkpoint_path)\n",
    "            model.load_state_dict(state_dict)\n",
    "            model.to(device)\n",
    "            model.eval()\n",
    "            pi = permutation_importance(model, mean_log_loss) # model と metric を渡す\n",
    "            pi.compute(X_val, y_val)\n",
    "            pi_result = pi.df_result\n",
    "            df_pi = pd.concat([df_pi, pi_result[['feat', 'score_diff']]])\n",
    "    #         pi.show_permutation_importance(score_type='loss')\n",
    "        \n",
    "        # plot\n",
    "        if show_log:\n",
    "            x = np.arange(1, len(trn_losses)+1)\n",
    "            plt.figure(figsize=(12, 7))\n",
    "            plt.plot(x[1:], trn_losses[1:], '--.', label='train')\n",
    "            plt.plot(x[1:], val_losses[1:], '--.', label='valid')\n",
    "            plt.title(f\"fold{n+1}/{n_splits} {settings['loss']['name']}\")\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        print('\\n')\n",
    "    \n",
    "    if pi:\n",
    "        # permutation score\n",
    "        plt.figure(figsize=(15, int(0.25*len(FEAT_COLUMNS))))\n",
    "        order = df_pi.groupby([\"feat\"]).mean()['score_diff'].reset_index().sort_values('score_diff', ascending=True)\n",
    "        sns.barplot(x=\"score_diff\", y=\"feat\", data=df_pi, order=order['feat'])\n",
    "        plt.title('base_score - permutation_score')\n",
    "        plt.show()\n",
    "    return mean_log_loss_list, oof, df_pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = yaml.safe_load(settings_str)\n",
    "seed_everything(settings['globals']['seed'])\n",
    "sns.set()\n",
    "sns.set_context('talk')\n",
    "\n",
    "if not os.path.exists(SAVE_DIR):\n",
    "    os.makedirs(SAVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    settings['split']['params']['n_splits'] = 2\n",
    "    settings['globals']['num_epochs'] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv(PATH_TRAIN)\n",
    "train_targets = pd.read_csv(PATH_TRAIN_SCORED)\n",
    "# test_features = pd.read_csv(PATH_TEST)\n",
    "train_drug = pd.read_csv(PATH_DRUGID)\n",
    "# group696 = pd.read_csv(PATH_GROUP696)\n",
    "group328 = pd.read_csv(PATH_GROUP328)\n",
    "\n",
    "# ss = pd.read_csv(PATH_SUB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_top8 を作成\n",
    "mask_top8 = []\n",
    "for drug_id in train_drug.drug_id.values:\n",
    "    if drug_id in TOP8_DRUG:\n",
    "        mask_top8.append(True)\n",
    "    else:\n",
    "        mask_top8.append(False)\n",
    "mask_top8 = np.array(mask_top8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_col = 10\n",
    "step_row = 11\n",
    "\n",
    "if DEBUG:\n",
    "    print(':: debug mode ::')\n",
    "    train_features = train_features.iloc[::step_row, :end_col].reset_index(drop=True)\n",
    "    train_targets = train_targets.iloc[::step_row, :].reset_index(drop=True)\n",
    "    mask_top8 = mask_top8[::step_row]\n",
    "    train_drug = train_drug.iloc[::step_row, :].reset_index(drop=True)\n",
    "#     group696 = group696.iloc[::step_row, :].reset_index(drop=True)\n",
    "    group328 = group328.iloc[::step_row, :].reset_index(drop=True)\n",
    "#     test_features = test_features.iloc[::100, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_trt = (train_features['cp_type'] == 'trt_cp').values\n",
    "train = preprocess(train_features)\n",
    "FEAT_COLUMNS = train_features.columns[2:]\n",
    "# test = preprocess(test_features).values\n",
    "\n",
    "del train_targets['sig_id']\n",
    "\n",
    "target_cols = [col for col in train_targets.columns]\n",
    "train, targets = remove_ctl_cp(train, train_targets)\n",
    "# train_targets = train_targets.loc[train['cp_type']==0].reset_index(drop=True).values\n",
    "# train = train.loc[train['cp_type']==0].reset_index(drop=True).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:         (21948, 874)\n",
      "train_targets shape: (21948, 206)\n"
     ]
    }
   ],
   "source": [
    "print(f'train shape:         {train.shape}')\n",
    "# print(f'test shape:          {test.shape}')\n",
    "print(f'train_targets shape: {targets.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "fold分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.61 s, sys: 0 ns, total: 5.61 s\n",
      "Wall time: 5.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_fold = get_not_drug_leak_folds(settings['split']['params']['n_splits'], train_features, train_drug, group328)\n",
    "df_fold['group'] = group328.group.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5  1  3  2  4 -1]\n",
      "[5 1 3 2 4]\n"
     ]
    }
   ],
   "source": [
    "splitter = KFold(n_splits=settings['split']['params']['n_splits'], random_state=1, shuffle=True)\n",
    "for top8_i in range(len(TOP8_DRUG)):\n",
    "    mask_drug = df_fold['drug_id'] == TOP8_DRUG[top8_i]\n",
    "\n",
    "    for fold_i, (train_idx, valid_idx) in enumerate(splitter.split(df_fold[mask_drug])):\n",
    "#         df_fold[['fold']][mask_drug].iloc[valid_idx, :] = fold_i + 1\n",
    "#         df_fold[['fold']][mask_drug] = fold_i + 1\n",
    "        _df_fold = df_fold[mask_drug]\n",
    "        _df_fold.fold.values[valid_idx] = fold_i + 1\n",
    "        df_fold.fold[mask_drug] = _df_fold.fold.values\n",
    "print(df_fold.fold.unique())\n",
    "print(df_fold[mask_trt].fold.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "top8の除去"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[~mask_top8[mask_trt]]\n",
    "targets = targets[~mask_top8[mask_trt]]\n",
    "df_fold = df_fold[mask_trt & ~mask_top8].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = settings['split']['params']['n_splits']\n",
    "n_epochs = settings['globals']['num_epochs']\n",
    "splitter = MultilabelStratifiedKFold(**settings['split']['params'])\n",
    "device = settings['globals']['device']\n",
    "# criterion = criterion_ = nn.__getattribute__(\n",
    "#     settings['loss']['name'])(**settings['loss']['params'])\n",
    "criterion = SmoothBCEwLogits(**settings['loss']['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Sat Nov 28 20:25:39 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 01/45   loss: 0.43733   val_loss: 0.09375   mean_log_loss: 0.09257\n",
      "Validation loss decreased (inf --> 0.093749).  Saving model ...\n",
      "Epoch 02/45   loss: 0.04765   val_loss: 0.02759   mean_log_loss: 0.02521\n",
      "Validation loss decreased (0.093749 --> 0.027594).  Saving model ...\n",
      "Epoch 03/45   loss: 0.02765   val_loss: 0.02501   mean_log_loss: 0.02235\n",
      "Validation loss decreased (0.027594 --> 0.025007).  Saving model ...\n",
      "Epoch 04/45   loss: 0.02625   val_loss: 0.02443   mean_log_loss: 0.02165\n",
      "Validation loss decreased (0.025007 --> 0.024429).  Saving model ...\n",
      "Epoch 05/45   loss: 0.02533   val_loss: 0.02401   mean_log_loss: 0.02117\n",
      "Validation loss decreased (0.024429 --> 0.024008).  Saving model ...\n",
      "Epoch 06/45   loss: 0.02494   val_loss: 0.02373   mean_log_loss: 0.02085\n",
      "Validation loss decreased (0.024008 --> 0.023732).  Saving model ...\n",
      "Epoch 07/45   loss: 0.02467   val_loss: 0.02363   mean_log_loss: 0.02073\n",
      "Validation loss decreased (0.023732 --> 0.023629).  Saving model ...\n",
      "Epoch 08/45   loss: 0.02452   val_loss: 0.02343   mean_log_loss: 0.02053\n",
      "Validation loss decreased (0.023629 --> 0.023431).  Saving model ...\n",
      "Epoch 09/45   loss: 0.02431   val_loss: 0.02337   mean_log_loss: 0.02045\n",
      "Validation loss decreased (0.023431 --> 0.023368).  Saving model ...\n",
      "Epoch 10/45   loss: 0.02441   val_loss: 0.02338   mean_log_loss: 0.02046\n",
      "EarlyStopping counter: 1 out of 15\n",
      "Epoch 11/45   loss: 0.02436   val_loss: 0.02339   mean_log_loss: 0.02047\n",
      "EarlyStopping counter: 2 out of 15\n",
      "Epoch 12/45   loss: 0.02432   val_loss: 0.02336   mean_log_loss: 0.02045\n",
      "Validation loss decreased (0.023368 --> 0.023358).  Saving model ...\n",
      "Epoch 13/45   loss: 0.02450   val_loss: 0.02348   mean_log_loss: 0.02055\n",
      "EarlyStopping counter: 1 out of 15\n",
      "Epoch 14/45   loss: 0.02439   val_loss: 0.02338   mean_log_loss: 0.02044\n",
      "EarlyStopping counter: 2 out of 15\n",
      "Epoch 15/45   loss: 0.02441   val_loss: 0.02333   mean_log_loss: 0.02037\n",
      "Validation loss decreased (0.023358 --> 0.023325).  Saving model ...\n",
      "Epoch 16/45   loss: 0.02433   val_loss: 0.02346   mean_log_loss: 0.02045\n",
      "EarlyStopping counter: 1 out of 15\n",
      "Epoch 17/45   loss: 0.02422   val_loss: 0.02312   mean_log_loss: 0.02010\n",
      "Validation loss decreased (0.023325 --> 0.023119).  Saving model ...\n",
      "Epoch 18/45   loss: 0.02430   val_loss: 0.02361   mean_log_loss: 0.02052\n",
      "EarlyStopping counter: 1 out of 15\n",
      "Epoch 19/45   loss: 0.02424   val_loss: 0.02322   mean_log_loss: 0.02015\n",
      "EarlyStopping counter: 2 out of 15\n",
      "Epoch 20/45   loss: 0.02390   val_loss: 0.02319   mean_log_loss: 0.02011\n",
      "EarlyStopping counter: 3 out of 15\n",
      "Epoch 21/45   loss: 0.02386   val_loss: 0.02306   mean_log_loss: 0.01997\n",
      "Validation loss decreased (0.023119 --> 0.023058).  Saving model ...\n",
      "Epoch 22/45   loss: 0.02350   val_loss: 0.02269   mean_log_loss: 0.01962\n",
      "Validation loss decreased (0.023058 --> 0.022691).  Saving model ...\n",
      "Epoch 23/45   loss: 0.02343   val_loss: 0.02298   mean_log_loss: 0.01991\n",
      "EarlyStopping counter: 1 out of 15\n",
      "Epoch 24/45   loss: 0.02353   val_loss: 0.02293   mean_log_loss: 0.01972\n",
      "EarlyStopping counter: 2 out of 15\n",
      "Epoch 25/45   loss: 0.02331   val_loss: 0.02280   mean_log_loss: 0.01963\n",
      "EarlyStopping counter: 3 out of 15\n",
      "Epoch 26/45   loss: 0.02301   val_loss: 0.02258   mean_log_loss: 0.01942\n",
      "Validation loss decreased (0.022691 --> 0.022580).  Saving model ...\n",
      "Epoch 27/45   loss: 0.02298   val_loss: 0.02267   mean_log_loss: 0.01949\n",
      "EarlyStopping counter: 1 out of 15\n",
      "Epoch 28/45   loss: 0.02274   val_loss: 0.02253   mean_log_loss: 0.01937\n",
      "Validation loss decreased (0.022580 --> 0.022534).  Saving model ...\n",
      "Epoch 29/45   loss: 0.02260   val_loss: 0.02243   mean_log_loss: 0.01928\n",
      "Validation loss decreased (0.022534 --> 0.022431).  Saving model ...\n",
      "Epoch 30/45   loss: 0.02261   val_loss: 0.02241   mean_log_loss: 0.01926\n",
      "Validation loss decreased (0.022431 --> 0.022408).  Saving model ...\n",
      "Epoch 31/45   loss: 0.02256   val_loss: 0.02245   mean_log_loss: 0.01929\n",
      "EarlyStopping counter: 1 out of 15\n",
      "Epoch 32/45   loss: 0.02263   val_loss: 0.02245   mean_log_loss: 0.01929\n",
      "EarlyStopping counter: 2 out of 15\n",
      "Epoch 33/45   loss: 0.02282   val_loss: 0.02244   mean_log_loss: 0.01928\n",
      "EarlyStopping counter: 3 out of 15\n",
      "Epoch 34/45   loss: 0.02247   val_loss: 0.02244   mean_log_loss: 0.01927\n",
      "EarlyStopping counter: 4 out of 15\n",
      "Epoch 35/45   loss: 0.02254   val_loss: 0.02238   mean_log_loss: 0.01922\n",
      "Validation loss decreased (0.022408 --> 0.022381).  Saving model ...\n",
      "Epoch 36/45   loss: 0.02259   val_loss: 0.02243   mean_log_loss: 0.01927\n",
      "EarlyStopping counter: 1 out of 15\n",
      "Epoch 37/45   loss: 0.02264   val_loss: 0.02238   mean_log_loss: 0.01917\n",
      "Validation loss decreased (0.022381 --> 0.022376).  Saving model ...\n",
      "Epoch 38/45   loss: 0.02255   val_loss: 0.02236   mean_log_loss: 0.01916\n",
      "Validation loss decreased (0.022376 --> 0.022362).  Saving model ...\n",
      "Epoch 39/45   loss: 0.02247   val_loss: 0.02240   mean_log_loss: 0.01919\n",
      "EarlyStopping counter: 1 out of 15\n",
      "Epoch 40/45   loss: 0.02227   val_loss: 0.02226   mean_log_loss: 0.01906\n",
      "Validation loss decreased (0.022362 --> 0.022262).  Saving model ...\n",
      "Epoch 41/45   loss: 0.02210   val_loss: 0.02224   mean_log_loss: 0.01910\n",
      "Validation loss decreased (0.022262 --> 0.022241).  Saving model ...\n",
      "Epoch 42/45   loss: 0.02199   val_loss: 0.02229   mean_log_loss: 0.01904\n",
      "EarlyStopping counter: 1 out of 15\n",
      "Epoch 43/45   loss: 0.02200   val_loss: 0.02232   mean_log_loss: 0.01906\n",
      "EarlyStopping counter: 2 out of 15\n",
      "Epoch 44/45   loss: 0.02181   val_loss: 0.02219   mean_log_loss: 0.01896\n",
      "Validation loss decreased (0.022241 --> 0.022188).  Saving model ...\n",
      "Epoch 45/45   loss: 0.02157   val_loss: 0.02232   mean_log_loss: 0.01906\n",
      "EarlyStopping counter: 1 out of 15\n",
      ":: best mean_log_loss: 0.01896 ::\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Sat Nov 28 20:26:42 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 01/45   loss: 0.45393   val_loss: 0.09757   mean_log_loss: 0.09636\n",
      "Validation loss decreased (inf --> 0.097566).  Saving model ...\n",
      "Epoch 02/45   loss: 0.04900   val_loss: 0.02766   mean_log_loss: 0.02533\n",
      "Validation loss decreased (0.097566 --> 0.027663).  Saving model ...\n",
      "Epoch 03/45   loss: 0.02735   val_loss: 0.02480   mean_log_loss: 0.02211\n",
      "Validation loss decreased (0.027663 --> 0.024795).  Saving model ...\n",
      "Epoch 04/45   loss: 0.02585   val_loss: 0.02443   mean_log_loss: 0.02172\n",
      "Validation loss decreased (0.024795 --> 0.024431).  Saving model ...\n",
      "Epoch 05/45   loss: 0.02531   val_loss: 0.02402   mean_log_loss: 0.02118\n",
      "Validation loss decreased (0.024431 --> 0.024020).  Saving model ...\n",
      "Epoch 06/45   loss: 0.02494   val_loss: 0.02380   mean_log_loss: 0.02093\n",
      "Validation loss decreased (0.024020 --> 0.023798).  Saving model ...\n",
      "Epoch 07/45   loss: 0.02463   val_loss: 0.02353   mean_log_loss: 0.02063\n",
      "Validation loss decreased (0.023798 --> 0.023530).  Saving model ...\n",
      "Epoch 08/45   loss: 0.02454   val_loss: 0.02353   mean_log_loss: 0.02061\n",
      "Validation loss decreased (0.023530 --> 0.023526).  Saving model ...\n",
      "Epoch 09/45   loss: 0.02434   val_loss: 0.02358   mean_log_loss: 0.02065\n",
      "EarlyStopping counter: 1 out of 15\n",
      "Epoch 10/45   loss: 0.02439   val_loss: 0.02352   mean_log_loss: 0.02060\n",
      "Validation loss decreased (0.023526 --> 0.023522).  Saving model ...\n",
      "Epoch 11/45   loss: 0.02432   val_loss: 0.02352   mean_log_loss: 0.02061\n",
      "EarlyStopping counter: 1 out of 15\n",
      "Epoch 12/45   loss: 0.02438   val_loss: 0.02352   mean_log_loss: 0.02059\n",
      "Validation loss decreased (0.023522 --> 0.023516).  Saving model ...\n",
      "Epoch 13/45   loss: 0.02422   val_loss: 0.02344   mean_log_loss: 0.02051\n",
      "Validation loss decreased (0.023516 --> 0.023443).  Saving model ...\n",
      "Epoch 14/45   loss: 0.02435   val_loss: 0.02345   mean_log_loss: 0.02050\n",
      "EarlyStopping counter: 1 out of 15\n",
      "Epoch 15/45   loss: 0.02423   val_loss: 0.02334   mean_log_loss: 0.02036\n",
      "Validation loss decreased (0.023443 --> 0.023336).  Saving model ...\n",
      "Epoch 16/45   loss: 0.02431   val_loss: 0.02339   mean_log_loss: 0.02037\n",
      "EarlyStopping counter: 1 out of 15\n",
      "Epoch 17/45   loss: 0.02416   val_loss: 0.02330   mean_log_loss: 0.02028\n",
      "Validation loss decreased (0.023336 --> 0.023304).  Saving model ...\n",
      "Epoch 18/45   loss: 0.02406   val_loss: 0.02325   mean_log_loss: 0.02021\n",
      "Validation loss decreased (0.023304 --> 0.023254).  Saving model ...\n",
      "Epoch 19/45   loss: 0.02397   val_loss: 0.02309   mean_log_loss: 0.02000\n",
      "Validation loss decreased (0.023254 --> 0.023085).  Saving model ...\n",
      "Epoch 20/45   loss: 0.02417   val_loss: 0.02317   mean_log_loss: 0.02007\n",
      "EarlyStopping counter: 1 out of 15\n",
      "Epoch 21/45   loss: 0.02381   val_loss: 0.02289   mean_log_loss: 0.01974\n",
      "Validation loss decreased (0.023085 --> 0.022889).  Saving model ...\n",
      "Epoch 22/45   loss: 0.02383   val_loss: 0.02306   mean_log_loss: 0.01997\n",
      "EarlyStopping counter: 1 out of 15\n",
      "Epoch 23/45   loss: 0.02354   val_loss: 0.02274   mean_log_loss: 0.01956\n",
      "Validation loss decreased (0.022889 --> 0.022736).  Saving model ...\n",
      "Epoch 24/45   loss: 0.02344   val_loss: 0.02291   mean_log_loss: 0.01971\n",
      "EarlyStopping counter: 1 out of 15\n",
      "Epoch 25/45   loss: 0.02306   val_loss: 0.02299   mean_log_loss: 0.01980\n",
      "EarlyStopping counter: 2 out of 15\n",
      "Epoch 26/45   loss: 0.02301   val_loss: 0.02259   mean_log_loss: 0.01941\n",
      "Validation loss decreased (0.022736 --> 0.022588).  Saving model ...\n",
      "Epoch 27/45   loss: 0.02287   val_loss: 0.02259   mean_log_loss: 0.01939\n",
      "Validation loss decreased (0.022588 --> 0.022588).  Saving model ...\n",
      "Epoch 28/45   loss: 0.02279   val_loss: 0.02256   mean_log_loss: 0.01939\n",
      "Validation loss decreased (0.022588 --> 0.022558).  Saving model ...\n",
      "Epoch 29/45   loss: 0.02273   val_loss: 0.02254   mean_log_loss: 0.01935\n",
      "Validation loss decreased (0.022558 --> 0.022542).  Saving model ...\n",
      "Epoch 30/45   loss: 0.02278   val_loss: 0.02257   mean_log_loss: 0.01936\n",
      "EarlyStopping counter: 1 out of 15\n",
      "Epoch 31/45   loss: 0.02264   val_loss: 0.02256   mean_log_loss: 0.01937\n",
      "EarlyStopping counter: 2 out of 15\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# mean_log_loss_list, _oof, df_pi = run(splitter, train, targets, MoaModel, show_log=isShowLog, pi=isPI)\n",
    "mean_log_loss_list, _oof, df_pi = run_not_drug_leak(df_fold, train, targets,\n",
    "                                                    MoaModel, show_log=isShowLog, \n",
    "                                                    pi=isPI, mixup=MIXUP, smote=isSMOTE)\n",
    "# result\n",
    "mean_mean_log_loss = np.mean(mean_log_loss_list)\n",
    "std_mean_log_loss = np.std(mean_log_loss_list)\n",
    "# oof = add_ctl_cp_oof(_oof)\n",
    "oof = _oof\n",
    "oof_score = mean_log_loss(targets, oof)\n",
    "print('-'*100)\n",
    "print(f\"mean_log_loss(all fold): {mean_mean_log_loss:5.6f} +- {std_mean_log_loss:5.6f}\")\n",
    "print(f\"mean_log_loss(oof):      {oof_score:5.6f}\")\n",
    "print('-'*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save oof"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "_df_oof = pd.DataFrame(_oof, columns=target_cols)\n",
    "_df_oof['fold'] = -1\n",
    "for i, (idx_trn, idx_val) in enumerate(splitter.split(train, targets)):\n",
    "    _df_oof.iloc[idx_val, -1] = i + 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_oof = pd.DataFrame(oof, columns=target_cols)\n",
    "df_oof['fold'] = -1\n",
    "df_oof['fold'][mask_trt] = _df_oof['fold'].values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "save_path = f'{SAVE_DIR}oof.csv'\n",
    "df_oof.to_csv(save_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save permutation importance"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "save_path = f'{SAVE_DIR}permutation_importance.csv'\n",
    "save_path"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "if isPI:\n",
    "    df_pi.to_csv(save_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_list = np.array(train_targets.sum(axis=0).values)\n",
    "logloss_cols = np.array([log_loss(train_targets.iloc[:, i], df_oof.iloc[:, i]) for i in range(len(target_cols))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logloss = pd.read_csv(PATH_ESTIMATED_LOGLOSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(n_list, logloss_cols, alpha=0.3)\n",
    "plt.scatter(df_logloss.n_target, df_logloss.best_loss_list, s=2, color='red', label='estimated')\n",
    "plt.xlabel('n target==1')\n",
    "plt.ylabel('logloss per target cols')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
