{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "- nb022の改良\n",
    "- mixupのハイパラチューニング\n",
    "- top8を除く\n",
    "- ctrlを除く"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21549ec\n"
     ]
    }
   ],
   "source": [
    "# gitのhash\n",
    "import subprocess\n",
    "cmd = \"git rev-parse --short HEAD\"\n",
    "hash = subprocess.check_output(cmd.split()).strip().decode('utf-8')\n",
    "print(hash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic\n",
    "NB = '026'\n",
    "DEBUG = False \n",
    "isPI = False\n",
    "isShowLog = False\n",
    "MIXUP = True\n",
    "\n",
    "PATH_TRAIN = '../data_ignore/input/train_features.csv'\n",
    "PATH_TRAIN_SCORED = '../data_ignore/input/train_targets_scored.csv'\n",
    "PATH_TRAIN_NONSCORED = '../data_ignore/input/train_targets_nonscored.csv'\n",
    "PATH_SUB = '../data_ignore/input/sample_submission.csv'\n",
    "PATH_TEST = '../data_ignore/input/test_features.csv'\n",
    "SAVE_DIR = f'../data_ignore/output_nb/nb{NB}/'\n",
    "PATH_DRUGID = '../data_ignore/input/train_drug.csv'\n",
    "PATH_GROUP696 = './../data_ignore/output_nb/nb004/group.csv'\n",
    "PATH_ESTIMATED_LOGLOSS = './../data_ignore/output_nb/nb017/estimated_logloss.csv'\n",
    "TOP8_DRUG = ['87d714366', '9f80f3f77', '8b87a7a83', '5628cb3ee', 'd08af5d4b', '292ab2c28', 'd50f18348', 'd1b47f29d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_str = \"\"\"\n",
    "globals:\n",
    "  seed: 2020\n",
    "  device: cuda\n",
    "  num_epochs: 80\n",
    "\n",
    "dataset:\n",
    "  name: \n",
    "  params:\n",
    "    \n",
    "split:\n",
    "  name: MultiStratifiedKFold\n",
    "  params:\n",
    "    n_splits: 5\n",
    "    random_state: 42\n",
    "    shuffle: True\n",
    "\n",
    "loader:\n",
    "  train:\n",
    "    batch_size: 512\n",
    "    shuffle: True\n",
    "    num_workers: 10\n",
    "    pin_memory: True\n",
    "    drop_last: True\n",
    "  val:\n",
    "    batch_size: 512\n",
    "    shuffle: False\n",
    "    num_workers: 10\n",
    "    pin_memory: True\n",
    "    drop_last: False\n",
    "\n",
    "model:\n",
    "  name: \n",
    "  params:\n",
    "\n",
    "loss:\n",
    "  name: SmoothLogitsLoss\n",
    "  params: {}\n",
    "\n",
    "optimizer:\n",
    "  name: Adam\n",
    "  params:\n",
    "    lr: 0.005\n",
    "\n",
    "scheduler:\n",
    "  name: CosineAnnealingLR\n",
    "  params:\n",
    "    T_max: 10\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import everything I need :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py:886: MatplotlibDeprecationWarning: \n",
      "examples.directory is deprecated; in the future, examples will be found relative to the 'datapath' directory.\n",
      "  \"found relative to the 'datapath' directory.\".format(key))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import yaml\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from pdb import set_trace as st\n",
    "from fastprogress import progress_bar\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import KFold\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df_):\n",
    "    df = df_.copy()\n",
    "    df.loc[:, 'cp_type'] = df.loc[:, 'cp_type'].map({'trt_cp': 0, 'ctl_vehicle': 1})\n",
    "    df.loc[:, 'cp_dose'] = df.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n",
    "#     df.loc[:, 'cp_time'] = df.loc[:, 'cp_time'].map({24: 0, 48: 1, 72: 2})\n",
    "    del df['sig_id']\n",
    "    return df\n",
    "\n",
    "def remove_ctl_cp(features_, target_):\n",
    "    features = features_.copy()\n",
    "    target = target_.copy()\n",
    "#     bools = features['cp_type'] != 'ctl_vehicle'\n",
    "    bools = features['cp_type'] != 1\n",
    "    features = features[bools].reset_index(drop=True)\n",
    "    features = features.drop(['cp_type'], axis=1).values\n",
    "    target = target[bools].reset_index(drop=True).values\n",
    "    return features, target\n",
    "\n",
    "def add_ctl_cp_oof(oof):\n",
    "    oof_new = np.zeros_like(train_targets).astype(float)\n",
    "    bools = train_features['cp_type'] != 'ctl_vehicle'\n",
    "    oof_new[bools, :] = oof\n",
    "    return oof_new\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "class permutation_importance():\n",
    "    def __init__(self, model, metric):\n",
    "        self.is_computed = False\n",
    "        self.n_feat = 0\n",
    "        self.base_score = 0\n",
    "        self.model = model\n",
    "        self.metric = metric\n",
    "        self.df_result = []\n",
    "    \n",
    "    def compute(self, _X_valid, y_valid):\n",
    "        X_valid = pd.DataFrame(_X_valid, columns=FEAT_COLUMNS)\n",
    "        self.n_feat = len(X_valid.columns)\n",
    "        \n",
    "        val_set = MoaDataset(_X_valid, y_valid, mode='train')\n",
    "        dataloaders = {'val': DataLoader(val_set, **settings['loader']['val'])}\n",
    "        y_valid_pred = get_epoch_pred(self.model, device, dataloaders['val'])\n",
    "        \n",
    "        \n",
    "        self.base_score = self.metric(y_valid, y_valid_pred)\n",
    "        self.df_result = pd.DataFrame({'feat': X_valid.columns, \n",
    "                                       'score': np.zeros(self.n_feat),\n",
    "                                       'score_diff': np.zeros(self.n_feat)})\n",
    "        \n",
    "        # predict\n",
    "        for i, col in enumerate(progress_bar(X_valid.columns)):\n",
    "            df_perm = X_valid.copy()\n",
    "            np.random.seed(1)\n",
    "            df_perm[col] = np.random.permutation(df_perm[col])\n",
    "            \n",
    "#             y_valid_pred = self.model.predict(df_perm)\n",
    "            val_set = MoaDataset(df_perm.values, y_valid, mode='train')\n",
    "            dataloaders = {'val': DataLoader(val_set, **settings['loader']['val'])}\n",
    "            y_valid_pred = get_epoch_pred(self.model, device, dataloaders['val'])\n",
    "            \n",
    "            score = self.metric(y_valid, y_valid_pred)\n",
    "            self.df_result['score'][self.df_result['feat']==col] = score\n",
    "            self.df_result['score_diff'][self.df_result['feat']==col] = self.base_score - score\n",
    "        self.is_computed = True\n",
    "    \n",
    "    def get_negative_feature(self):\n",
    "        assert self.is_computed!=False, 'compute メソッドが実行されていません'\n",
    "        idx = self.df_result['score_diff'] < 0\n",
    "        return self.df_result.loc[idx, 'feat'].values.tolist()\n",
    "        \n",
    "    def get_positive_feature(self):\n",
    "        assert self.is_computed!=False, 'compute メソッドが実行されていません'\n",
    "        idx = self.df_result['score_diff'] > 0\n",
    "        return self.df_result.loc[idx, 'feat'].values.tolist()\n",
    "    \n",
    "    def show_permutation_importance(self, score_type='loss'):\n",
    "        '''score_type = 'loss' or 'accuracy'  '''\n",
    "        assert self.is_computed!=False, 'compute メソッドが実行されていません'\n",
    "        if score_type=='loss':\n",
    "            ascending = True\n",
    "        elif score_type=='accuracy':\n",
    "            ascending = False\n",
    "        else:\n",
    "            ascending = ''\n",
    "        \n",
    "        plt.figure(figsize=(15, int(0.25*self.n_feat)))\n",
    "        sns.barplot(x=\"score_diff\", y=\"feat\", data=self.df_result.sort_values(by=\"score_diff\", ascending=ascending))\n",
    "        plt.title('base_score - permutation_score')\n",
    "\n",
    "def get_not_drug_leak_folds(n_splits, train_features, train_drug, gruoup696):\n",
    "    '''\n",
    "    n_splits だけfoldを作成する。\n",
    "    ただし、cp_type = ctl_vehicle と、top8にはfold=-1を割り振っている。\n",
    "    \n",
    "    696group のcsv: https://www.kaggle.com/fkubota/moa-nb004-696group\n",
    "    \n",
    "    ::example::\n",
    "    train_features = pd.read_csv(\"train_features.csv\")\n",
    "    train_drug = pd.read_csv(\"train_drug.csv\")\n",
    "    group696 = pd.read_csv(\"MoA_nb004_696group/group.csv\")\n",
    "    df_fold = get_not_drug_leak_folds(5, train_features, train_drug, group696)\n",
    "    '''\n",
    "    TOP8_DRUG = ['87d714366', '9f80f3f77', '8b87a7a83', '5628cb3ee', 'd08af5d4b', '292ab2c28', 'd50f18348', 'd1b47f29d']\n",
    "    mask_trt = (train_features['cp_type'] == 'trt_cp').values\n",
    "\n",
    "    # mask_top8 を作成\n",
    "    mask_top8 = []\n",
    "    for drug_id in train_drug.drug_id.values:\n",
    "        if drug_id in TOP8_DRUG:\n",
    "            mask_top8.append(True)\n",
    "        else:\n",
    "            mask_top8.append(False)\n",
    "    mask_top8 = np.array(mask_top8)\n",
    "    \n",
    "    # trt かつ top8 以外を抜き出す\n",
    "    # group = 0 は要素数が多いので一番最後にやるようにする\n",
    "    drug_groups = group696[mask_trt & ~mask_top8].group.values\n",
    "    groups = np.sort(group696[mask_trt & ~mask_top8].group.unique())\n",
    "    groups = groups[1:]\n",
    "    groups = np.append(groups, 0)\n",
    "    \n",
    "    # 各グループにfoldを割り振る\n",
    "    tile = []\n",
    "    train_drug_trt = train_drug[mask_trt & ~mask_top8]\n",
    "    train_drug_trt['fold'] = -1\n",
    "    for i_grp, grp in enumerate(groups):\n",
    "        if i_grp == 0:\n",
    "            tile = np.arange(1, n_splits+1).astype(int)\n",
    "\n",
    "        mask_grp = drug_groups == grp\n",
    "        drug_rank = train_drug[mask_trt & ~mask_top8][mask_grp].drug_id.value_counts()\n",
    "\n",
    "        n_repeat = np.ceil(len(drug_rank)/n_splits).astype(int)\n",
    "        folds = np.tile(tile, n_repeat)[:len(drug_rank)]\n",
    "\n",
    "        for i, drug_id in enumerate(drug_rank.index.sort_values()):\n",
    "            mask = train_drug_trt.drug_id.values == drug_id\n",
    "            train_drug_trt.fold[mask] = folds[i]\n",
    "        tile = train_drug_trt.fold.value_counts()[::-1][:n_splits].index\n",
    "        \n",
    "    train_drug_fold = train_drug.copy()\n",
    "    train_drug_fold['fold'] = -1\n",
    "    train_drug_fold['fold'][mask_trt & ~mask_top8] = train_drug_trt.fold.values\n",
    "    return train_drug_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoaModel(nn.Module):\n",
    "    def __init__(self, n_input, n_output):\n",
    "        super(MoaModel, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(n_input)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(n_input, 2048))\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(2048)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.dense2 = nn.utils.weight_norm(nn.Linear(2048, 1048))\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(1048)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "#         self.dense3 = nn.utils.weight_norm(nn.Linear(1048, 206))\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(1048, n_output))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.dense1(x))\n",
    "        \n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.dense2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x_raw = self.dense3(x)\n",
    "        x_sigmoid = F.sigmoid(x_raw)\n",
    "        \n",
    "        return x_sigmoid, x_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoaDataset(Dataset):\n",
    "    def __init__(self, df, targets, mode):\n",
    "        self.mode = mode\n",
    "        self.df = df\n",
    "#         self.targets = targets\n",
    "        if mode=='train':\n",
    "            self.targets = targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == 'train':\n",
    "            return torch.FloatTensor(self.df[idx]), torch.FloatTensor(self.targets[idx])\n",
    "        elif self.mode == 'val':\n",
    "            return torch.FloatTensor(self.df[idx]), 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_log_loss(y_true, y_pred):\n",
    "    metrics = []\n",
    "#     for i in range(y_true.shape[1]):\n",
    "#         metrics.append(log_loss(y_true[:, i], y_pred[:, i].astype(float), labels=[0,1]))\n",
    "#     return np.mean(metrics)\n",
    "    y_true =  y_true.astype(np.float64).ravel()\n",
    "    y_pred =  y_pred.astype(np.float64).ravel()\n",
    "    return log_loss(y_true, y_pred, labels=[0, 1])\n",
    "\n",
    "class SmoothBCEwLogits(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.001):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n",
    "        assert 0 <= smoothing < 1\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1),\n",
    "            self.smoothing)\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets,self.weight)\n",
    "\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss\n",
    "\n",
    "class FocalLoss2d(nn.modules.loss._WeightedLoss):\n",
    "    '''\n",
    "    https://github.com/andrijdavid/FocalLoss/blob/master/focalloss.py\n",
    "    '''\n",
    "    def __init__(self, gamma=2, weight=None, size_average=None, ignore_index=-100,\n",
    "                 reduce=None, reduction='mean', balance_param=0.25):\n",
    "        super(FocalLoss2d, self).__init__(weight, size_average, reduce, reduction)\n",
    "        self.gamma = gamma\n",
    "        self.weight = weight\n",
    "        self.size_average = size_average\n",
    "        self.ignore_index = ignore_index\n",
    "        self.balance_param = balance_param\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        \n",
    "        # inputs and targets are assumed to be BatchxClasses\n",
    "        assert len(input.shape) == len(target.shape)\n",
    "        assert input.size(0) == target.size(0)\n",
    "        assert input.size(1) == target.size(1)\n",
    "        \n",
    "        weight = Variable(self.weight)\n",
    "           \n",
    "        # compute the negative likelyhood\n",
    "        logpt = - F.binary_cross_entropy_with_logits(input, target, pos_weight=self.weight, reduction=self.reduction)\n",
    "#         logpt = - F.binary_cross_entropy_with_logits(input, target, reduction=self.reduction)\n",
    "        pt = torch.exp(logpt)\n",
    "\n",
    "        # compute the loss\n",
    "        focal_loss = -( (1-pt)**self.gamma ) * logpt\n",
    "        balanced_focal_loss = self.balance_param * focal_loss\n",
    "        return balanced_focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"\n",
    "    Early stops the training if validation loss doesn't improve after a given patience.\n",
    "    https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\n",
    "    \"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "#         self.best_state_dict = {}\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "#         if not DEBUG:\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "#         self.best_state_dict = model.state_dict()\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "def mixup_data(x, y, alpha=1.0, use_cuda=True):\n",
    "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    if use_cuda:\n",
    "        index = torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index = torch.randperm(batch_size)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, device, train_loader, optimizer, scheduler, criterion, mixup=False, mixup_alpha=1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        if mixup:\n",
    "            x, y_a, y_b, lam = mixup_data(x, y, mixup_alpha)\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(True):\n",
    "            pred_sigmoid, pred_raw = model(x)\n",
    "            if mixup:\n",
    "                loss = mixup_criterion(criterion, pred_raw, y_a, y_b, lam)\n",
    "            else:\n",
    "                loss = criterion(pred_raw, y)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        running_loss += loss.item() / len(train_loader)\n",
    "    scheduler.step()\n",
    "    return running_loss\n",
    "\n",
    "def get_epoch_loss_score(model, device, valid_loader, criterion, optimizer):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    targets = []\n",
    "    preds = []\n",
    "    for i, (x, y) in enumerate(valid_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(False):\n",
    "            pred_sigmoid, pred_raw = model(x)\n",
    "            loss = criterion(pred_raw, y)\n",
    "        running_loss += loss.item() / len(valid_loader)\n",
    "        targets.append(y)\n",
    "        preds.append(pred_sigmoid)\n",
    "    targets = torch.cat(targets, dim=0).cpu().numpy()\n",
    "    preds = torch.cat(preds, dim=0).cpu().numpy()\n",
    "    _mean_log_loss = mean_log_loss(targets, preds)\n",
    "    return running_loss, _mean_log_loss, preds\n",
    "\n",
    "def get_epoch_pred(model, device, valid_loader):\n",
    "    model.eval()\n",
    "    targets = []\n",
    "    preds = []\n",
    "    for i, (x, y) in enumerate(valid_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        with torch.set_grad_enabled(False):\n",
    "            pred_sigmoid, pred_raw = model(x)\n",
    "        targets.append(y)\n",
    "        preds.append(pred_sigmoid)\n",
    "    targets = torch.cat(targets, dim=0).cpu().numpy()\n",
    "    preds = torch.cat(preds, dim=0).cpu().numpy()\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fold(dataloaders, shape, checkpoint_path, ModelClass, show_log=True, mixup=False, mixup_alpha=1):\n",
    "    device = torch.device(\"cuda\")\n",
    "    model = ModelClass(shape[0], shape[1]).to(device)\n",
    "#     model = ModelClass(train.shape[1], ).to(device)\n",
    "    early_stopping = EarlyStopping(patience=15, verbose=show_log, path=checkpoint_path)\n",
    "    optimizer = optim.__getattribute__(settings['optimizer']['name'])(\n",
    "        model.parameters(), **settings['optimizer']['params'])\n",
    "    scheduler = optim.lr_scheduler.__getattribute__(settings['scheduler']['name'])(\n",
    "        optimizer, **settings['scheduler']['params'])\n",
    "    \n",
    "    best_valid_loss = np.inf\n",
    "    best_mean_log_loss = np.inf\n",
    "    best_preds = 0\n",
    "    val_losses = []\n",
    "    trn_losses = []\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss =  train_model(model, device, dataloaders['train'], optimizer, scheduler, criterion, mixup=mixup, mixup_alpha=mixup_alpha)\n",
    "        valid_loss, _mean_log_loss, preds = get_epoch_loss_score(model, device, dataloaders['val'], criterion, optimizer)\n",
    "\n",
    "        trn_losses.append(train_loss)\n",
    "        val_losses.append(valid_loss)\n",
    "        if show_log:\n",
    "            print(f\"Epoch {str(epoch+1).zfill(2)}/{n_epochs }   loss: {train_loss:5.5f}   val_loss: {valid_loss:5.5f}   mean_log_loss: {_mean_log_loss:5.5f}\")\n",
    "        early_stopping(valid_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "        if valid_loss < best_valid_loss: \n",
    "            best_valid_loss = valid_loss\n",
    "            best_mean_log_loss = _mean_log_loss\n",
    "            best_preds = preds\n",
    "    return best_mean_log_loss, best_preds, trn_losses, val_losses\n",
    "\n",
    "def run(splitter, train, targets, ModelClass, show_log=True, pi=False, mixup=False):\n",
    "    mean_log_loss_list = []\n",
    "    oof = np.zeros_like(targets).astype(float)\n",
    "    df_pi = pd.DataFrame(columns=['feat', 'score_diff'])\n",
    "    for n, (idx_trn, idx_val) in enumerate(splitter.split(train, targets)):\n",
    "        print('-'*100)\n",
    "        print(f':: start fold {n+1}/{n_splits} at {time.ctime()} ::')\n",
    "        print('-'*100)\n",
    "        X_trn, X_val = train[idx_trn], train[idx_val]\n",
    "        y_trn, y_val = targets[idx_trn], targets[idx_val]\n",
    "\n",
    "        train_set = MoaDataset(X_trn, y_trn, mode='train')\n",
    "        val_set = MoaDataset(X_val, y_val, mode='train')\n",
    "\n",
    "        dataloaders = {\n",
    "            'train': DataLoader(train_set, **settings['loader']['train']),\n",
    "            'val': DataLoader(val_set, **settings['loader']['val']),\n",
    "        }\n",
    "\n",
    "        checkpoint_path = f'{SAVE_DIR}Fold{n+1}of{n_splits}.pt'\n",
    "        shape = (X_trn.shape[1], y_trn.shape[1])\n",
    "        best_mean_log_loss, best_preds, trn_losses, val_losses =  run_fold(dataloaders, shape, checkpoint_path, ModelClass, show_log=show_log, mixup=mixup)\n",
    "\n",
    "        # result\n",
    "        print(f':: best mean_log_loss: {best_mean_log_loss:5.5f} ::')\n",
    "        mean_log_loss_list.append(best_mean_log_loss)\n",
    "        oof[idx_val, :] = best_preds\n",
    "        \n",
    "        # permutation importance\n",
    "        if pi:\n",
    "            device = torch.device(\"cuda\")\n",
    "            model = ModelClass(shape[0], shape[1]).to(device)\n",
    "            state_dict = torch.load(checkpoint_path)\n",
    "            model.load_state_dict(state_dict)\n",
    "            model.to(device)\n",
    "            model.eval()\n",
    "            pi = permutation_importance(model, mean_log_loss) # model と metric を渡す\n",
    "            pi.compute(X_val, y_val)\n",
    "            pi_result = pi.df_result\n",
    "            df_pi = pd.concat([df_pi, pi_result[['feat', 'score_diff']]])\n",
    "    #         pi.show_permutation_importance(score_type='loss')\n",
    "        \n",
    "        # plot\n",
    "        if show_log:\n",
    "            x = np.arange(1, len(trn_losses)+1)\n",
    "            plt.figure(figsize=(12, 7))\n",
    "            plt.plot(x[1:], trn_losses[1:], '--.', label='train')\n",
    "            plt.plot(x[1:], val_losses[1:], '--.', label='valid')\n",
    "            plt.title(f\"fold{n+1}/{n_splits} {settings['loss']['name']}\")\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        print('\\n')\n",
    "    \n",
    "    if pi:\n",
    "        # permutation score\n",
    "        plt.figure(figsize=(15, int(0.25*len(FEAT_COLUMNS))))\n",
    "        order = df_pi.groupby([\"feat\"]).mean()['score_diff'].reset_index().sort_values('score_diff', ascending=True)\n",
    "        sns.barplot(x=\"score_diff\", y=\"feat\", data=df_pi, order=order['feat'])\n",
    "        plt.title('base_score - permutation_score')\n",
    "        plt.show()\n",
    "    return mean_log_loss_list, oof, df_pi\n",
    "\n",
    "def run_not_drug_leak(df_fold, train, targets, ModelClass, show_log=True, pi=False, mixup=False, mixup_alpha=1):\n",
    "    mean_log_loss_list = []\n",
    "    oof = np.zeros_like(targets).astype(float)\n",
    "    df_pi = pd.DataFrame(columns=['feat', 'score_diff'])\n",
    "#     for n, (idx_trn, idx_val) in enumerate(splitter.split(train, targets)):\n",
    "    for n, fold_i in enumerate(df_fold['fold'].unique()):\n",
    "        print('-'*100)\n",
    "        print(f':: start fold {n+1}/{n_splits} at {time.ctime()} ::')\n",
    "        print('-'*100)\n",
    "        mask_fold = df_fold.fold == fold_i\n",
    "        X_trn, X_val = train[~mask_fold], train[mask_fold]\n",
    "        y_trn, y_val = targets[~mask_fold], targets[mask_fold]\n",
    "\n",
    "        train_set = MoaDataset(X_trn, y_trn, mode='train')\n",
    "        val_set = MoaDataset(X_val, y_val, mode='train')\n",
    "\n",
    "        dataloaders = {\n",
    "            'train': DataLoader(train_set, **settings['loader']['train']),\n",
    "            'val': DataLoader(val_set, **settings['loader']['val']),\n",
    "        }\n",
    "\n",
    "        checkpoint_path = f'{SAVE_DIR}Fold{n+1}of{n_splits}.pt'\n",
    "        shape = (X_trn.shape[1], y_trn.shape[1])\n",
    "        best_mean_log_loss, best_preds, trn_losses, val_losses = run_fold(dataloaders, shape, checkpoint_path, \n",
    "                                                                          ModelClass, show_log=show_log, \n",
    "                                                                          mixup=mixup, mixup_alpha=mixup_alpha)\n",
    "\n",
    "        # result\n",
    "        print(f':: best mean_log_loss: {best_mean_log_loss:5.5f} ::')\n",
    "        mean_log_loss_list.append(best_mean_log_loss)\n",
    "#         oof[idx_val, :] = best_preds\n",
    "        oof[mask_fold, :] = best_preds\n",
    "        \n",
    "        # permutation importance\n",
    "        if pi:\n",
    "            device = torch.device(\"cuda\")\n",
    "            model = ModelClass(shape[0], shape[1]).to(device)\n",
    "            state_dict = torch.load(checkpoint_path)\n",
    "            model.load_state_dict(state_dict)\n",
    "            model.to(device)\n",
    "            model.eval()\n",
    "            pi = permutation_importance(model, mean_log_loss) # model と metric を渡す\n",
    "            pi.compute(X_val, y_val)\n",
    "            pi_result = pi.df_result\n",
    "            df_pi = pd.concat([df_pi, pi_result[['feat', 'score_diff']]])\n",
    "    #         pi.show_permutation_importance(score_type='loss')\n",
    "        \n",
    "        # plot\n",
    "        if show_log:\n",
    "            x = np.arange(1, len(trn_losses)+1)\n",
    "            plt.figure(figsize=(12, 7))\n",
    "            plt.plot(x[1:], trn_losses[1:], '--.', label='train')\n",
    "            plt.plot(x[1:], val_losses[1:], '--.', label='valid')\n",
    "            plt.title(f\"fold{n+1}/{n_splits} {settings['loss']['name']}\")\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        print('\\n')\n",
    "    \n",
    "    if pi:\n",
    "        # permutation score\n",
    "        plt.figure(figsize=(15, int(0.25*len(FEAT_COLUMNS))))\n",
    "        order = df_pi.groupby([\"feat\"]).mean()['score_diff'].reset_index().sort_values('score_diff', ascending=True)\n",
    "        sns.barplot(x=\"score_diff\", y=\"feat\", data=df_pi, order=order['feat'])\n",
    "        plt.title('base_score - permutation_score')\n",
    "        plt.show()\n",
    "    return mean_log_loss_list, oof, df_pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = yaml.safe_load(settings_str)\n",
    "seed_everything(settings['globals']['seed'])\n",
    "sns.set()\n",
    "sns.set_context('talk')\n",
    "\n",
    "if not os.path.exists(SAVE_DIR):\n",
    "    os.makedirs(SAVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    settings['split']['params']['n_splits'] = 2\n",
    "    settings['globals']['num_epochs'] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv(PATH_TRAIN)\n",
    "train_targets = pd.read_csv(PATH_TRAIN_SCORED)\n",
    "# test_features = pd.read_csv(PATH_TEST)\n",
    "train_drug = pd.read_csv(PATH_DRUGID)\n",
    "group696 = pd.read_csv(PATH_GROUP696)\n",
    "\n",
    "# ss = pd.read_csv(PATH_SUB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_top8 を作成\n",
    "mask_top8 = []\n",
    "for drug_id in train_drug.drug_id.values:\n",
    "    if drug_id in TOP8_DRUG:\n",
    "        mask_top8.append(True)\n",
    "    else:\n",
    "        mask_top8.append(False)\n",
    "mask_top8 = np.array(mask_top8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_col = 10\n",
    "step_row = 11\n",
    "\n",
    "if DEBUG:\n",
    "    print(':: debug mode ::')\n",
    "    train_features = train_features.iloc[::step_row, :end_col].reset_index(drop=True)\n",
    "    train_targets = train_targets.iloc[::step_row, :].reset_index(drop=True)\n",
    "    mask_top8 = mask_top8[::step_row]\n",
    "    train_drug = train_drug.iloc[::step_row, :].reset_index(drop=True)\n",
    "    group696 = group696.iloc[::step_row, :].reset_index(drop=True)\n",
    "#     test_features = test_features.iloc[::100, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_trt = (train_features['cp_type'] == 'trt_cp').values\n",
    "train = preprocess(train_features)\n",
    "FEAT_COLUMNS = train_features.columns[2:]\n",
    "# test = preprocess(test_features).values\n",
    "\n",
    "del train_targets['sig_id']\n",
    "\n",
    "target_cols = [col for col in train_targets.columns]\n",
    "train, targets = remove_ctl_cp(train, train_targets)\n",
    "# train_targets = train_targets.loc[train['cp_type']==0].reset_index(drop=True).values\n",
    "# train = train.loc[train['cp_type']==0].reset_index(drop=True).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:         (21948, 874)\n",
      "train_targets shape: (21948, 206)\n"
     ]
    }
   ],
   "source": [
    "print(f'train shape:         {train.shape}')\n",
    "# print(f'test shape:          {test.shape}')\n",
    "print(f'train_targets shape: {targets.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "fold分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.53 s, sys: 0 ns, total: 6.53 s\n",
      "Wall time: 6.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_fold = get_not_drug_leak_folds(settings['split']['params']['n_splits'], train_features, train_drug, group696)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5  3  1  2  4 -1]\n",
      "[5 3 1 2 4]\n"
     ]
    }
   ],
   "source": [
    "splitter = KFold(n_splits=settings['split']['params']['n_splits'], random_state=1, shuffle=True)\n",
    "for top8_i in range(len(TOP8_DRUG)):\n",
    "    mask_drug = df_fold['drug_id'] == TOP8_DRUG[top8_i]\n",
    "\n",
    "    for fold_i, (train_idx, valid_idx) in enumerate(splitter.split(df_fold[mask_drug])):\n",
    "#         df_fold[['fold']][mask_drug].iloc[valid_idx, :] = fold_i + 1\n",
    "#         df_fold[['fold']][mask_drug] = fold_i + 1\n",
    "        _df_fold = df_fold[mask_drug]\n",
    "        _df_fold.fold.values[valid_idx] = fold_i + 1\n",
    "        df_fold.fold[mask_drug] = _df_fold.fold.values\n",
    "print(df_fold.fold.unique())\n",
    "print(df_fold[mask_trt].fold.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "top8の除去"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[~mask_top8[mask_trt]]\n",
    "targets = targets[~mask_top8[mask_trt]]\n",
    "df_fold = df_fold[mask_trt & ~mask_top8].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = settings['split']['params']['n_splits']\n",
    "n_epochs = settings['globals']['num_epochs']\n",
    "splitter = MultilabelStratifiedKFold(**settings['split']['params'])\n",
    "device = settings['globals']['device']\n",
    "# criterion = criterion_ = nn.__getattribute__(\n",
    "#     settings['loss']['name'])(**settings['loss']['params'])\n",
    "criterion = SmoothBCEwLogits(**settings['loss']['params'], smoothing=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  1.17063378,  1.37038345,  1.60421716,  1.8779508 ,\n",
       "        2.19839265,  2.5735127 ,  3.0126409 ,  3.52669921,  4.12847324,\n",
       "        4.83293024,  5.6575914 ,  6.62296762,  7.75306963,  9.07600522,\n",
       "       10.62467831, 12.43760735, 14.55988332, 17.04429127, 19.95262315])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_logspace = 5\n",
    "n_logspace = 20\n",
    "logspace = np.logspace(0, 1.3, n_logspace)\n",
    "# logspace = np.hstack((np.array([0]), logspace))\n",
    "logspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='20' class='' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [20/20 2:24:01<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mixup_alpha: 1.0\n",
      "save: ../data_ignore/output_nb/nb026/oof_focal_loss_mixup-alpha_1.000000.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Fri Nov 27 10:00:28 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01886 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Fri Nov 27 10:01:59 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02009 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Fri Nov 27 10:03:26 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01872 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Fri Nov 27 10:04:48 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02144 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Fri Nov 27 10:05:58 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01911 ::\n",
      "\n",
      "\n",
      "mixup_alpha: 1.1706337816171068\n",
      "save: ../data_ignore/output_nb/nb026/oof_focal_loss_mixup-alpha_1.170634.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Fri Nov 27 10:07:29 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01885 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Fri Nov 27 10:08:52 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02004 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Fri Nov 27 10:10:11 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01857 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Fri Nov 27 10:11:28 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02142 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Fri Nov 27 10:12:35 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01898 ::\n",
      "\n",
      "\n",
      "mixup_alpha: 1.370383450663168\n",
      "save: ../data_ignore/output_nb/nb026/oof_focal_loss_mixup-alpha_1.370383.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Fri Nov 27 10:13:58 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01887 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Fri Nov 27 10:15:28 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02005 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Fri Nov 27 10:16:54 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01867 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Fri Nov 27 10:18:07 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02131 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Fri Nov 27 10:19:29 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01908 ::\n",
      "\n",
      "\n",
      "mixup_alpha: 1.6042171611153244\n",
      "save: ../data_ignore/output_nb/nb026/oof_focal_loss_mixup-alpha_1.604217.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Fri Nov 27 10:21:07 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01876 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Fri Nov 27 10:22:37 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02012 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Fri Nov 27 10:24:04 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01861 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Fri Nov 27 10:25:25 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02129 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Fri Nov 27 10:26:47 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01902 ::\n",
      "\n",
      "\n",
      "mixup_alpha: 1.8779508018514914\n",
      "save: ../data_ignore/output_nb/nb026/oof_focal_loss_mixup-alpha_1.877951.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Fri Nov 27 10:28:27 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01885 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Fri Nov 27 10:29:54 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02000 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Fri Nov 27 10:31:16 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01860 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Fri Nov 27 10:32:45 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02120 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Fri Nov 27 10:34:04 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01906 ::\n",
      "\n",
      "\n",
      "mixup_alpha: 2.1983926488622894\n",
      "save: ../data_ignore/output_nb/nb026/oof_focal_loss_mixup-alpha_2.198393.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Fri Nov 27 10:35:34 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01873 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Fri Nov 27 10:36:59 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02002 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Fri Nov 27 10:38:30 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01871 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Fri Nov 27 10:40:04 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02125 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Fri Nov 27 10:41:35 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01897 ::\n",
      "\n",
      "\n",
      "mixup_alpha: 2.5735127000169107\n",
      "save: ../data_ignore/output_nb/nb026/oof_focal_loss_mixup-alpha_2.573513.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Fri Nov 27 10:43:06 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01880 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Fri Nov 27 10:44:30 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02003 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Fri Nov 27 10:45:58 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01863 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Fri Nov 27 10:47:23 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02128 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Fri Nov 27 10:48:41 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01911 ::\n",
      "\n",
      "\n",
      "mixup_alpha: 3.0126409040604467\n",
      "save: ../data_ignore/output_nb/nb026/oof_focal_loss_mixup-alpha_3.012641.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Fri Nov 27 10:50:11 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01879 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Fri Nov 27 10:51:40 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02007 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Fri Nov 27 10:53:15 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01863 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Fri Nov 27 10:54:33 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02120 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Fri Nov 27 10:55:50 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01903 ::\n",
      "\n",
      "\n",
      "mixup_alpha: 3.52669921417466\n",
      "save: ../data_ignore/output_nb/nb026/oof_focal_loss_mixup-alpha_3.526699.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Fri Nov 27 10:57:27 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01880 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Fri Nov 27 10:58:57 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01999 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Fri Nov 27 11:00:29 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01863 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Fri Nov 27 11:01:56 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02132 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Fri Nov 27 11:03:27 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01897 ::\n",
      "\n",
      "\n",
      "mixup_alpha: 4.128473237715361\n",
      "save: ../data_ignore/output_nb/nb026/oof_focal_loss_mixup-alpha_4.128473.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Fri Nov 27 11:05:04 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01876 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Fri Nov 27 11:06:27 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02005 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Fri Nov 27 11:07:58 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01868 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Fri Nov 27 11:09:29 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02126 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Fri Nov 27 11:10:57 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01890 ::\n",
      "\n",
      "\n",
      "mixup_alpha: 4.832930238571754\n",
      "save: ../data_ignore/output_nb/nb026/oof_focal_loss_mixup-alpha_4.832930.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Fri Nov 27 11:12:27 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01875 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Fri Nov 27 11:13:47 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02004 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Fri Nov 27 11:15:14 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01868 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Fri Nov 27 11:16:35 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02203 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Fri Nov 27 11:17:18 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01902 ::\n",
      "\n",
      "\n",
      "mixup_alpha: 5.657591401470918\n",
      "save: ../data_ignore/output_nb/nb026/oof_focal_loss_mixup-alpha_5.657591.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Fri Nov 27 11:18:56 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01875 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Fri Nov 27 11:20:25 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01996 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Fri Nov 27 11:21:48 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01865 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Fri Nov 27 11:23:10 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02126 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Fri Nov 27 11:24:28 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01902 ::\n",
      "\n",
      "\n",
      "mixup_alpha: 6.622967617148329\n",
      "save: ../data_ignore/output_nb/nb026/oof_focal_loss_mixup-alpha_6.622968.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Fri Nov 27 11:26:05 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01882 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Fri Nov 27 11:27:34 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02000 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Fri Nov 27 11:29:06 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01859 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Fri Nov 27 11:30:31 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02138 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Fri Nov 27 11:31:54 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01907 ::\n",
      "\n",
      "\n",
      "mixup_alpha: 7.753069627189986\n",
      "save: ../data_ignore/output_nb/nb026/oof_focal_loss_mixup-alpha_7.753070.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Fri Nov 27 11:33:25 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01877 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Fri Nov 27 11:34:52 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01999 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Fri Nov 27 11:36:16 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01861 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Fri Nov 27 11:37:47 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02124 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Fri Nov 27 11:38:57 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01902 ::\n",
      "\n",
      "\n",
      "mixup_alpha: 9.076005216818146\n",
      "save: ../data_ignore/output_nb/nb026/oof_focal_loss_mixup-alpha_9.076005.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Fri Nov 27 11:40:26 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01877 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Fri Nov 27 11:41:46 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02006 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Fri Nov 27 11:43:20 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01866 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Fri Nov 27 11:44:47 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02132 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Fri Nov 27 11:46:19 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01892 ::\n",
      "\n",
      "\n",
      "mixup_alpha: 10.624678308940414\n",
      "save: ../data_ignore/output_nb/nb026/oof_focal_loss_mixup-alpha_10.624678.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Fri Nov 27 11:47:50 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01870 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Fri Nov 27 11:49:21 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02002 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Fri Nov 27 11:50:53 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01867 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Fri Nov 27 11:52:24 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02125 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Fri Nov 27 11:53:41 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01897 ::\n",
      "\n",
      "\n",
      "mixup_alpha: 12.437607347260164\n",
      "save: ../data_ignore/output_nb/nb026/oof_focal_loss_mixup-alpha_12.437607.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Fri Nov 27 11:55:20 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01875 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Fri Nov 27 11:56:43 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02001 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Fri Nov 27 11:58:06 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01870 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Fri Nov 27 11:59:20 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02133 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Fri Nov 27 12:00:42 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01911 ::\n",
      "\n",
      "\n",
      "mixup_alpha: 14.559883323191878\n",
      "save: ../data_ignore/output_nb/nb026/oof_focal_loss_mixup-alpha_14.559883.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Fri Nov 27 12:02:20 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01881 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Fri Nov 27 12:03:44 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01999 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Fri Nov 27 12:05:08 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01860 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Fri Nov 27 12:06:29 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02129 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Fri Nov 27 12:08:05 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01899 ::\n",
      "\n",
      "\n",
      "mixup_alpha: 17.044291274531954\n",
      "save: ../data_ignore/output_nb/nb026/oof_focal_loss_mixup-alpha_17.044291.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Fri Nov 27 12:09:39 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01875 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Fri Nov 27 12:11:04 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02002 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Fri Nov 27 12:12:40 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01858 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Fri Nov 27 12:14:05 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02140 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Fri Nov 27 12:15:37 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01902 ::\n",
      "\n",
      "\n",
      "mixup_alpha: 19.952623149688797\n",
      "save: ../data_ignore/output_nb/nb026/oof_focal_loss_mixup-alpha_19.952623.csv\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 1/5 at Fri Nov 27 12:17:07 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01873 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 2/5 at Fri Nov 27 12:18:38 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01998 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 3/5 at Fri Nov 27 12:20:15 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01860 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 4/5 at Fri Nov 27 12:21:40 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.02114 ::\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ":: start fold 5/5 at Fri Nov 27 12:23:00 2020 ::\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping\n",
      ":: best mean_log_loss: 0.01900 ::\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_resultmma' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_resultmma' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# mean_log_loss_list, _oof, df_pi = run(splitter, train, targets, MoaModel, show_log=isShowLog, pi=isPI)\n",
    "list_oof_score = []\n",
    "for alpha in progress_bar(logspace):\n",
    "    print(f'mixup_alpha: {alpha}')\n",
    "    save_path = f'{SAVE_DIR}oof_focal_loss_mixup-alpha_{alpha:.6f}.csv'\n",
    "    print(f'save: {save_path}')\n",
    "    \n",
    "    mean_log_loss_list, _oof, df_pi = run_not_drug_leak(df_fold, train, targets, MoaModel,\n",
    "                                                        show_log=isShowLog, pi=isPI, \n",
    "                                                        mixup=MIXUP, mixup_alpha=alpha)\n",
    "    oof_score = mean_log_loss(targets, _oof)\n",
    "    list_oof_score.append(oof_score)\n",
    "    \n",
    "    # save oof\n",
    "    df_oof = pd.DataFrame(_oof, columns=target_cols)\n",
    "    df_oof.to_csv(save_path, index=False)\n",
    "\n",
    "df_result = pd.DataFrame()\n",
    "df_result['mixup_alpha'] = logspace\n",
    "df_result['oof_score'] = list_oof_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mixup_alpha</th>\n",
       "      <th>oof_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.019644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.170634</td>\n",
       "      <td>0.019574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.370383</td>\n",
       "      <td>0.019595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.604217</td>\n",
       "      <td>0.019559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.877951</td>\n",
       "      <td>0.019541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.198393</td>\n",
       "      <td>0.019539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.573513</td>\n",
       "      <td>0.019568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.012641</td>\n",
       "      <td>0.019544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.526699</td>\n",
       "      <td>0.019542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.128473</td>\n",
       "      <td>0.019530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.832930</td>\n",
       "      <td>0.019702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.657591</td>\n",
       "      <td>0.019528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6.622968</td>\n",
       "      <td>0.019572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7.753070</td>\n",
       "      <td>0.019525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9.076005</td>\n",
       "      <td>0.019547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10.624678</td>\n",
       "      <td>0.019522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>12.437607</td>\n",
       "      <td>0.019580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>14.559883</td>\n",
       "      <td>0.019536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17.044291</td>\n",
       "      <td>0.019553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19.952623</td>\n",
       "      <td>0.019491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mixup_alpha  oof_score\n",
       "0      1.000000   0.019644\n",
       "1      1.170634   0.019574\n",
       "2      1.370383   0.019595\n",
       "3      1.604217   0.019559\n",
       "4      1.877951   0.019541\n",
       "5      2.198393   0.019539\n",
       "6      2.573513   0.019568\n",
       "7      3.012641   0.019544\n",
       "8      3.526699   0.019542\n",
       "9      4.128473   0.019530\n",
       "10     4.832930   0.019702\n",
       "11     5.657591   0.019528\n",
       "12     6.622968   0.019572\n",
       "13     7.753070   0.019525\n",
       "14     9.076005   0.019547\n",
       "15    10.624678   0.019522\n",
       "16    12.437607   0.019580\n",
       "17    14.559883   0.019536\n",
       "18    17.044291   0.019553\n",
       "19    19.952623   0.019491"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'oof_score')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.axhline(df_result.oof_score[0], color='r', label='mixup_alpha=1')\n",
    "# plt.plot(df_result.mixup_alpha[1:], df_result.oof_score[1:], '.', label=None)\n",
    "plt.plot(df_result.mixup_alpha, df_result.oof_score, '.', label=None)\n",
    "plt.xscale('log')\n",
    "plt.xlabel('mixup_alpha')\n",
    "plt.ylabel('oof_score')\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
